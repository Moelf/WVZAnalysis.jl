{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-31 04:08:26.137441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-31 04:08:29.479404: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-31 04:08:29.486112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-31 04:08:29.529080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:65:00.0 name: Quadro RTX 4000 computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 387.49GiB/s\n",
      "2022-01-31 04:08:29.529159: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-31 04:08:29.561981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-31 04:08:29.562120: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-01-31 04:08:29.581991: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-31 04:08:29.586535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-31 04:08:29.620501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-31 04:08:29.626523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-31 04:08:29.685819: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-31 04:08:29.686921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.errors import InvalidArgumentError\n",
    "import tensorflow as tf\n",
    "\n",
    "# Tensorflow GPU settings\n",
    "# gpu_options = tf.GPUOptions(allow_growth=True)#per_process_gpu_memory_fraction=0.5)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from scipy import interpolate\n",
    "\n",
    "from atlasify import atlasify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/20220117_iso_e4m1_VVZ_RD.arrow')\n",
    "sig['is_signal'] = True\n",
    "# sig = sig[sig.SR == 2]\n",
    "\n",
    "bg = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/20220117_iso_e4m1_FULLBG_RD.arrow')\n",
    "bg['is_signal'] = False\n",
    "# bg = bg[bg.SR == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats_raw = sorted([f for f in sig.columns if f not in ['index', 'wgt', 'is_signal', \n",
    "                                                              'Zcand_mass', 'chisq']])\n",
    "\n",
    "train_feat_sets = [train_feats_raw, \n",
    "                   [f for f in train_feats_raw if f not in ['Wlep1_phi', 'Wlep2_phi', 'Zlep1_phi', 'Zlep2_phi']],\n",
    "                   [f for f in train_feats_raw if f not in ['MET', 'METSig']],\n",
    "                   [f for f in train_feats_raw if f not in ['pt_1', 'pt_2', 'pt_3', 'pt_4']],\n",
    "                   [f for f in train_feats_raw if f not in ['Njet', 'Nlep']]\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize training features\n",
    "X = pd.concat([sig[train_feats_raw], bg[train_feats_raw]], ignore_index=True)\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "min_max_scaler.fit(X)\n",
    "\n",
    "for df in [sig, bg]:\n",
    "    df[train_feats_raw] = min_max_scaler.transform(df[train_feats_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load per-background models\n",
    "models_dir = 'models/background_id_models/'\n",
    "\n",
    "background_classifiers = {'ZZ': 1, 'Zjets': 2, 'WZ': 1, 'ttZ': 0, 'other': 1}\n",
    "\n",
    "for bc_name in background_classifiers:\n",
    "    bc_index = background_classifiers[bc_name]\n",
    "    \n",
    "    classifier = keras.models.load_model((models_dir + 'classifier_' + bc_name \n",
    "                                          + '_train_feat_test_' + str(bc_index)))\n",
    "    sig['classifier_' + bc_name + '_score'] = classifier.predict(sig[train_feat_sets[bc_index]], \n",
    "                                                                    batch_size=10000)\n",
    "    bg['classifier_' + bc_name + '_score'] = classifier.predict(bg[train_feat_sets[bc_index]], \n",
    "                                                                   batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, b, _ = plt.hist(bg.classifier_ZZ_score, bins=100, weights=bg.wgt, density=True, alpha=0.5)\n",
    "plt.hist(sig.classifier_ZZ_score, bins=b, weights=sig.wgt, density=True, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, b, _ = plt.hist(bg.classifier_Zjets_score, bins=100, weights=bg.wgt, density=True, alpha=0.5)\n",
    "plt.hist(sig.classifier_Zjets_score, bins=b, weights=sig.wgt, density=True, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, b, _ = plt.hist(bg.classifier_WZ_score, bins=100, weights=bg.wgt, density=True, alpha=0.5)\n",
    "plt.hist(sig.classifier_WZ_score, bins=b, weights=sig.wgt, density=True, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAD4CAYAAAAuNhccAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAANDElEQVR4nO3df4xsd1nH8fdTbq1oTCXchVbjsi1SiBGKZMVWAinEG0yDYgoK0Wj4g66BGGwjok0waWwMiWIwRvljCVETg/3HCBZjTQUJvwp4G7SG21pqWyBU9LbxDxVE0z7+MXMvc7c7M2d3zjnzzDnvV7LJ3D3nzjzfzL2ffeZ7vt+zkZlIkmq6aN0FSJLmM6QlqTBDWpIKM6QlqTBDWpIKO9H2E548eTJ3dnbaflpJGrR77rnnsczcOvj91kN6Z2eH06dPt/20kjRoEfGlw77vdIckFWZIS1JhhrQkFWZIS1JhhrQkFWZIS1JhhrQkFWZIS1JhhrQkFdb6jkNJGoL33PXA+cc3n7pqbXXYSUtSYYa0JBVmSEtSYYa0JBVmSEtSYYa0JBVmSEtSYYa0JBXmZhZJmprdwDLv+31vbLGTlqTCDGlJKszpDkmjNm+Kowo7aUkqzJCWpMIMaUkqzJCWpMIMaUkqzJCWpMIMaUkqzJCWpMIMaUkqzB2Hkkan+i7DWXbSklSYIS1JhTUK6Yj4toj4QkTsdFyPJGlG0076N4DndFmIJOmploZ0RFwNPB843X05kqRZC0M6Ik4A7wFuWnLeXkScjojTZ8+ebbE8SRq3ZZ30rwK3Z+aji07KzP3M3M3M3a2trfaqk6SRWxbS1wC/EhH3Ay8FPhIRz+u+LEkSLNnMkpmvPfc4Ij4GvCkzH+m4JknSlOukJamwxtvCM/O6DuuQJB3CTlqSCvMGS5JGYZNuqjTLkJakI5gN+5tPXdX56zndIUmFGdKSVJghLUmFGdKSVJghLUmFGdKSVJghLUmFGdKSVJghLUmFGdKSVJghLUmFGdKSVJghLUmFGdKSVJi3KpU0WJt6D+lZdtKSVJghLUmFGdKSVJghLUmFGdKSVJghLUmFGdKSVJghLUmFuZlF0qAMYQPLLDtpSSrMkJakwgxpSSrMkJakwgxpSSrMkJakwgxpSSrMddKSNt7Q1kbPspOWpMKWhnREPD0iPhARj0TEP0XEK/ooTJLUbLrjjcB/Z+ZORFwN7AM/0m1ZkiRoFtKfAj46c/7XuytHkjRraUhn5gMAEfEB4GeA1xw8JyL2gD2A7e3tlkuUpPFqfOEwM38WeD7whxFx4sCx/czczczdra2ttmuUpNFqcuHwxoh4IUBm/gvwGPCMrguTJDWbk74Y+EXglyLiCuDSzDzbbVmStNiQ10bPajLd8UfAZRHxCPAXwI2dViRJOq/JhcNvAK/voRZJ0gHuOJSkwgxpSSrMkJakwgxpSSrMkJakwgxpSSrMkJakwvzNLJI2xlh2Gc6yk5akwgxpSSrMkJakwgxpSSrMkJakwlzdIam0Ma7omGUnLUmFGdKSVJghLUmFGdKSVJghLUmFGdKSVJhL8CSVM/Zld7PspCWpMENakgozpCWpMENakgrzwqGkErxYeDg7aUkqzJCWpMIMaUkqzJCWpMIMaUkqzNUdkkbtmi/vn3/8me29NVZyODtpSSrMTlpSr1wPfTR20pJUWKOQjoh3R8SjEXF/RFzfdVGSpIml0x0R8aPAy4ArgGcDH4uI78/MJ7suTpLGrsmc9Bbwvsz8JvDliPhP4CTw751WJkkdmV3RUd3SkM7MD517HBGvBgI422VRkqSJRqs7IuIS4DeB1wI3ZGYeOL4H7AFsb2+3XaMkLdRkrfMmdc+zll44jIgTwF8DlwAvycwzB8/JzP3M3M3M3a2trQ7KlKRxatJJvwE4m5k3dVyLpIHalLXRFXcfNgnpHwReFREPznzvhzPzPzqqSZI01eTC4S3ALT3UIkmtWmUeukpX7bZwSaVVCct1MaQlbYwmnfGmruKYx3t3SFJhdtKSOrEpKzqqs5OWpMLspCUdyWyHfPOpq1Z6rrFfFGzCkJbUCqc3umFIS+rEUbvkTeyq2/xUMY8hLalXY1xGtwovHEpSYXbSko6t6Ty0nfHx2UlLUmF20pK0xDovatpJS1JhdtKSdAR9d9V20pJUmJ20pGPbxA0om8aQltQKl9l1w5CWtJT35VgfQ3qT/d27vvX4lf4aSmmIDGlJh7J7rsGQHiI7bGkwXIInSYXZSUtayqV262NIbwKnL9ST2XnoeUvqXGrXL6c7JKkwO+mhmO22pWX8dLYx7KQlqTA7aWlTHbEbvuCXps78z7/7/W//1h+8KFiOIT1WftzdTEec1jrqhhQvCtZjSFfS5D+gc886jD90B8uQHhMDXlN3P/T4uktQQ4a0NDQX/DB+3drKUDsM6aGze5Y2miEtjYQXBTeTIb1udrqSFmgU0hFxHXBdZt7aZTEqzhUEUu+WhnREvAN4C/An3ZejQakc6pVrO+iIn7ZmV25cg1Mcm65JJ30v8MGO6xgXpzikQbhwnv/dnbzG0pDOzDsj4jJgZ945EbEH7AFsb2+3Vpx6Mq+r9IeJtHatXDjMzH2YfK7a3d3NNp5TWrvjTImsaRrFzSnD5eoOqSurfBJpEPAG8zgY0lrdJl2EO65FgdvFmOe8nsE8Poa0LuQ8tFRKo5DOzD/uuA5tmqOG+bq67Q3t8u2YdY6/mUWSCnO6Q+1aZbpk3t9t0gFvaMcsLWNId8n53fXo4gdFV68nLWFIa70MOGkhQ1r9a+ui4yrPs0o9LfICoZYxpLVZ7Lw1Moa01AM7Zh2XS/AkqTBDWpIKM6QlqTDnpKWOOA+tNhjSbXP1QStmA+7aK5+5xkqe6mD4ztZnMKtthrS0IoNZXTKkpRmVO3iNkyEtzWGHrApc3SFJhdlJa9CaTF/YMasyQ1qjYRhrExnS2liGrsbAkD4u10P3xhUXGjNDeiDmBVn1gDtqfXbPGhtDesM0Cal556waiF2HvwEsPZUhvQG6CK95z9lmt23oSqszpHWBRcHapEOX1C5Des0MOEmLGNJH4YoOST0zpNfA7llSU967Q5IKs5M+zOy0xitvWV8dkkbPkIbFc80tzUM7xSHpOJzukKTC7KSPyVtgSuqDId0yg1lSm8Yb0i2ueTaYJXXFOWlJKmy8nfQx2DFL6lujkI6I24CfBx4FbsjMr3VaVZvcyi1pgy0N6Yh4OfAy4ErgF4DbgBs7ruvojrgBxa5Y0iZo0kn/GPCnmflkRNwO1NmCNxPMF4TuQ29fQzGS1L4mIX058GmAzPyfiLjk4AkRsQfsTf/4XxHxOPBYa1VunpOMd/xjHjs4/vGO/82/u+rYn3PYN5teOIyZx08ePJiZ+8D++ZMjTmfm7pHKG5Axj3/MYwfHP+bxdzX2Jkvw/hX4nmkR3w58s+0iJEmHaxLSHwF+LiIuAn4auKvbkiRJ5yyd7sjMj0fE54EvAQ8Bb2jwvPvLTxm0MY9/zGMHxz/m8Xcy9sjMLp5XktQCt4VLUmGGtCQVtnJIR8RtEfFIRHw6Ii47cOzaiPhCRDwcEa9f9bWqWTL2V0XEg9OxvzciYt7zbKpF4585550RcWvPpXVuyXv/fRHx2enx29ZVY5eWjP8nI+K+6b//OpvfWhQR1x3277qTzMvMY38BLwc+yiTs3wS878DxM8BVwBbwReA7Vnm9Sl8Nxn4f8EPT438O/NS6a+5z/NNzfgB4HLh13fX2/N7fBVwLPA34JHD1umvuefwPAs9isjDhU8CV66655fG/A3j4sH/XXWTeqp30+S3jwO3AK84diIgrgMcy84HMPAvcDQxpkfuisT8NuC8zPz89/kkmb9yQzB0/wHTJ5u9Nv4Zm0Xv/bOC7MvPuzHwC+HHgn9dTZmcWvvfA/wFPZxLSlzC8u23eC3zw4De7yrxVQ/py4Ksw2TLO5A15yrGpR5luihmIuWPPzCcy8waAiHgGk27j42uosUuL3nuAm4APAV/pt6xeLBr7FcA3IuKOiDgD/Nr0nCFZ9t7/DpMu8t+AM5n5QL/ldSsz7wT+8ZBDnWReGxcOF20ZjwOPn2jh9SpZuF0+Iq4HTjP5OPiZ3qrqz6Hjj4grmXSQ7+29ov7Me+8vAl4I/DLwYuAlEXGqx7r6Mu+9v5TJdMBzgcuA746IF/Vc2zq1nnmrfgxZtGX8/LGp7wX+csXXq2ThdvmIeDPwVuAnMvNM/+V1btH4X8pkeuc+4FLg4oj4emb+du9VdmPR2M8Cn8vMh6bHPwxczbB26i4a/wuAezPzK9PjdzL5gX1v30WuQSeZt2onPXfLeGY+DGxFxPMi4plMLqL9/YqvV8ncsU/vFPhbwKmBBjQsfu9vz8ydzHwBk1vb/sGAAhoW3yrhQeDyiNiOiBPA9cA/9F9ipxaN/4vAiyPi5HT8rwbuX0ONvesq81bqpPOQLeMR8bbpsd9n0kn+1fT0X8/M/13l9SpZNHbgb5h0kJ+dWXn3rsx8f/+VdqPBez9Yy8YeEW8B7gC+E/izzPzb9VXbvgbjfyfwCeBiJp3kHWsrtgddZ57bwiWpMHccSlJhhrQkFWZIS1JhhrQkFWZIS1JhhrQkFWZIS1Jh/w/b7UmocVTYXgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, b, _ = plt.hist(bg.classifier_ttZ_score, bins=100, weights=bg.wgt, density=True, alpha=0.5)\n",
    "plt.hist(sig.classifier_ttZ_score, bins=b, weights=sig.wgt, density=True, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD4CAYAAAAjKGdbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAO5ElEQVR4nO3df6xkdXnH8fezLkJtLLbsKEhdllWRGi1oL2a3BLPYUoyJtaG2JJK2JsJNbJN2NS0tCVYiMTQVS9sY/1ir0F/pmqhBaIUW+aFYwHopZRvBAgWElLYOmzZto6AuT/+Y2d2zl/l1zz3n3P3OvF/JTc7MOXPn+d5z53Of+z3nzERmIkkqy6aNLkCStHaGtyQVyPCWpAIZ3pJUIMNbkgq0uYsn2bJlS27btq2Lp5KkuXHvvfc+nZm9Ues6Ce9t27axsrLSxVNJ0tyIiG+OW+e0iSQVyPCWpAIZ3pJUIMNbkgpkeEtSgQxvSSqQ4S1JBTK8JalAhrckFaiTKywlaaHcftXh5XMva+Up7LwlqUCGtyQVyPCWpAIZ3pJUIMNbkgpkeEtSgWYK74jYFRFXrLrvnIi4rZWqJEkTTQ3viLgUuHbVfccBfzTL4yVJzZslfPcB16+670PAnzVejSRpJlPDOzNvBu4/eDsizgJewfMDXZLUkTVNe0TEMcDVwPtm2HY5IlYiYqXf79etT5I0wlrnrE8EXgXcAdwKvCkiPjNqw8zck5lLmbnU64385HpJUk1remOqzHwSOBkgIrYB12XmO1uoS5I0gWeLSFKBZuq8M/O6Efc9DuxqthxJ0izsvCWpQIa3JBXI8JakAhneklQgw1uSCmR4S1KBDG9JKpDhLUkFMrwlqUCGtyQVyPCWpAIZ3pJUIMNbkgpkeEtSgQxvSSqQ4S1JBTK8JalAhrckFcjwlqQCGd6SVKCZwjsidkXEFcPlH42IuyLiiYj4u4jY0mqFkqTnmRreEXEpcG3lrt8F9mbmVuALwOUt1SZJGmOWznsfcH3ldgB7h8tfAk5ruCZJ0hRTwzszbwbur9y+JDO/FRGbgN3AHaMeFxHLEbESESv9fr+hciVJUPOAZUS8BriTQRf+B6O2ycw9mbmUmUu9Xm8dJUqSVtu81gdExJnA54DdmXlD4xVJkqZac3gDHwF+LTNvaroYSdJs6oT364CPRUQOb9+WmcsN1iRJmmKm8M7M6yrLJ7VWjSRpJl5hKUkFMrwlqUCGtyQVyPCWpAIZ3pJUIMNbkgpkeEtSgQxvSSqQ4S1JBTK8JalAhrckFcjwlqQCGd6SVCDDW5IKZHhLUoEMb0kqkOEtSQUyvCWpQIa3JBVopvCOiF0RccVw+cSIuD0inoyI32u1OknSSFPDOyIuBa6t3PVh4E+BU4CzIuLslmqTJI0xS+e9D7i+cvvNwN7MfA74S+CnWqhLkjTB1PDOzJuB+yt3HZuZzwyXnwJePupxEbEcESsRsdLv99dfqSTpkDoHLLOyHMCBkRtl7snMpcxc6vV6tYqTJI1WJ7y/GxHHDZdPZtB9S5I6VCe87wQujIhNwIXATc2WJEmapk54Xw68F/hX4GuZ+Y/NliRJmmbzLBtl5nWV5aeAHW0VJEmazissJalAhrckFcjwlqQCGd6SVCDDW5IKZHhLUoEMb0kqkOEtSQUyvCWpQIa3JBXI8JakAhneklQgw1uSCmR4S1KBDG9JKpDhLUkFMrwlqUCGtyQVyPCWpALVCu8Y2BMRj0TEfRGx1HRhkqTx6nbePwO8BHg1cBHw0aYKkiRNVze8nwGOGz7+RcAxjVUkSZqqVnhn5peA44E+cA/wgdXbRMRyRKxExEq/319flZKkI9Sd8/4V4HGgB7wBuGz1Npm5JzOXMnOp1+utq0hJ0pHqTpvsAD6dmQcy85+BH4qIlzZYlyRpgrrhvQ94O0BEbGfQge9vqihJ0mR1w/tTwAsj4mHgBmA5Mw80V5YkaZLNdR6Umc8C72m4FknSjLzCUpIKZHhLUoEMb0kqkOEtSQWqdcBSkrTK7Vd1+nR23pJUIMNbkgpkeEtSgQxvSSqQ4S1JBTK8JalAhrckFcjwlqQCGd6SVCDDW5IKZHhLUoEMb0kqkOEtSQUyvCWpQLXDOyIuiojHIuLBiNjZZFGSpMlqvZ93RJwC7AZeC5wK/DnwE82VJUmapG7n/YvApzLzO5n5AHB+gzVJkqaoG96vBF4fESsRsQL82OoNImL54Pp+v7+uIiVJR6ob3puAHwF2Au8C/mT1Bpm5JzOXMnOp1+uto0RJ0mp1w7sPfC4zv5eZDwH/HRFbGqxLkjRB3Q8gvh24OCI+w+CA5YuB/Y1VJUkl6PhDh6tqhXdmfjEizgG+ATwDXJKZ2WhlkqSx6nbeZOYHgQ82WIskaUZeYSlJBTK8JalAhrckFcjwlqQCGd6SVCDDW5IKZHhLUoEMb0kqkOEtSQUyvCWpQIa3JBXI8JakAhneklQgw1uSCmR4S1KBDG9JKlDtD2OQpIW0gR99VmXnLUkFMrwlqUDrCu+IeGFEfD0itjVUjyRpBuvtvD8AnNJEIZKk2dU+YBkRZwCvAVaaK0eSjkJHyUHKqlqdd0RsBq4Bdk/YZjkiViJipd/v1yxPkjRK3WmT3wL2ZuZT4zbIzD2ZuZSZS71er+bTSJJGqTttsgM4PSLeD2wFbo2It2bmw82VJklluvvR/YeWd57bznPUCu/MfMfB5Yi4A3h3Zj7eUE2SpCk8z1uSCrTuy+Mzc1cDdUjSUeuIaZDtJ2xgJYfZeUtSgXxjKkkauuaWhw4t73hiz8htjpYu3M5bkgpk5y1poVW77ZLYeUtSgey8Jamm6vx31wxvSQun1KmSKqdNJKlAdt6SNDTu9MCjkZ23JBXIzlvSQpiHee4qw1vS3Jq3wK5y2kSSCmR4S1KBnDaRNFfWOlVS0hkmVXbeklQgO29JRatzULLUbrvKzluSCmTnLak483wK4Kxqh3dEXA28C/gf4P2Z+YXGqpKkhs3DVElVrfCOiJ8EzgZOBV4G3BERr8rM55osTpI0Wt3Ouwd8IjOfBZ6IiP8FtgDfaqwySapwquRItcI7Mz9/cDkizgcC6Fe3iYhlYBlg69at6yhRkuqZt6mSqvXMeR8LfAh4B3BBZmZ1fWbuAfYALC0t5fO/gyRNZrc9Xt05783ATcA+4I2Z+e1Gq5K0sNYb2PPcbVfV7bwvBPqZubvBWiQtqPUE9qKE9Wp1w/t1wFsi4pHKfWdl5n81UJOkBeCUyPrUPWB5GXBZw7VImnMGdnO8wlJScRZ1qqTK8JbUKrvtdhjekhpnYLfP8JbUiDYC2+mR8QxvSWvSdldtYM/G8JY0UjWk33feaRtYiUYxvCVN1VS3Xe2q79m63Mj3XFSGt6RDmrrScZZgdnpkfQxvaY6Nm/ro8mwQQ7odhrc0Z8YFs2eDzBfDWzrKHA3dMoyfBpklsA319hne0lGgy255NYO2TIZ3gzy1qlC3X3V4+dxm3m9tI7vkEr+/1m6hwnut/44awJrGszO0URYqvKtmedEdLXOPOmyt/93Msq92PLH/0PI932/+fOaqcSFtMGutFja8q2bpgMaFwLjH3v3J3xy5/c73XH34Rgv/rndilror21zz/Z8/tDwupKo/l9U/63EhXf0Zjz2gtsawnOUg3VoP3kltiFWfG9yKpaWlXFlZaf15Rhn3Aq+a5QXY9Qt2luAYpxp24/6IVO3cfsLh7R/dP3KbWcbfVNitHmNTP29DVxvhiIZtjSLi3sxcGrVuLjvvaue2o3L/PLxgZwnyWQL7iO3HBPa4513rNmv9ube1n+Zh/0sHzWV4t6HrF77n0kqapHZ4R8SVwC8BTwEXZOZ/NFZVDUd024aapDlXK7wj4hzgbGA78MvAlcAlDdY1EwNb0qKq23n/NPAXmflcROylw0+Sr87n7piwnSTNs7rhfRJwF0BmPhMRx67eICKWgYNH1P4vIv5lzPfaAjxds47SLerYF3XcsLhjX9Rxw8UfXc/YTxm3Yj0HLKOy/NzqlZm5B5g6lxERK+NOhZl3izr2RR03LO7YF3Xc0N7YN9V83L8DLweIiOOAZxurSJI0Vd3wvhW4KCI2Ab8A3NJcSZKkaWpNm2TmlyPiPuCbwKPAheuoYZFPE1nUsS/quGFxx76o44aWxt7J5fGSpGbVnTaRJG0gw1uSCtRpeEfElRHxeETcFREnrlq3MyK+HhGPRcQ7u6yrbVPG/ZaIeGQ47o9HRIz7PiWaNPbKNpdHxBUdl9aqKfv8FRHx1eH6KzeqxrZMGfvPRsSDw9/5gt4HeTYRsWvU73Ir+ZaZnXwB5wC3MfiD8W7gE6vWPwCcBvSAh4EXdVXbBo/7QeANw/WfBX5uo2vuauzDbV4L7Aeu2Oh6O9zntwA7gRcAXwHO2OiaOxz7I8BLGZws8ffA9o2uucGxXwo8Nup3uY1867LzPnRJPbAXePPBFRFxKvB0Zj6UmX3gbmBeTuifNO4XAA9m5n3D9V9hsIPnxdixAwxPNf3D4dc8mbTPXwa8ODPvzswDwFuBcVcfl2jiPge+B/wAg/A+lvl6Z9N9wPWr72wr37oM75OAf4PBJfUMdtzz1g09xfAioDkwdtyZeSAzLwCIiB9m0Kl8eQNqbMukfQ6wG/g88GS3ZbVu0rhPBb4TETdGxAPAbw+3mRfT9vlHGHSe/wk8kJlz85mCmXkzcP+IVa3kW9cHLCddUh+rlg+0X05nJr6VQES8DVhh8C/mPZ1V1Y2RY4+I7Qy6zo93XlE3xu3zTcDrgd8AzgTeGBHndVhXF8bt8+MZTC28EjgReElE/HjHtW2UxvOty39ZJl1Sf2jd0MnADd2V1qqJbyUQERcDvwq8PTMf6L68Vk0a+5sYTBE9CBwPHBMR387M3++8yuZNGncf+IfMfHS4/q+BM5ifq5Qnjf10YF9mPjlcfzODP+D7ui6yY63kW5ed99hL6jPzMaAXEa+OiBMYHMD7Woe1tWnsuIfvxvhh4Lw5DG6YvM/3Zua2zDydwVsKf2xOghsmv33EI8BJEbE1IjYDbwP+qfsSWzNp7A8DZ0bEluHYzwe+sQE1dqqtfOus884Rl9RHxK8P1/0xg+7zb4ab/05mfrer2to0adzA3zLoOr9aOUPwqsz8ZPeVNm+GfT6Xpo07It4L3Aj8IPBXmfnFjau2WTOM/XLgTuAYBt3njRtWbMvazjcvj5ekAnmFpSQVyPCWpAIZ3pJUIMNbkgpkeEtSgQxvSSqQ4S1JBfp/rBr3mlP9meEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, b, _ = plt.hist(bg.classifier_other_score, bins=100, weights=bg.wgt, density=True, alpha=0.5)\n",
    "plt.hist(sig.classifier_other_score, bins=b, weights=sig.wgt, density=True, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut to 4l-DF signal region\n",
    "bg = bg[bg.SR == 1]\n",
    "sig = sig[sig.SR == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "\n",
    "First we want to figure out the signal/background ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 38.30702696298086 background events\n",
      "There are 6.760975084128499 signal events\n",
      "\n",
      "S/B = 0.17649438288860603\n",
      "Starting significance is 1.0623934062436122 sigma\n",
      "Corresponds to 1.5024511636854656 sigma\n"
     ]
    }
   ],
   "source": [
    "def region_sig(s, b):\n",
    "    if s == 0:\n",
    "        return 0\n",
    "    return np.sqrt(2 * ((s + b) * np.log(1 + s / b) - s))\n",
    "\n",
    "n_bg = sum(bg.wgt)\n",
    "n_sig = sum(sig.wgt)\n",
    "\n",
    "print('There are', n_bg, 'background events')\n",
    "print('There are', n_sig, 'signal events')\n",
    "print('')\n",
    "print('S/B =', n_sig/n_bg)\n",
    "print('Starting significance is', region_sig(n_sig, n_bg), 'sigma')\n",
    "print('Corresponds to', np.sqrt(2.0) * region_sig(n_sig, n_bg), 'sigma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/kbenkend/ipykernel_56255/2235700710.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bg['abs_wgt'] = np.abs(bg.wgt)\n",
      "/tmp/kbenkend/ipykernel_56255/2235700710.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sig['abs_wgt'] = np.abs(sig.wgt)\n"
     ]
    }
   ],
   "source": [
    "bg['abs_wgt'] = np.abs(bg.wgt)\n",
    "sig['abs_wgt'] = np.abs(sig.wgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'pt_4l', 'SR', 'Wlep1_pt', 'Zlep1_phi', 'Wlep1_pid',\n",
       "       'leptonic_HT', 'Zlep2_pt', 'METSig', 'Wlep2_phi', 'chisq', 'Zlep2_phi',\n",
       "       'MET', 'other_mass', 'total_HT', 'Wlep2_pid', 'Zlep1_eta', 'Wlep1_dphi',\n",
       "       'Zlep1_pt', 'Zlep2_dphi', 'HT', 'wgt', 'pt_2', 'pt_4', 'pt_3',\n",
       "       'Wlep1_eta', 'Wlep2_dphi', 'Zlep2_eta', 'Zcand_mass', 'pt_1', 'Njet',\n",
       "       'Zlep1_dphi', 'Zlep1_pid', 'Wlep2_pt', 'Nlep', 'Wlep2_eta', 'mass_4l',\n",
       "       'Zlep2_pid', 'Wlep1_phi', 'is_signal', 'classifier_ZZ_score',\n",
       "       'classifier_Zjets_score', 'classifier_WZ_score', 'classifier_ttZ_score',\n",
       "       'classifier_other_score', 'abs_wgt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_classifier_score_feats = ['classifier_' + bc + '_score' for bc in background_classifiers]\n",
    "combined_train_feats_raw = train_feats_raw + bg_classifier_score_feats\n",
    "\n",
    "combined_train_feat_sets = [combined_train_feats_raw, \n",
    "                            [f for f in combined_train_feats_raw if f not in bg_classifier_score_feats],\n",
    "                            [f for f in combined_train_feats_raw if f not in ['Wlep1_phi', 'Wlep2_phi', \n",
    "                                                                              'Zlep1_phi', 'Zlep2_phi']],\n",
    "                            [f for f in combined_train_feats_raw if f not in ['MET', 'METSig']],\n",
    "                            [f for f in combined_train_feats_raw if f not in ['pt_1', 'pt_2', 'pt_3', 'pt_4']],\n",
    "                            [f for f in combined_train_feats_raw if f not in ['Njet', 'Nlep']]\n",
    "                           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with training features: ['HT', 'MET', 'METSig', 'Njet', 'Nlep', 'SR', 'Wlep1_dphi', 'Wlep1_eta', 'Wlep1_phi', 'Wlep1_pid', 'Wlep1_pt', 'Wlep2_dphi', 'Wlep2_eta', 'Wlep2_phi', 'Wlep2_pid', 'Wlep2_pt', 'Zlep1_dphi', 'Zlep1_eta', 'Zlep1_phi', 'Zlep1_pid', 'Zlep1_pt', 'Zlep2_dphi', 'Zlep2_eta', 'Zlep2_phi', 'Zlep2_pid', 'Zlep2_pt', 'leptonic_HT', 'mass_4l', 'other_mass', 'pt_1', 'pt_2', 'pt_3', 'pt_4', 'pt_4l', 'total_HT', 'classifier_ZZ_score', 'classifier_Zjets_score', 'classifier_WZ_score', 'classifier_ttZ_score', 'classifier_other_score']\n",
      "Epoch 1/10000\n",
      "31/31 [==============================] - 1s 11ms/step - loss: 0.0020 - accuracy: 0.3325 - val_loss: 0.0020 - val_accuracy: 0.3309\n",
      "Epoch 2/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.3387 - val_loss: 0.0020 - val_accuracy: 0.3309\n",
      "Epoch 3/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.3335 - val_loss: 0.0020 - val_accuracy: 0.3309\n",
      "Epoch 4/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.3352 - val_loss: 0.0020 - val_accuracy: 0.3309\n",
      "Epoch 5/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.3363 - val_loss: 0.0020 - val_accuracy: 0.3309\n",
      "Epoch 6/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 0.3441 - val_loss: 0.0020 - val_accuracy: 0.3309\n",
      "Epoch 7/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.3393 - val_loss: 0.0020 - val_accuracy: 0.3310\n",
      "Epoch 8/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.3417 - val_loss: 0.0020 - val_accuracy: 0.3311\n",
      "Epoch 9/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.3401 - val_loss: 0.0020 - val_accuracy: 0.3314\n",
      "Epoch 10/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 0.3538 - val_loss: 0.0020 - val_accuracy: 0.3318\n",
      "Epoch 11/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.3460 - val_loss: 0.0020 - val_accuracy: 0.3321\n",
      "Epoch 12/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.3455 - val_loss: 0.0020 - val_accuracy: 0.3325\n",
      "Epoch 13/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.3499 - val_loss: 0.0020 - val_accuracy: 0.3330\n",
      "Epoch 14/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.3529 - val_loss: 0.0020 - val_accuracy: 0.3336\n",
      "Epoch 15/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 0.3551 - val_loss: 0.0020 - val_accuracy: 0.3348\n",
      "Epoch 16/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.3580 - val_loss: 0.0020 - val_accuracy: 0.3358\n",
      "Epoch 17/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.3541 - val_loss: 0.0020 - val_accuracy: 0.3381\n",
      "Epoch 18/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.3568 - val_loss: 0.0020 - val_accuracy: 0.3389\n",
      "Epoch 19/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.3627 - val_loss: 0.0020 - val_accuracy: 0.3406\n",
      "Epoch 20/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.3630 - val_loss: 0.0020 - val_accuracy: 0.3421\n",
      "Epoch 21/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.3685 - val_loss: 0.0019 - val_accuracy: 0.3443\n",
      "Epoch 22/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.3681 - val_loss: 0.0019 - val_accuracy: 0.3460\n",
      "Epoch 23/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.3714 - val_loss: 0.0019 - val_accuracy: 0.3487\n",
      "Epoch 24/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.3727 - val_loss: 0.0019 - val_accuracy: 0.3525\n",
      "Epoch 25/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.3720 - val_loss: 0.0019 - val_accuracy: 0.3551\n",
      "Epoch 26/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.3698 - val_loss: 0.0019 - val_accuracy: 0.3579\n",
      "Epoch 27/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.3876 - val_loss: 0.0019 - val_accuracy: 0.3617\n",
      "Epoch 28/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.3878 - val_loss: 0.0019 - val_accuracy: 0.3656\n",
      "Epoch 29/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.3876 - val_loss: 0.0019 - val_accuracy: 0.3704\n",
      "Epoch 30/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.3981 - val_loss: 0.0019 - val_accuracy: 0.3727\n",
      "Epoch 31/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.4065 - val_loss: 0.0019 - val_accuracy: 0.3759\n",
      "Epoch 32/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.3961 - val_loss: 0.0019 - val_accuracy: 0.3805\n",
      "Epoch 33/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4032 - val_loss: 0.0019 - val_accuracy: 0.3838\n",
      "Epoch 34/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.4003 - val_loss: 0.0019 - val_accuracy: 0.3900\n",
      "Epoch 35/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4122 - val_loss: 0.0019 - val_accuracy: 0.3945\n",
      "Epoch 36/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.4211 - val_loss: 0.0019 - val_accuracy: 0.4004\n",
      "Epoch 37/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.4124 - val_loss: 0.0019 - val_accuracy: 0.4038\n",
      "Epoch 38/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.4126 - val_loss: 0.0019 - val_accuracy: 0.4073\n",
      "Epoch 39/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4230 - val_loss: 0.0019 - val_accuracy: 0.4098\n",
      "Epoch 40/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.4377 - val_loss: 0.0019 - val_accuracy: 0.4155\n",
      "Epoch 41/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4268 - val_loss: 0.0019 - val_accuracy: 0.4210\n",
      "Epoch 42/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.4276 - val_loss: 0.0019 - val_accuracy: 0.4260\n",
      "Epoch 43/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.4277 - val_loss: 0.0019 - val_accuracy: 0.4299\n",
      "Epoch 44/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4423 - val_loss: 0.0019 - val_accuracy: 0.4327\n",
      "Epoch 45/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4486 - val_loss: 0.0019 - val_accuracy: 0.4369\n",
      "Epoch 46/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4497 - val_loss: 0.0019 - val_accuracy: 0.4411\n",
      "Epoch 47/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4527 - val_loss: 0.0019 - val_accuracy: 0.4469\n",
      "Epoch 48/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4590 - val_loss: 0.0019 - val_accuracy: 0.4514\n",
      "Epoch 49/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4521 - val_loss: 0.0019 - val_accuracy: 0.4548\n",
      "Epoch 50/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4609 - val_loss: 0.0019 - val_accuracy: 0.4588\n",
      "Epoch 51/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.4617 - val_loss: 0.0019 - val_accuracy: 0.4618\n",
      "Epoch 52/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.4646 - val_loss: 0.0019 - val_accuracy: 0.4646\n",
      "Epoch 53/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.4686 - val_loss: 0.0019 - val_accuracy: 0.4661\n",
      "Epoch 54/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4738 - val_loss: 0.0019 - val_accuracy: 0.4714\n",
      "Epoch 55/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.4669 - val_loss: 0.0019 - val_accuracy: 0.4758\n",
      "Epoch 56/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.4798 - val_loss: 0.0019 - val_accuracy: 0.4775\n",
      "Epoch 57/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4772 - val_loss: 0.0019 - val_accuracy: 0.4812\n",
      "Epoch 58/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.4813 - val_loss: 0.0019 - val_accuracy: 0.4839\n",
      "Epoch 59/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4799 - val_loss: 0.0019 - val_accuracy: 0.4856\n",
      "Epoch 60/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4824 - val_loss: 0.0019 - val_accuracy: 0.4884\n",
      "Epoch 61/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4795 - val_loss: 0.0019 - val_accuracy: 0.4937\n",
      "Epoch 62/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4925 - val_loss: 0.0019 - val_accuracy: 0.4950\n",
      "Epoch 63/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4881 - val_loss: 0.0019 - val_accuracy: 0.5012\n",
      "Epoch 64/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.5009 - val_loss: 0.0019 - val_accuracy: 0.5018\n",
      "Epoch 65/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.4954 - val_loss: 0.0019 - val_accuracy: 0.5066\n",
      "Epoch 66/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.5033 - val_loss: 0.0019 - val_accuracy: 0.5102\n",
      "Epoch 67/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.5074 - val_loss: 0.0019 - val_accuracy: 0.5130\n",
      "Epoch 68/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5129 - val_loss: 0.0019 - val_accuracy: 0.5142\n",
      "Epoch 69/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.5062 - val_loss: 0.0019 - val_accuracy: 0.5179\n",
      "Epoch 70/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5217 - val_loss: 0.0019 - val_accuracy: 0.5193\n",
      "Epoch 71/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.5188 - val_loss: 0.0019 - val_accuracy: 0.5206\n",
      "Epoch 72/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.5257 - val_loss: 0.0019 - val_accuracy: 0.5235\n",
      "Epoch 73/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.5159 - val_loss: 0.0019 - val_accuracy: 0.5259\n",
      "Epoch 74/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.5268 - val_loss: 0.0019 - val_accuracy: 0.5273\n",
      "Epoch 75/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.5251 - val_loss: 0.0019 - val_accuracy: 0.5295\n",
      "Epoch 76/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.5178 - val_loss: 0.0018 - val_accuracy: 0.5333\n",
      "Epoch 77/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.5266 - val_loss: 0.0018 - val_accuracy: 0.5353\n",
      "Epoch 78/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.5300 - val_loss: 0.0018 - val_accuracy: 0.5387\n",
      "Epoch 79/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.5301 - val_loss: 0.0018 - val_accuracy: 0.5414\n",
      "Epoch 80/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.5438 - val_loss: 0.0018 - val_accuracy: 0.5447\n",
      "Epoch 81/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.5322 - val_loss: 0.0018 - val_accuracy: 0.5466\n",
      "Epoch 82/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5347 - val_loss: 0.0018 - val_accuracy: 0.5478\n",
      "Epoch 83/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.5375 - val_loss: 0.0018 - val_accuracy: 0.5480\n",
      "Epoch 84/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5406 - val_loss: 0.0018 - val_accuracy: 0.5527\n",
      "Epoch 85/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5362 - val_loss: 0.0018 - val_accuracy: 0.5541\n",
      "Epoch 86/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5438 - val_loss: 0.0018 - val_accuracy: 0.5569\n",
      "Epoch 87/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5473 - val_loss: 0.0018 - val_accuracy: 0.5603\n",
      "Epoch 88/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5497 - val_loss: 0.0018 - val_accuracy: 0.5605\n",
      "Epoch 89/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5489 - val_loss: 0.0018 - val_accuracy: 0.5638\n",
      "Epoch 90/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.5468 - val_loss: 0.0018 - val_accuracy: 0.5655\n",
      "Epoch 91/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.5560 - val_loss: 0.0018 - val_accuracy: 0.5675\n",
      "Epoch 92/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5556 - val_loss: 0.0018 - val_accuracy: 0.5679\n",
      "Epoch 93/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.5564 - val_loss: 0.0018 - val_accuracy: 0.5682\n",
      "Epoch 94/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5562 - val_loss: 0.0018 - val_accuracy: 0.5713\n",
      "Epoch 95/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.5687 - val_loss: 0.0018 - val_accuracy: 0.5754\n",
      "Epoch 96/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5692 - val_loss: 0.0018 - val_accuracy: 0.5758\n",
      "Epoch 97/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5677 - val_loss: 0.0018 - val_accuracy: 0.5778\n",
      "Epoch 98/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.5631 - val_loss: 0.0018 - val_accuracy: 0.5804\n",
      "Epoch 99/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.5665 - val_loss: 0.0018 - val_accuracy: 0.5800\n",
      "Epoch 100/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5737 - val_loss: 0.0018 - val_accuracy: 0.5829\n",
      "Epoch 101/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5736 - val_loss: 0.0018 - val_accuracy: 0.5815\n",
      "Epoch 102/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5730 - val_loss: 0.0018 - val_accuracy: 0.5834\n",
      "Epoch 103/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5726 - val_loss: 0.0018 - val_accuracy: 0.5845\n",
      "Epoch 104/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5739 - val_loss: 0.0018 - val_accuracy: 0.5846\n",
      "Epoch 105/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5734 - val_loss: 0.0018 - val_accuracy: 0.5868\n",
      "Epoch 106/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5734 - val_loss: 0.0018 - val_accuracy: 0.5866\n",
      "Epoch 107/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.5692 - val_loss: 0.0018 - val_accuracy: 0.5888\n",
      "Epoch 108/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5840 - val_loss: 0.0018 - val_accuracy: 0.5911\n",
      "Epoch 109/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.5778 - val_loss: 0.0018 - val_accuracy: 0.5920\n",
      "Epoch 110/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5888 - val_loss: 0.0018 - val_accuracy: 0.5926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5807 - val_loss: 0.0018 - val_accuracy: 0.5941\n",
      "Epoch 112/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5884 - val_loss: 0.0018 - val_accuracy: 0.5950\n",
      "Epoch 113/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5878 - val_loss: 0.0018 - val_accuracy: 0.5964\n",
      "Epoch 114/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.5897 - val_loss: 0.0018 - val_accuracy: 0.5967\n",
      "Epoch 115/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.5886 - val_loss: 0.0018 - val_accuracy: 0.5995\n",
      "Epoch 116/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5845 - val_loss: 0.0018 - val_accuracy: 0.5992\n",
      "Epoch 117/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.5847 - val_loss: 0.0017 - val_accuracy: 0.5998\n",
      "Epoch 118/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.5896 - val_loss: 0.0017 - val_accuracy: 0.6004\n",
      "Epoch 119/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.6020 - val_loss: 0.0017 - val_accuracy: 0.6023\n",
      "Epoch 120/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5942 - val_loss: 0.0017 - val_accuracy: 0.6032\n",
      "Epoch 121/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.5968 - val_loss: 0.0017 - val_accuracy: 0.6031\n",
      "Epoch 122/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5972 - val_loss: 0.0017 - val_accuracy: 0.6020\n",
      "Epoch 123/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.6015 - val_loss: 0.0017 - val_accuracy: 0.6037\n",
      "Epoch 124/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5889 - val_loss: 0.0017 - val_accuracy: 0.6050\n",
      "Epoch 125/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.5989 - val_loss: 0.0017 - val_accuracy: 0.6041\n",
      "Epoch 126/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.5923 - val_loss: 0.0017 - val_accuracy: 0.6038\n",
      "Epoch 127/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.5976 - val_loss: 0.0017 - val_accuracy: 0.6044\n",
      "Epoch 128/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6000 - val_loss: 0.0017 - val_accuracy: 0.6052\n",
      "Epoch 129/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.6025 - val_loss: 0.0017 - val_accuracy: 0.6071\n",
      "Epoch 130/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.6030 - val_loss: 0.0017 - val_accuracy: 0.6060\n",
      "Epoch 131/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.6026 - val_loss: 0.0017 - val_accuracy: 0.6095\n",
      "Epoch 132/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6054 - val_loss: 0.0017 - val_accuracy: 0.6090\n",
      "Epoch 133/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.6010 - val_loss: 0.0017 - val_accuracy: 0.6108\n",
      "Epoch 134/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6073 - val_loss: 0.0017 - val_accuracy: 0.6104\n",
      "Epoch 135/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6065 - val_loss: 0.0017 - val_accuracy: 0.6113\n",
      "Epoch 136/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6006 - val_loss: 0.0017 - val_accuracy: 0.6106\n",
      "Epoch 137/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6041 - val_loss: 0.0017 - val_accuracy: 0.6107\n",
      "Epoch 138/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6120 - val_loss: 0.0017 - val_accuracy: 0.6121\n",
      "Epoch 139/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6122 - val_loss: 0.0017 - val_accuracy: 0.6121\n",
      "Epoch 140/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.6097 - val_loss: 0.0017 - val_accuracy: 0.6122\n",
      "Epoch 141/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6131 - val_loss: 0.0017 - val_accuracy: 0.6118\n",
      "Epoch 142/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.6069 - val_loss: 0.0017 - val_accuracy: 0.6125\n",
      "Epoch 143/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6117 - val_loss: 0.0017 - val_accuracy: 0.6123\n",
      "Epoch 144/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.6065 - val_loss: 0.0017 - val_accuracy: 0.6131\n",
      "Epoch 145/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.6146 - val_loss: 0.0017 - val_accuracy: 0.6134\n",
      "Epoch 146/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6088 - val_loss: 0.0017 - val_accuracy: 0.6138\n",
      "Epoch 147/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6071 - val_loss: 0.0017 - val_accuracy: 0.6141\n",
      "Epoch 148/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6172 - val_loss: 0.0017 - val_accuracy: 0.6148\n",
      "Epoch 149/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6100 - val_loss: 0.0017 - val_accuracy: 0.6162\n",
      "Epoch 150/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6119 - val_loss: 0.0017 - val_accuracy: 0.6167\n",
      "Epoch 151/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6154 - val_loss: 0.0017 - val_accuracy: 0.6168\n",
      "Epoch 152/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6105 - val_loss: 0.0017 - val_accuracy: 0.6181\n",
      "Epoch 153/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6086 - val_loss: 0.0017 - val_accuracy: 0.6190\n",
      "Epoch 154/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.6129 - val_loss: 0.0017 - val_accuracy: 0.6182\n",
      "Epoch 155/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6125 - val_loss: 0.0017 - val_accuracy: 0.6183\n",
      "Epoch 156/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6080 - val_loss: 0.0017 - val_accuracy: 0.6194\n",
      "Epoch 157/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6174 - val_loss: 0.0017 - val_accuracy: 0.6202\n",
      "Epoch 158/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6145 - val_loss: 0.0017 - val_accuracy: 0.6210\n",
      "Epoch 159/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6097 - val_loss: 0.0017 - val_accuracy: 0.6223\n",
      "Epoch 160/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.6149 - val_loss: 0.0017 - val_accuracy: 0.6225\n",
      "Epoch 161/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6193 - val_loss: 0.0017 - val_accuracy: 0.6230\n",
      "Epoch 162/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6098 - val_loss: 0.0017 - val_accuracy: 0.6225\n",
      "Epoch 163/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6214 - val_loss: 0.0017 - val_accuracy: 0.6229\n",
      "Epoch 164/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6119 - val_loss: 0.0017 - val_accuracy: 0.6232\n",
      "Epoch 165/10000\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.61 - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6169 - val_loss: 0.0017 - val_accuracy: 0.6216\n",
      "Epoch 166/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6163 - val_loss: 0.0017 - val_accuracy: 0.6231\n",
      "Epoch 167/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6139 - val_loss: 0.0017 - val_accuracy: 0.6234\n",
      "Epoch 168/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6158 - val_loss: 0.0017 - val_accuracy: 0.6244\n",
      "Epoch 169/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.6152 - val_loss: 0.0017 - val_accuracy: 0.6243\n",
      "Epoch 170/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6165 - val_loss: 0.0017 - val_accuracy: 0.6249\n",
      "Epoch 171/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.6249 - val_loss: 0.0017 - val_accuracy: 0.6249\n",
      "Epoch 172/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6220 - val_loss: 0.0017 - val_accuracy: 0.6245\n",
      "Epoch 173/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6173 - val_loss: 0.0017 - val_accuracy: 0.6248\n",
      "Epoch 174/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6217 - val_loss: 0.0017 - val_accuracy: 0.6246\n",
      "Epoch 175/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.6178 - val_loss: 0.0016 - val_accuracy: 0.6248\n",
      "Epoch 176/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6072 - val_loss: 0.0016 - val_accuracy: 0.6247\n",
      "Epoch 177/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6237 - val_loss: 0.0016 - val_accuracy: 0.6251\n",
      "Epoch 178/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6169 - val_loss: 0.0016 - val_accuracy: 0.6261\n",
      "Epoch 179/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6183 - val_loss: 0.0016 - val_accuracy: 0.6263\n",
      "Epoch 180/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6151 - val_loss: 0.0016 - val_accuracy: 0.6258\n",
      "Epoch 181/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6249 - val_loss: 0.0016 - val_accuracy: 0.6277\n",
      "Epoch 182/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.6193 - val_loss: 0.0016 - val_accuracy: 0.6283\n",
      "Epoch 183/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.6239 - val_loss: 0.0016 - val_accuracy: 0.6288\n",
      "Epoch 184/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.6224 - val_loss: 0.0016 - val_accuracy: 0.6277\n",
      "Epoch 185/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6258 - val_loss: 0.0016 - val_accuracy: 0.6276\n",
      "Epoch 186/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.6186 - val_loss: 0.0016 - val_accuracy: 0.6276\n",
      "Epoch 187/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6244 - val_loss: 0.0016 - val_accuracy: 0.6286\n",
      "Epoch 188/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6228 - val_loss: 0.0016 - val_accuracy: 0.6290\n",
      "Epoch 189/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6274 - val_loss: 0.0016 - val_accuracy: 0.6298\n",
      "Epoch 190/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.6226 - val_loss: 0.0016 - val_accuracy: 0.6291\n",
      "Epoch 191/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.6223 - val_loss: 0.0016 - val_accuracy: 0.6293\n",
      "Epoch 192/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6199 - val_loss: 0.0016 - val_accuracy: 0.6296\n",
      "Epoch 193/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6239 - val_loss: 0.0016 - val_accuracy: 0.6281\n",
      "Epoch 194/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6262 - val_loss: 0.0016 - val_accuracy: 0.6299\n",
      "Epoch 195/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6289 - val_loss: 0.0016 - val_accuracy: 0.6290\n",
      "Epoch 196/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6168 - val_loss: 0.0016 - val_accuracy: 0.6284\n",
      "Epoch 197/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6264 - val_loss: 0.0016 - val_accuracy: 0.6281\n",
      "Epoch 198/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6191 - val_loss: 0.0016 - val_accuracy: 0.6295\n",
      "Epoch 199/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.6168 - val_loss: 0.0016 - val_accuracy: 0.6306\n",
      "Epoch 200/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.6333 - val_loss: 0.0016 - val_accuracy: 0.6304\n",
      "Epoch 201/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.6261 - val_loss: 0.0016 - val_accuracy: 0.6301\n",
      "Epoch 202/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6274 - val_loss: 0.0016 - val_accuracy: 0.6292\n",
      "Epoch 203/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6154 - val_loss: 0.0016 - val_accuracy: 0.6304\n",
      "Epoch 204/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6319 - val_loss: 0.0016 - val_accuracy: 0.6311\n",
      "Epoch 205/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6290 - val_loss: 0.0016 - val_accuracy: 0.6310\n",
      "Epoch 206/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6231 - val_loss: 0.0016 - val_accuracy: 0.6323\n",
      "Epoch 207/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6268 - val_loss: 0.0016 - val_accuracy: 0.6328\n",
      "Epoch 208/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6279 - val_loss: 0.0016 - val_accuracy: 0.6339\n",
      "Epoch 209/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6319 - val_loss: 0.0016 - val_accuracy: 0.6325\n",
      "Epoch 210/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6269 - val_loss: 0.0016 - val_accuracy: 0.6324\n",
      "Epoch 211/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.6294 - val_loss: 0.0016 - val_accuracy: 0.6332\n",
      "Epoch 212/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6284 - val_loss: 0.0016 - val_accuracy: 0.6328\n",
      "Epoch 213/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.6238 - val_loss: 0.0016 - val_accuracy: 0.6332\n",
      "Epoch 214/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.6228 - val_loss: 0.0016 - val_accuracy: 0.6329\n",
      "Epoch 215/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6372 - val_loss: 0.0016 - val_accuracy: 0.6325\n",
      "Epoch 216/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.6242 - val_loss: 0.0016 - val_accuracy: 0.6326\n",
      "Epoch 217/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6338 - val_loss: 0.0016 - val_accuracy: 0.6316\n",
      "Epoch 218/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6304 - val_loss: 0.0016 - val_accuracy: 0.6316\n",
      "Epoch 219/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6258 - val_loss: 0.0016 - val_accuracy: 0.6321\n",
      "Epoch 220/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6272 - val_loss: 0.0016 - val_accuracy: 0.6334\n",
      "Epoch 221/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6304 - val_loss: 0.0016 - val_accuracy: 0.6326\n",
      "Epoch 222/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6381 - val_loss: 0.0016 - val_accuracy: 0.6331\n",
      "Epoch 223/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6309 - val_loss: 0.0016 - val_accuracy: 0.6336\n",
      "Epoch 224/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6285 - val_loss: 0.0016 - val_accuracy: 0.6333\n",
      "Epoch 225/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.6342 - val_loss: 0.0016 - val_accuracy: 0.6337\n",
      "Epoch 226/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6299 - val_loss: 0.0016 - val_accuracy: 0.6345\n",
      "Epoch 227/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6305 - val_loss: 0.0016 - val_accuracy: 0.6352\n",
      "Epoch 228/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6356 - val_loss: 0.0016 - val_accuracy: 0.6350\n",
      "Epoch 229/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6271 - val_loss: 0.0016 - val_accuracy: 0.6354\n",
      "Epoch 230/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6297 - val_loss: 0.0016 - val_accuracy: 0.6346\n",
      "Epoch 231/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6317 - val_loss: 0.0016 - val_accuracy: 0.6354\n",
      "Epoch 232/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.6335 - val_loss: 0.0016 - val_accuracy: 0.6355\n",
      "Epoch 233/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.6325 - val_loss: 0.0016 - val_accuracy: 0.6358\n",
      "Epoch 234/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6287 - val_loss: 0.0016 - val_accuracy: 0.6351\n",
      "Epoch 235/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6312 - val_loss: 0.0016 - val_accuracy: 0.6355\n",
      "Epoch 236/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6277 - val_loss: 0.0016 - val_accuracy: 0.6361\n",
      "Epoch 237/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6323 - val_loss: 0.0016 - val_accuracy: 0.6354\n",
      "Epoch 238/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6316 - val_loss: 0.0016 - val_accuracy: 0.6357\n",
      "Epoch 239/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6375 - val_loss: 0.0016 - val_accuracy: 0.6357\n",
      "Epoch 240/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6231 - val_loss: 0.0016 - val_accuracy: 0.6361\n",
      "Epoch 241/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.6337 - val_loss: 0.0016 - val_accuracy: 0.6360\n",
      "Epoch 242/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6314 - val_loss: 0.0016 - val_accuracy: 0.6360\n",
      "Epoch 243/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6268 - val_loss: 0.0016 - val_accuracy: 0.6360\n",
      "Epoch 244/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6230 - val_loss: 0.0016 - val_accuracy: 0.6354\n",
      "Epoch 245/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6268 - val_loss: 0.0016 - val_accuracy: 0.6356\n",
      "Epoch 246/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.6324 - val_loss: 0.0016 - val_accuracy: 0.6360\n",
      "Epoch 247/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6307 - val_loss: 0.0016 - val_accuracy: 0.6371\n",
      "Epoch 248/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6259 - val_loss: 0.0016 - val_accuracy: 0.6371\n",
      "Epoch 249/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6353 - val_loss: 0.0016 - val_accuracy: 0.6368\n",
      "Epoch 250/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6289 - val_loss: 0.0016 - val_accuracy: 0.6371\n",
      "Epoch 251/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6339 - val_loss: 0.0016 - val_accuracy: 0.6369\n",
      "Epoch 252/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6350 - val_loss: 0.0016 - val_accuracy: 0.6372\n",
      "Epoch 253/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.6250 - val_loss: 0.0016 - val_accuracy: 0.6372\n",
      "Epoch 254/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6316 - val_loss: 0.0016 - val_accuracy: 0.6373\n",
      "Epoch 255/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6381 - val_loss: 0.0016 - val_accuracy: 0.6371\n",
      "Epoch 256/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6327 - val_loss: 0.0016 - val_accuracy: 0.6370\n",
      "Epoch 257/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6314 - val_loss: 0.0016 - val_accuracy: 0.6373\n",
      "Epoch 258/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6319 - val_loss: 0.0016 - val_accuracy: 0.6379\n",
      "Epoch 259/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6352 - val_loss: 0.0016 - val_accuracy: 0.6381\n",
      "Epoch 260/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.6338 - val_loss: 0.0016 - val_accuracy: 0.6375\n",
      "Epoch 261/10000\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.6419 - val_loss: 0.0016 - val_accuracy: 0.6391\n",
      "Epoch 262/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.6351 - val_loss: 0.0016 - val_accuracy: 0.6381\n",
      "Epoch 263/10000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.6321 - val_loss: 0.0016 - val_accuracy: 0.6385\n",
      "Epoch 264/10000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0016 - accuracy: 0.6426"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10000\n",
    "patience = 500\n",
    "batch_size = 512\n",
    "num_nodes = 64\n",
    "dropout = 0.1\n",
    "learn_rate = 1e-5\n",
    "\n",
    "for i, train_feats in enumerate(combined_train_feat_sets):\n",
    "    model_dir = 'models/SR_4l_DF_models/'\n",
    "    model_name = 'classifier_train_feat_test_' + str(i)\n",
    "    \n",
    "    print('Running with training features:', train_feats)\n",
    "    # Save training setup\n",
    "    with open(model_dir + model_name + '_setup.txt', 'w') as file:\n",
    "        file.write('Epochs: ' + str(EPOCHS) + '\\n')\n",
    "        file.write('Patience: ' + str(patience) + '\\n')\n",
    "        file.write('Learning rate: ' + str(learn_rate) + '\\n')\n",
    "        file.write('Batch size: ' + str(batch_size) + '\\n\\n')\n",
    "        file.write('Training features:\\n' + '\\n'.join(train_feats))\n",
    "    \n",
    "    # Generate train and test samples\n",
    "    sig_train, sig_test = train_test_split(sig[train_feats + ['wgt']], train_size=0.5, random_state=314)\n",
    "    bg_train, bg_test = train_test_split(bg[train_feats + ['wgt']], train_size=0.5, random_state=314)\n",
    "\n",
    "    n_sig = sum(sig_train.wgt)\n",
    "    n_bg = sum(bg_train.wgt)\n",
    "\n",
    "    x_train_sig = sig_train[train_feats]\n",
    "    x_train_bg = bg_train[train_feats]\n",
    "\n",
    "    x_train = pd.concat([x_train_sig, x_train_bg])\n",
    "    y_train = np.concatenate([np.ones(len(sig_train)), np.zeros(len(bg_train))])\n",
    "    w_train = pd.Series(np.concatenate([(n_sig + n_bg) / n_sig * sig_train['wgt'], \n",
    "                                        (n_sig + n_bg) / n_bg * bg_train['wgt']]))\n",
    "\n",
    "    n_sig_test = sum(sig_test.wgt)\n",
    "    n_bg_test = sum(bg_test.wgt)\n",
    "\n",
    "    x_test = pd.concat([sig_test[train_feats], bg_test[train_feats]])\n",
    "    y_test = np.concatenate([np.ones(len(sig_test)), np.zeros(len(bg_test))])\n",
    "    w_test = pd.Series(np.concatenate([(n_sig_test + n_bg_test) / n_sig_test * sig_test['wgt'], \n",
    "                                       (n_sig_test + n_bg_test) / n_bg_test * bg_test['wgt']]))\n",
    "    \n",
    "    # Generate and fit model\n",
    "    K.clear_session()\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(num_nodes, input_dim=x_train.shape[1], activation='relu')) \n",
    "    classifier.add(Dropout(dropout))\n",
    "    classifier.add(Dense(num_nodes, activation='relu'))\n",
    "    classifier.add(Dropout(dropout))\n",
    "    classifier.add(Dense(num_nodes, activation='relu'))\n",
    "    classifier.add(Dropout(dropout))\n",
    "    classifier.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=learn_rate)\n",
    "    classifier.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    # Early stopping\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "\n",
    "    history = classifier.fit(x_train, y_train, epochs=EPOCHS, batch_size=batch_size,\n",
    "                             validation_data=(x_test, y_test, w_test), sample_weight=w_train, \n",
    "                             verbose=1, callbacks=[callback], shuffle=True)\n",
    "    \n",
    "    # Save model and history\n",
    "    classifier.save(model_dir + model_name)\n",
    "    with open(model_dir + model_name + '_history.pkl', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data\n",
    "sig_train, sig_test = train_test_split(sig[combined_train_feats + ['wgt', 'abs_wgt']], train_size=0.5)\n",
    "bg_train, bg_test = train_test_split(bg[combined_train_feats + ['wgt', 'abs_wgt']], train_size=0.5)\n",
    "\n",
    "n_sig = sum(sig_train.wgt)\n",
    "n_bg = sum(bg_train.wgt)\n",
    "\n",
    "x_train_sig = pd.concat([sig_train[combined_train_feats]])\n",
    "x_train_bg = bg_train[combined_train_feats]\n",
    "\n",
    "x_train = pd.concat([x_train_sig, x_train_bg])\n",
    "y_train = np.concatenate([np.ones(len(sig_train))] + [np.zeros(len(bg_train))])\n",
    "w_train = pd.Series(np.concatenate([(n_sig + n_bg) / n_sig * sig_train['abs_wgt'], \n",
    "                                    (n_sig + n_bg) / n_bg * bg_train['abs_wgt']]))\n",
    "# w_train = pd.Series(np.concatenate([sig_train['wgt']]*n_sig_copies + [bg_train['wgt']]))\n",
    "\n",
    "n_sig_test = sum(sig_test.wgt)\n",
    "n_bg_test = sum(bg_test.wgt)\n",
    "\n",
    "x_test = pd.concat([sig_test[combined_train_feats], bg_test[combined_train_feats]])\n",
    "y_test = np.concatenate([np.ones(len(sig_test)), np.zeros(len(bg_test))])\n",
    "w_test = pd.Series(np.concatenate([(n_sig_test + n_bg_test) / n_sig_test * sig_test['abs_wgt'], \n",
    "                                   (n_sig_test + n_bg_test) / n_bg_test * bg_test['abs_wgt']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "233/233 [==============================] - 2s 6ms/step - loss: 0.0027 - accuracy: 0.3298 - val_loss: 0.0027 - val_accuracy: 0.7700\n",
      "Epoch 2/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.6858 - val_loss: 0.0027 - val_accuracy: 0.9414\n",
      "Epoch 3/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.8669 - val_loss: 0.0026 - val_accuracy: 0.9457\n",
      "Epoch 4/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9161 - val_loss: 0.0026 - val_accuracy: 0.9458\n",
      "Epoch 5/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9312 - val_loss: 0.0026 - val_accuracy: 0.9459\n",
      "Epoch 6/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9356 - val_loss: 0.0026 - val_accuracy: 0.9458\n",
      "Epoch 7/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9379 - val_loss: 0.0025 - val_accuracy: 0.9458\n",
      "Epoch 8/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9339 - val_loss: 0.0025 - val_accuracy: 0.9455\n",
      "Epoch 9/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9326 - val_loss: 0.0025 - val_accuracy: 0.9444\n",
      "Epoch 10/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9285 - val_loss: 0.0025 - val_accuracy: 0.9414\n",
      "Epoch 11/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9188 - val_loss: 0.0024 - val_accuracy: 0.9353\n",
      "Epoch 12/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.9101 - val_loss: 0.0024 - val_accuracy: 0.9233\n",
      "Epoch 13/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.8930 - val_loss: 0.0024 - val_accuracy: 0.9084\n",
      "Epoch 14/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.8745 - val_loss: 0.0023 - val_accuracy: 0.8956\n",
      "Epoch 15/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.8684 - val_loss: 0.0023 - val_accuracy: 0.8702\n",
      "Epoch 16/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.8466 - val_loss: 0.0023 - val_accuracy: 0.8515\n",
      "Epoch 17/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.8366 - val_loss: 0.0022 - val_accuracy: 0.8297\n",
      "Epoch 18/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 0.8237 - val_loss: 0.0022 - val_accuracy: 0.8008\n",
      "Epoch 19/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0022 - accuracy: 0.8025 - val_loss: 0.0022 - val_accuracy: 0.7888\n",
      "Epoch 20/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0022 - accuracy: 0.7888 - val_loss: 0.0021 - val_accuracy: 0.7710\n",
      "Epoch 21/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 0.7746 - val_loss: 0.0021 - val_accuracy: 0.7580\n",
      "Epoch 22/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 0.7640 - val_loss: 0.0021 - val_accuracy: 0.7396\n",
      "Epoch 23/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 0.7548 - val_loss: 0.0021 - val_accuracy: 0.7341\n",
      "Epoch 24/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 0.7484 - val_loss: 0.0020 - val_accuracy: 0.7213\n",
      "Epoch 25/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7461 - val_loss: 0.0020 - val_accuracy: 0.7045\n",
      "Epoch 26/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7287 - val_loss: 0.0020 - val_accuracy: 0.7009\n",
      "Epoch 27/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7311 - val_loss: 0.0020 - val_accuracy: 0.6889\n",
      "Epoch 28/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7180 - val_loss: 0.0020 - val_accuracy: 0.6840\n",
      "Epoch 29/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7129 - val_loss: 0.0020 - val_accuracy: 0.6822\n",
      "Epoch 30/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7097 - val_loss: 0.0020 - val_accuracy: 0.6858\n",
      "Epoch 31/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7111 - val_loss: 0.0020 - val_accuracy: 0.6854\n",
      "Epoch 32/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7110 - val_loss: 0.0019 - val_accuracy: 0.6795\n",
      "Epoch 33/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7015 - val_loss: 0.0019 - val_accuracy: 0.6764\n",
      "Epoch 34/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7083 - val_loss: 0.0019 - val_accuracy: 0.6748\n",
      "Epoch 35/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7002 - val_loss: 0.0019 - val_accuracy: 0.6737\n",
      "Epoch 36/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7019 - val_loss: 0.0019 - val_accuracy: 0.6705\n",
      "Epoch 37/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7025 - val_loss: 0.0019 - val_accuracy: 0.6765\n",
      "Epoch 38/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7056 - val_loss: 0.0019 - val_accuracy: 0.6744\n",
      "Epoch 39/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7003 - val_loss: 0.0019 - val_accuracy: 0.6693\n",
      "Epoch 40/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6964 - val_loss: 0.0019 - val_accuracy: 0.6721\n",
      "Epoch 41/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6970 - val_loss: 0.0019 - val_accuracy: 0.6764\n",
      "Epoch 42/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6972 - val_loss: 0.0019 - val_accuracy: 0.6695\n",
      "Epoch 43/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6990 - val_loss: 0.0019 - val_accuracy: 0.6741\n",
      "Epoch 44/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6958 - val_loss: 0.0019 - val_accuracy: 0.6750\n",
      "Epoch 45/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6988 - val_loss: 0.0019 - val_accuracy: 0.6783\n",
      "Epoch 46/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.6978 - val_loss: 0.0019 - val_accuracy: 0.6802\n",
      "Epoch 47/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7021 - val_loss: 0.0019 - val_accuracy: 0.6732\n",
      "Epoch 48/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.6978 - val_loss: 0.0019 - val_accuracy: 0.6699\n",
      "Epoch 49/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6956 - val_loss: 0.0019 - val_accuracy: 0.6775\n",
      "Epoch 50/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6951 - val_loss: 0.0019 - val_accuracy: 0.6795\n",
      "Epoch 51/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7039 - val_loss: 0.0019 - val_accuracy: 0.6697\n",
      "Epoch 52/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6956 - val_loss: 0.0019 - val_accuracy: 0.6729\n",
      "Epoch 53/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6982 - val_loss: 0.0019 - val_accuracy: 0.6703\n",
      "Epoch 54/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6966 - val_loss: 0.0019 - val_accuracy: 0.6744\n",
      "Epoch 55/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6945 - val_loss: 0.0019 - val_accuracy: 0.6730\n",
      "Epoch 56/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7021 - val_loss: 0.0019 - val_accuracy: 0.6700\n",
      "Epoch 57/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6947 - val_loss: 0.0019 - val_accuracy: 0.6752\n",
      "Epoch 58/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.6968 - val_loss: 0.0019 - val_accuracy: 0.6768\n",
      "Epoch 59/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6947 - val_loss: 0.0019 - val_accuracy: 0.6777\n",
      "Epoch 60/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6960 - val_loss: 0.0019 - val_accuracy: 0.6765\n",
      "Epoch 61/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6941 - val_loss: 0.0019 - val_accuracy: 0.6793\n",
      "Epoch 62/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6993 - val_loss: 0.0019 - val_accuracy: 0.6782\n",
      "Epoch 63/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6980 - val_loss: 0.0019 - val_accuracy: 0.6782\n",
      "Epoch 64/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7015 - val_loss: 0.0019 - val_accuracy: 0.6781\n",
      "Epoch 65/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6984 - val_loss: 0.0019 - val_accuracy: 0.6807\n",
      "Epoch 66/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6986 - val_loss: 0.0019 - val_accuracy: 0.6778\n",
      "Epoch 67/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.6974 - val_loss: 0.0019 - val_accuracy: 0.6809\n",
      "Epoch 68/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6961 - val_loss: 0.0019 - val_accuracy: 0.6842\n",
      "Epoch 69/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7031 - val_loss: 0.0019 - val_accuracy: 0.6756\n",
      "Epoch 70/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6929 - val_loss: 0.0019 - val_accuracy: 0.6791\n",
      "Epoch 71/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6969 - val_loss: 0.0019 - val_accuracy: 0.6842\n",
      "Epoch 72/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7007 - val_loss: 0.0019 - val_accuracy: 0.6812\n",
      "Epoch 73/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6974 - val_loss: 0.0019 - val_accuracy: 0.6879\n",
      "Epoch 74/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7026 - val_loss: 0.0019 - val_accuracy: 0.6817\n",
      "Epoch 75/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6971 - val_loss: 0.0019 - val_accuracy: 0.6880\n",
      "Epoch 76/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7031 - val_loss: 0.0019 - val_accuracy: 0.6845\n",
      "Epoch 77/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7003 - val_loss: 0.0019 - val_accuracy: 0.6802\n",
      "Epoch 78/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6958 - val_loss: 0.0019 - val_accuracy: 0.6877\n",
      "Epoch 79/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7029 - val_loss: 0.0019 - val_accuracy: 0.6787\n",
      "Epoch 80/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6999 - val_loss: 0.0019 - val_accuracy: 0.6846\n",
      "Epoch 81/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.6998 - val_loss: 0.0018 - val_accuracy: 0.6856\n",
      "Epoch 82/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7018 - val_loss: 0.0018 - val_accuracy: 0.6861\n",
      "Epoch 83/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7054 - val_loss: 0.0018 - val_accuracy: 0.6863\n",
      "Epoch 84/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7020 - val_loss: 0.0018 - val_accuracy: 0.6855\n",
      "Epoch 85/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7056 - val_loss: 0.0018 - val_accuracy: 0.6884\n",
      "Epoch 86/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7017 - val_loss: 0.0018 - val_accuracy: 0.6925\n",
      "Epoch 87/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7058 - val_loss: 0.0018 - val_accuracy: 0.6884\n",
      "Epoch 88/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7024 - val_loss: 0.0018 - val_accuracy: 0.6900\n",
      "Epoch 89/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7041 - val_loss: 0.0018 - val_accuracy: 0.6935\n",
      "Epoch 90/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7142 - val_loss: 0.0018 - val_accuracy: 0.6823\n",
      "Epoch 91/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.6972 - val_loss: 0.0018 - val_accuracy: 0.6885\n",
      "Epoch 92/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7048 - val_loss: 0.0018 - val_accuracy: 0.6866\n",
      "Epoch 93/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.6998 - val_loss: 0.0018 - val_accuracy: 0.6917\n",
      "Epoch 94/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7026 - val_loss: 0.0018 - val_accuracy: 0.6966\n",
      "Epoch 95/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7057 - val_loss: 0.0018 - val_accuracy: 0.6899\n",
      "Epoch 96/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7045 - val_loss: 0.0018 - val_accuracy: 0.6856\n",
      "Epoch 97/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7032 - val_loss: 0.0018 - val_accuracy: 0.6874\n",
      "Epoch 98/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6997 - val_loss: 0.0018 - val_accuracy: 0.6948\n",
      "Epoch 99/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7038 - val_loss: 0.0018 - val_accuracy: 0.6948\n",
      "Epoch 100/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7065 - val_loss: 0.0018 - val_accuracy: 0.6907\n",
      "Epoch 101/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7011 - val_loss: 0.0018 - val_accuracy: 0.6952\n",
      "Epoch 102/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7053 - val_loss: 0.0018 - val_accuracy: 0.6983\n",
      "Epoch 103/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7122 - val_loss: 0.0018 - val_accuracy: 0.6926\n",
      "Epoch 104/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7095 - val_loss: 0.0018 - val_accuracy: 0.6896\n",
      "Epoch 105/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7051 - val_loss: 0.0018 - val_accuracy: 0.6924\n",
      "Epoch 106/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7042 - val_loss: 0.0018 - val_accuracy: 0.6962\n",
      "Epoch 107/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7089 - val_loss: 0.0018 - val_accuracy: 0.6991\n",
      "Epoch 108/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7092 - val_loss: 0.0018 - val_accuracy: 0.6949\n",
      "Epoch 109/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7062 - val_loss: 0.0018 - val_accuracy: 0.7017\n",
      "Epoch 110/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7096 - val_loss: 0.0018 - val_accuracy: 0.6971\n",
      "Epoch 111/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7085 - val_loss: 0.0018 - val_accuracy: 0.7016\n",
      "Epoch 112/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7108 - val_loss: 0.0018 - val_accuracy: 0.6985\n",
      "Epoch 113/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7082 - val_loss: 0.0018 - val_accuracy: 0.6976\n",
      "Epoch 114/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7090 - val_loss: 0.0018 - val_accuracy: 0.7031\n",
      "Epoch 115/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7148 - val_loss: 0.0018 - val_accuracy: 0.7023\n",
      "Epoch 116/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7102 - val_loss: 0.0018 - val_accuracy: 0.7008\n",
      "Epoch 117/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7134 - val_loss: 0.0018 - val_accuracy: 0.7006\n",
      "Epoch 118/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7135 - val_loss: 0.0018 - val_accuracy: 0.7014\n",
      "Epoch 119/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7127 - val_loss: 0.0018 - val_accuracy: 0.6948\n",
      "Epoch 120/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7116 - val_loss: 0.0018 - val_accuracy: 0.7037\n",
      "Epoch 121/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7135 - val_loss: 0.0018 - val_accuracy: 0.7030\n",
      "Epoch 122/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7150 - val_loss: 0.0018 - val_accuracy: 0.7013\n",
      "Epoch 123/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7131 - val_loss: 0.0018 - val_accuracy: 0.6998\n",
      "Epoch 124/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7148 - val_loss: 0.0018 - val_accuracy: 0.7072\n",
      "Epoch 125/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7128 - val_loss: 0.0018 - val_accuracy: 0.7081\n",
      "Epoch 126/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7123 - val_loss: 0.0018 - val_accuracy: 0.7051\n",
      "Epoch 127/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7142 - val_loss: 0.0018 - val_accuracy: 0.7008\n",
      "Epoch 128/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7076 - val_loss: 0.0018 - val_accuracy: 0.7086\n",
      "Epoch 129/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7170 - val_loss: 0.0018 - val_accuracy: 0.7049\n",
      "Epoch 130/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7090 - val_loss: 0.0018 - val_accuracy: 0.7144\n",
      "Epoch 131/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7155 - val_loss: 0.0018 - val_accuracy: 0.7094\n",
      "Epoch 132/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7167 - val_loss: 0.0018 - val_accuracy: 0.7088\n",
      "Epoch 133/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7117 - val_loss: 0.0018 - val_accuracy: 0.7138\n",
      "Epoch 134/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7185 - val_loss: 0.0018 - val_accuracy: 0.7098\n",
      "Epoch 135/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7116 - val_loss: 0.0018 - val_accuracy: 0.7136\n",
      "Epoch 136/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7187 - val_loss: 0.0018 - val_accuracy: 0.7101\n",
      "Epoch 137/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7105 - val_loss: 0.0018 - val_accuracy: 0.7139\n",
      "Epoch 138/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7169 - val_loss: 0.0018 - val_accuracy: 0.7098\n",
      "Epoch 139/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7189 - val_loss: 0.0018 - val_accuracy: 0.7099\n",
      "Epoch 140/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7158 - val_loss: 0.0018 - val_accuracy: 0.7070\n",
      "Epoch 141/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7120 - val_loss: 0.0018 - val_accuracy: 0.7063\n",
      "Epoch 142/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7136 - val_loss: 0.0018 - val_accuracy: 0.7143\n",
      "Epoch 143/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7192 - val_loss: 0.0018 - val_accuracy: 0.7167\n",
      "Epoch 144/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7244 - val_loss: 0.0018 - val_accuracy: 0.7086\n",
      "Epoch 145/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7158 - val_loss: 0.0018 - val_accuracy: 0.7117\n",
      "Epoch 146/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7167 - val_loss: 0.0018 - val_accuracy: 0.7168\n",
      "Epoch 147/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7237 - val_loss: 0.0018 - val_accuracy: 0.7177\n",
      "Epoch 148/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7235 - val_loss: 0.0018 - val_accuracy: 0.7115\n",
      "Epoch 149/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7230 - val_loss: 0.0018 - val_accuracy: 0.7096\n",
      "Epoch 150/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7171 - val_loss: 0.0018 - val_accuracy: 0.7170\n",
      "Epoch 151/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7181 - val_loss: 0.0018 - val_accuracy: 0.7168\n",
      "Epoch 152/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7230 - val_loss: 0.0018 - val_accuracy: 0.7167\n",
      "Epoch 153/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7245 - val_loss: 0.0018 - val_accuracy: 0.7137\n",
      "Epoch 154/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7189 - val_loss: 0.0018 - val_accuracy: 0.7198\n",
      "Epoch 155/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7234 - val_loss: 0.0018 - val_accuracy: 0.7185\n",
      "Epoch 156/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7244 - val_loss: 0.0018 - val_accuracy: 0.7215\n",
      "Epoch 157/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7231 - val_loss: 0.0018 - val_accuracy: 0.7166\n",
      "Epoch 158/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7214 - val_loss: 0.0018 - val_accuracy: 0.7172\n",
      "Epoch 159/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7242 - val_loss: 0.0018 - val_accuracy: 0.7226\n",
      "Epoch 160/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7275 - val_loss: 0.0018 - val_accuracy: 0.7257\n",
      "Epoch 161/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7284 - val_loss: 0.0018 - val_accuracy: 0.7239\n",
      "Epoch 162/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7238 - val_loss: 0.0018 - val_accuracy: 0.7213\n",
      "Epoch 163/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7192 - val_loss: 0.0018 - val_accuracy: 0.7255\n",
      "Epoch 164/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7229 - val_loss: 0.0018 - val_accuracy: 0.7278\n",
      "Epoch 165/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7297 - val_loss: 0.0018 - val_accuracy: 0.7230\n",
      "Epoch 166/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7261 - val_loss: 0.0018 - val_accuracy: 0.7252\n",
      "Epoch 167/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7283 - val_loss: 0.0018 - val_accuracy: 0.7240\n",
      "Epoch 168/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7318 - val_loss: 0.0018 - val_accuracy: 0.7186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7226 - val_loss: 0.0018 - val_accuracy: 0.7251\n",
      "Epoch 170/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7254 - val_loss: 0.0018 - val_accuracy: 0.7234\n",
      "Epoch 171/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7279 - val_loss: 0.0018 - val_accuracy: 0.7238\n",
      "Epoch 172/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7221 - val_loss: 0.0018 - val_accuracy: 0.7311\n",
      "Epoch 173/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7301 - val_loss: 0.0018 - val_accuracy: 0.7251\n",
      "Epoch 174/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7257 - val_loss: 0.0018 - val_accuracy: 0.7298\n",
      "Epoch 175/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7268 - val_loss: 0.0018 - val_accuracy: 0.7285\n",
      "Epoch 176/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7325 - val_loss: 0.0018 - val_accuracy: 0.7269\n",
      "Epoch 177/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7314 - val_loss: 0.0018 - val_accuracy: 0.7344\n",
      "Epoch 178/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7321 - val_loss: 0.0018 - val_accuracy: 0.7275\n",
      "Epoch 179/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7315 - val_loss: 0.0018 - val_accuracy: 0.7299\n",
      "Epoch 180/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7299 - val_loss: 0.0018 - val_accuracy: 0.7287\n",
      "Epoch 181/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7316 - val_loss: 0.0018 - val_accuracy: 0.7311\n",
      "Epoch 182/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7350 - val_loss: 0.0018 - val_accuracy: 0.7285\n",
      "Epoch 183/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7321 - val_loss: 0.0018 - val_accuracy: 0.7339\n",
      "Epoch 184/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7351 - val_loss: 0.0018 - val_accuracy: 0.7291\n",
      "Epoch 185/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7321 - val_loss: 0.0018 - val_accuracy: 0.7353\n",
      "Epoch 186/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7320 - val_loss: 0.0018 - val_accuracy: 0.7347\n",
      "Epoch 187/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7339 - val_loss: 0.0018 - val_accuracy: 0.7336\n",
      "Epoch 188/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7370 - val_loss: 0.0018 - val_accuracy: 0.7296\n",
      "Epoch 189/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7302 - val_loss: 0.0018 - val_accuracy: 0.7345\n",
      "Epoch 190/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7296 - val_loss: 0.0018 - val_accuracy: 0.7367\n",
      "Epoch 191/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7390 - val_loss: 0.0018 - val_accuracy: 0.7309\n",
      "Epoch 192/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7317 - val_loss: 0.0018 - val_accuracy: 0.7336\n",
      "Epoch 193/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7357 - val_loss: 0.0018 - val_accuracy: 0.7336\n",
      "Epoch 194/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7329 - val_loss: 0.0018 - val_accuracy: 0.7380\n",
      "Epoch 195/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7375 - val_loss: 0.0018 - val_accuracy: 0.7380\n",
      "Epoch 196/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7383 - val_loss: 0.0018 - val_accuracy: 0.7368\n",
      "Epoch 197/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7336 - val_loss: 0.0018 - val_accuracy: 0.7390\n",
      "Epoch 198/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7389 - val_loss: 0.0018 - val_accuracy: 0.7372\n",
      "Epoch 199/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7369 - val_loss: 0.0018 - val_accuracy: 0.7370\n",
      "Epoch 200/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7340 - val_loss: 0.0018 - val_accuracy: 0.7382\n",
      "Epoch 201/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7388 - val_loss: 0.0018 - val_accuracy: 0.7385\n",
      "Epoch 202/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7371 - val_loss: 0.0017 - val_accuracy: 0.7373\n",
      "Epoch 203/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7360 - val_loss: 0.0017 - val_accuracy: 0.7359\n",
      "Epoch 204/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7376 - val_loss: 0.0017 - val_accuracy: 0.7367\n",
      "Epoch 205/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7361 - val_loss: 0.0017 - val_accuracy: 0.7411\n",
      "Epoch 206/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7370 - val_loss: 0.0017 - val_accuracy: 0.7452\n",
      "Epoch 207/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7445 - val_loss: 0.0017 - val_accuracy: 0.7388\n",
      "Epoch 208/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7394 - val_loss: 0.0017 - val_accuracy: 0.7413\n",
      "Epoch 209/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7381 - val_loss: 0.0017 - val_accuracy: 0.7418\n",
      "Epoch 210/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7400 - val_loss: 0.0017 - val_accuracy: 0.7384\n",
      "Epoch 211/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7432 - val_loss: 0.0017 - val_accuracy: 0.7418\n",
      "Epoch 212/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7380 - val_loss: 0.0017 - val_accuracy: 0.7455\n",
      "Epoch 213/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7451 - val_loss: 0.0017 - val_accuracy: 0.7410\n",
      "Epoch 214/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7338 - val_loss: 0.0017 - val_accuracy: 0.7516\n",
      "Epoch 215/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7481 - val_loss: 0.0017 - val_accuracy: 0.7421\n",
      "Epoch 216/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7396 - val_loss: 0.0017 - val_accuracy: 0.7473\n",
      "Epoch 217/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7420 - val_loss: 0.0017 - val_accuracy: 0.7468\n",
      "Epoch 218/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7401 - val_loss: 0.0017 - val_accuracy: 0.7454\n",
      "Epoch 219/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7431 - val_loss: 0.0017 - val_accuracy: 0.7421\n",
      "Epoch 220/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7387 - val_loss: 0.0017 - val_accuracy: 0.7487\n",
      "Epoch 221/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7482 - val_loss: 0.0017 - val_accuracy: 0.7516\n",
      "Epoch 222/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7485 - val_loss: 0.0017 - val_accuracy: 0.7508\n",
      "Epoch 223/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7476 - val_loss: 0.0017 - val_accuracy: 0.7477\n",
      "Epoch 224/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7442 - val_loss: 0.0017 - val_accuracy: 0.7509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7455 - val_loss: 0.0017 - val_accuracy: 0.7447\n",
      "Epoch 226/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7444 - val_loss: 0.0017 - val_accuracy: 0.7451\n",
      "Epoch 227/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7444 - val_loss: 0.0017 - val_accuracy: 0.7475\n",
      "Epoch 228/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7435 - val_loss: 0.0017 - val_accuracy: 0.7539\n",
      "Epoch 229/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7474 - val_loss: 0.0017 - val_accuracy: 0.7503\n",
      "Epoch 230/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7427 - val_loss: 0.0017 - val_accuracy: 0.7545\n",
      "Epoch 231/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7511 - val_loss: 0.0017 - val_accuracy: 0.7543\n",
      "Epoch 232/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7501 - val_loss: 0.0017 - val_accuracy: 0.7469\n",
      "Epoch 233/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7450 - val_loss: 0.0017 - val_accuracy: 0.7497\n",
      "Epoch 234/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7433 - val_loss: 0.0017 - val_accuracy: 0.7560\n",
      "Epoch 235/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7494 - val_loss: 0.0017 - val_accuracy: 0.7562\n",
      "Epoch 236/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7484 - val_loss: 0.0017 - val_accuracy: 0.7532\n",
      "Epoch 237/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7510 - val_loss: 0.0017 - val_accuracy: 0.7522\n",
      "Epoch 238/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7424 - val_loss: 0.0017 - val_accuracy: 0.7551\n",
      "Epoch 239/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7510 - val_loss: 0.0017 - val_accuracy: 0.7544\n",
      "Epoch 240/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7489 - val_loss: 0.0017 - val_accuracy: 0.7534\n",
      "Epoch 241/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7518 - val_loss: 0.0017 - val_accuracy: 0.7521\n",
      "Epoch 242/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7490 - val_loss: 0.0017 - val_accuracy: 0.7552\n",
      "Epoch 243/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7506 - val_loss: 0.0017 - val_accuracy: 0.7566\n",
      "Epoch 244/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7503 - val_loss: 0.0017 - val_accuracy: 0.7504\n",
      "Epoch 245/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7494 - val_loss: 0.0017 - val_accuracy: 0.7516\n",
      "Epoch 246/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7494 - val_loss: 0.0017 - val_accuracy: 0.7548\n",
      "Epoch 247/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7519 - val_loss: 0.0017 - val_accuracy: 0.7563\n",
      "Epoch 248/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7528 - val_loss: 0.0017 - val_accuracy: 0.7597\n",
      "Epoch 249/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7542 - val_loss: 0.0017 - val_accuracy: 0.7599\n",
      "Epoch 250/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7540 - val_loss: 0.0017 - val_accuracy: 0.7621\n",
      "Epoch 251/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7534 - val_loss: 0.0017 - val_accuracy: 0.7634\n",
      "Epoch 252/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7560 - val_loss: 0.0017 - val_accuracy: 0.7635\n",
      "Epoch 253/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7561 - val_loss: 0.0017 - val_accuracy: 0.7689\n",
      "Epoch 254/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7578 - val_loss: 0.0017 - val_accuracy: 0.7609\n",
      "Epoch 255/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7562 - val_loss: 0.0017 - val_accuracy: 0.7616\n",
      "Epoch 256/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7571 - val_loss: 0.0017 - val_accuracy: 0.7647\n",
      "Epoch 257/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7560 - val_loss: 0.0017 - val_accuracy: 0.7605\n",
      "Epoch 258/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7571 - val_loss: 0.0017 - val_accuracy: 0.7614\n",
      "Epoch 259/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7524 - val_loss: 0.0017 - val_accuracy: 0.7648\n",
      "Epoch 260/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7554 - val_loss: 0.0017 - val_accuracy: 0.7648\n",
      "Epoch 261/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7609 - val_loss: 0.0017 - val_accuracy: 0.7599\n",
      "Epoch 262/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7565 - val_loss: 0.0017 - val_accuracy: 0.7608\n",
      "Epoch 263/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7541 - val_loss: 0.0017 - val_accuracy: 0.7706\n",
      "Epoch 264/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7618 - val_loss: 0.0017 - val_accuracy: 0.7653\n",
      "Epoch 265/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7563 - val_loss: 0.0017 - val_accuracy: 0.7655\n",
      "Epoch 266/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7590 - val_loss: 0.0017 - val_accuracy: 0.7633\n",
      "Epoch 267/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7607 - val_loss: 0.0017 - val_accuracy: 0.7684\n",
      "Epoch 268/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7636 - val_loss: 0.0017 - val_accuracy: 0.7676\n",
      "Epoch 269/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7619 - val_loss: 0.0017 - val_accuracy: 0.7605\n",
      "Epoch 270/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7595 - val_loss: 0.0017 - val_accuracy: 0.7642\n",
      "Epoch 271/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7617 - val_loss: 0.0017 - val_accuracy: 0.7590\n",
      "Epoch 272/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7592 - val_loss: 0.0017 - val_accuracy: 0.7716\n",
      "Epoch 273/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7593 - val_loss: 0.0017 - val_accuracy: 0.7739\n",
      "Epoch 274/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7662 - val_loss: 0.0017 - val_accuracy: 0.7789\n",
      "Epoch 275/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7641 - val_loss: 0.0017 - val_accuracy: 0.7735\n",
      "Epoch 276/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7673 - val_loss: 0.0017 - val_accuracy: 0.7662\n",
      "Epoch 277/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7587 - val_loss: 0.0017 - val_accuracy: 0.7695\n",
      "Epoch 278/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7630 - val_loss: 0.0017 - val_accuracy: 0.7725\n",
      "Epoch 279/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7633 - val_loss: 0.0017 - val_accuracy: 0.7693\n",
      "Epoch 280/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7644 - val_loss: 0.0017 - val_accuracy: 0.7701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7616 - val_loss: 0.0017 - val_accuracy: 0.7692\n",
      "Epoch 282/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7643 - val_loss: 0.0017 - val_accuracy: 0.7696\n",
      "Epoch 283/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7612 - val_loss: 0.0017 - val_accuracy: 0.7757\n",
      "Epoch 284/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7629 - val_loss: 0.0017 - val_accuracy: 0.7749\n",
      "Epoch 285/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7721 - val_loss: 0.0017 - val_accuracy: 0.7745\n",
      "Epoch 286/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7662 - val_loss: 0.0017 - val_accuracy: 0.7720\n",
      "Epoch 287/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7660 - val_loss: 0.0017 - val_accuracy: 0.7690\n",
      "Epoch 288/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7660 - val_loss: 0.0017 - val_accuracy: 0.7719\n",
      "Epoch 289/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7633 - val_loss: 0.0017 - val_accuracy: 0.7732\n",
      "Epoch 290/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7665 - val_loss: 0.0017 - val_accuracy: 0.7770\n",
      "Epoch 291/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7674 - val_loss: 0.0017 - val_accuracy: 0.7725\n",
      "Epoch 292/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7652 - val_loss: 0.0017 - val_accuracy: 0.7787\n",
      "Epoch 293/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7646 - val_loss: 0.0017 - val_accuracy: 0.7765\n",
      "Epoch 294/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7670 - val_loss: 0.0017 - val_accuracy: 0.7760\n",
      "Epoch 295/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7682 - val_loss: 0.0017 - val_accuracy: 0.7704\n",
      "Epoch 296/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7636 - val_loss: 0.0017 - val_accuracy: 0.7773\n",
      "Epoch 297/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7657 - val_loss: 0.0017 - val_accuracy: 0.7736\n",
      "Epoch 298/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7668 - val_loss: 0.0017 - val_accuracy: 0.7741\n",
      "Epoch 299/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7635 - val_loss: 0.0017 - val_accuracy: 0.7781\n",
      "Epoch 300/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7680 - val_loss: 0.0017 - val_accuracy: 0.7749\n",
      "Epoch 301/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7669 - val_loss: 0.0017 - val_accuracy: 0.7804\n",
      "Epoch 302/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7700 - val_loss: 0.0017 - val_accuracy: 0.7853\n",
      "Epoch 303/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7744 - val_loss: 0.0017 - val_accuracy: 0.7874\n",
      "Epoch 304/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7706 - val_loss: 0.0017 - val_accuracy: 0.7819\n",
      "Epoch 305/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7718 - val_loss: 0.0017 - val_accuracy: 0.7797\n",
      "Epoch 306/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7746 - val_loss: 0.0017 - val_accuracy: 0.7751\n",
      "Epoch 307/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7665 - val_loss: 0.0017 - val_accuracy: 0.7758\n",
      "Epoch 308/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7653 - val_loss: 0.0017 - val_accuracy: 0.7768\n",
      "Epoch 309/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7716 - val_loss: 0.0017 - val_accuracy: 0.7778\n",
      "Epoch 310/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7662 - val_loss: 0.0017 - val_accuracy: 0.7782\n",
      "Epoch 311/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7715 - val_loss: 0.0017 - val_accuracy: 0.7793\n",
      "Epoch 312/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7737 - val_loss: 0.0017 - val_accuracy: 0.7819\n",
      "Epoch 313/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7728 - val_loss: 0.0017 - val_accuracy: 0.7859\n",
      "Epoch 314/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7764 - val_loss: 0.0017 - val_accuracy: 0.7820\n",
      "Epoch 315/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7723 - val_loss: 0.0017 - val_accuracy: 0.7866\n",
      "Epoch 316/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7739 - val_loss: 0.0017 - val_accuracy: 0.7807\n",
      "Epoch 317/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7670 - val_loss: 0.0017 - val_accuracy: 0.7939\n",
      "Epoch 318/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7795 - val_loss: 0.0017 - val_accuracy: 0.7852\n",
      "Epoch 319/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7748 - val_loss: 0.0017 - val_accuracy: 0.7793\n",
      "Epoch 320/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7711 - val_loss: 0.0017 - val_accuracy: 0.7793\n",
      "Epoch 321/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7662 - val_loss: 0.0017 - val_accuracy: 0.7867\n",
      "Epoch 322/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7739 - val_loss: 0.0017 - val_accuracy: 0.7839\n",
      "Epoch 323/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7731 - val_loss: 0.0017 - val_accuracy: 0.7853\n",
      "Epoch 324/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7746 - val_loss: 0.0017 - val_accuracy: 0.7895\n",
      "Epoch 325/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7746 - val_loss: 0.0017 - val_accuracy: 0.7870\n",
      "Epoch 326/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7753 - val_loss: 0.0017 - val_accuracy: 0.7906\n",
      "Epoch 327/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7777 - val_loss: 0.0017 - val_accuracy: 0.7840\n",
      "Epoch 328/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7719 - val_loss: 0.0017 - val_accuracy: 0.7909\n",
      "Epoch 329/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7797 - val_loss: 0.0017 - val_accuracy: 0.7861\n",
      "Epoch 330/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7755 - val_loss: 0.0017 - val_accuracy: 0.7899\n",
      "Epoch 331/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7824 - val_loss: 0.0017 - val_accuracy: 0.7850\n",
      "Epoch 332/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7732 - val_loss: 0.0017 - val_accuracy: 0.7924\n",
      "Epoch 333/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7761 - val_loss: 0.0017 - val_accuracy: 0.7853\n",
      "Epoch 334/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7736 - val_loss: 0.0017 - val_accuracy: 0.7923\n",
      "Epoch 335/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7745 - val_loss: 0.0017 - val_accuracy: 0.7930\n",
      "Epoch 336/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7810 - val_loss: 0.0017 - val_accuracy: 0.7929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7788 - val_loss: 0.0017 - val_accuracy: 0.7916\n",
      "Epoch 338/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7815 - val_loss: 0.0017 - val_accuracy: 0.7864\n",
      "Epoch 339/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7738 - val_loss: 0.0017 - val_accuracy: 0.7906\n",
      "Epoch 340/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7795 - val_loss: 0.0017 - val_accuracy: 0.7866\n",
      "Epoch 341/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7705 - val_loss: 0.0017 - val_accuracy: 0.7930\n",
      "Epoch 342/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7792 - val_loss: 0.0017 - val_accuracy: 0.7900\n",
      "Epoch 343/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7808 - val_loss: 0.0017 - val_accuracy: 0.7936\n",
      "Epoch 344/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7847 - val_loss: 0.0017 - val_accuracy: 0.7874\n",
      "Epoch 345/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7812 - val_loss: 0.0017 - val_accuracy: 0.7847\n",
      "Epoch 346/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7768 - val_loss: 0.0017 - val_accuracy: 0.7910\n",
      "Epoch 347/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7818 - val_loss: 0.0017 - val_accuracy: 0.7964\n",
      "Epoch 348/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7789 - val_loss: 0.0017 - val_accuracy: 0.7932\n",
      "Epoch 349/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7815 - val_loss: 0.0017 - val_accuracy: 0.7934\n",
      "Epoch 350/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7823 - val_loss: 0.0017 - val_accuracy: 0.7905\n",
      "Epoch 351/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7776 - val_loss: 0.0017 - val_accuracy: 0.7969\n",
      "Epoch 352/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7822 - val_loss: 0.0017 - val_accuracy: 0.7941\n",
      "Epoch 353/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7817 - val_loss: 0.0017 - val_accuracy: 0.7940\n",
      "Epoch 354/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7808 - val_loss: 0.0017 - val_accuracy: 0.7948\n",
      "Epoch 355/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7809 - val_loss: 0.0017 - val_accuracy: 0.7975\n",
      "Epoch 356/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7836 - val_loss: 0.0017 - val_accuracy: 0.7965\n",
      "Epoch 357/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7810 - val_loss: 0.0017 - val_accuracy: 0.7993\n",
      "Epoch 358/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7826 - val_loss: 0.0017 - val_accuracy: 0.7946\n",
      "Epoch 359/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7818 - val_loss: 0.0017 - val_accuracy: 0.7960\n",
      "Epoch 360/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7838 - val_loss: 0.0017 - val_accuracy: 0.7938\n",
      "Epoch 361/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7822 - val_loss: 0.0017 - val_accuracy: 0.7927\n",
      "Epoch 362/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7813 - val_loss: 0.0017 - val_accuracy: 0.7932\n",
      "Epoch 363/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7812 - val_loss: 0.0017 - val_accuracy: 0.7911\n",
      "Epoch 364/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7818 - val_loss: 0.0017 - val_accuracy: 0.7958\n",
      "Epoch 365/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7847 - val_loss: 0.0017 - val_accuracy: 0.7960\n",
      "Epoch 366/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7792 - val_loss: 0.0017 - val_accuracy: 0.7941\n",
      "Epoch 367/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7839 - val_loss: 0.0017 - val_accuracy: 0.7927\n",
      "Epoch 368/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7798 - val_loss: 0.0017 - val_accuracy: 0.7972\n",
      "Epoch 369/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7856 - val_loss: 0.0017 - val_accuracy: 0.7921\n",
      "Epoch 370/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7816 - val_loss: 0.0017 - val_accuracy: 0.7978\n",
      "Epoch 371/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7855 - val_loss: 0.0017 - val_accuracy: 0.8000\n",
      "Epoch 372/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7851 - val_loss: 0.0017 - val_accuracy: 0.7984\n",
      "Epoch 373/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7855 - val_loss: 0.0017 - val_accuracy: 0.8003\n",
      "Epoch 374/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7876 - val_loss: 0.0017 - val_accuracy: 0.7953\n",
      "Epoch 375/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7814 - val_loss: 0.0017 - val_accuracy: 0.7976\n",
      "Epoch 376/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7839 - val_loss: 0.0017 - val_accuracy: 0.7982\n",
      "Epoch 377/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7852 - val_loss: 0.0017 - val_accuracy: 0.8050\n",
      "Epoch 378/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7882 - val_loss: 0.0017 - val_accuracy: 0.8010\n",
      "Epoch 379/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7850 - val_loss: 0.0017 - val_accuracy: 0.7999\n",
      "Epoch 380/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7893 - val_loss: 0.0017 - val_accuracy: 0.8017\n",
      "Epoch 381/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7865 - val_loss: 0.0017 - val_accuracy: 0.8023\n",
      "Epoch 382/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7921 - val_loss: 0.0017 - val_accuracy: 0.7965\n",
      "Epoch 383/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7862 - val_loss: 0.0017 - val_accuracy: 0.7991\n",
      "Epoch 384/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7864 - val_loss: 0.0017 - val_accuracy: 0.8014\n",
      "Epoch 385/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7872 - val_loss: 0.0017 - val_accuracy: 0.8051\n",
      "Epoch 386/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7918 - val_loss: 0.0017 - val_accuracy: 0.8010\n",
      "Epoch 387/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7868 - val_loss: 0.0017 - val_accuracy: 0.8009\n",
      "Epoch 388/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7888 - val_loss: 0.0017 - val_accuracy: 0.8004\n",
      "Epoch 389/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7868 - val_loss: 0.0017 - val_accuracy: 0.8078\n",
      "Epoch 390/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7902 - val_loss: 0.0016 - val_accuracy: 0.8002\n",
      "Epoch 391/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7901 - val_loss: 0.0016 - val_accuracy: 0.7983\n",
      "Epoch 392/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7899 - val_loss: 0.0016 - val_accuracy: 0.7973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7854 - val_loss: 0.0016 - val_accuracy: 0.8050\n",
      "Epoch 394/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7940 - val_loss: 0.0016 - val_accuracy: 0.8008\n",
      "Epoch 395/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7845 - val_loss: 0.0016 - val_accuracy: 0.8047\n",
      "Epoch 396/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7908 - val_loss: 0.0016 - val_accuracy: 0.8056\n",
      "Epoch 397/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7871 - val_loss: 0.0017 - val_accuracy: 0.8123\n",
      "Epoch 398/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7961 - val_loss: 0.0016 - val_accuracy: 0.8005\n",
      "Epoch 399/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7863 - val_loss: 0.0016 - val_accuracy: 0.8047\n",
      "Epoch 400/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7903 - val_loss: 0.0016 - val_accuracy: 0.8059\n",
      "Epoch 401/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7925 - val_loss: 0.0016 - val_accuracy: 0.8037\n",
      "Epoch 402/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7932 - val_loss: 0.0016 - val_accuracy: 0.8058\n",
      "Epoch 403/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7903 - val_loss: 0.0016 - val_accuracy: 0.8043\n",
      "Epoch 404/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7920 - val_loss: 0.0016 - val_accuracy: 0.8040\n",
      "Epoch 405/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7908 - val_loss: 0.0016 - val_accuracy: 0.8086\n",
      "Epoch 406/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7919 - val_loss: 0.0016 - val_accuracy: 0.8051\n",
      "Epoch 407/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7903 - val_loss: 0.0016 - val_accuracy: 0.8071\n",
      "Epoch 408/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7921 - val_loss: 0.0016 - val_accuracy: 0.8029\n",
      "Epoch 409/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7932 - val_loss: 0.0016 - val_accuracy: 0.8040\n",
      "Epoch 410/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7923 - val_loss: 0.0016 - val_accuracy: 0.8034\n",
      "Epoch 411/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7934 - val_loss: 0.0016 - val_accuracy: 0.8027\n",
      "Epoch 412/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7922 - val_loss: 0.0016 - val_accuracy: 0.8033\n",
      "Epoch 413/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7888 - val_loss: 0.0016 - val_accuracy: 0.8113\n",
      "Epoch 414/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7920 - val_loss: 0.0016 - val_accuracy: 0.8112\n",
      "Epoch 415/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7949 - val_loss: 0.0016 - val_accuracy: 0.8130\n",
      "Epoch 416/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7949 - val_loss: 0.0016 - val_accuracy: 0.8127\n",
      "Epoch 417/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7949 - val_loss: 0.0016 - val_accuracy: 0.8135\n",
      "Epoch 418/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7962 - val_loss: 0.0016 - val_accuracy: 0.8038\n",
      "Epoch 419/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7912 - val_loss: 0.0016 - val_accuracy: 0.8018\n",
      "Epoch 420/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7885 - val_loss: 0.0016 - val_accuracy: 0.8085\n",
      "Epoch 421/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7951 - val_loss: 0.0016 - val_accuracy: 0.8084\n",
      "Epoch 422/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7914 - val_loss: 0.0016 - val_accuracy: 0.8125\n",
      "Epoch 423/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7935 - val_loss: 0.0016 - val_accuracy: 0.8122\n",
      "Epoch 424/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7974 - val_loss: 0.0016 - val_accuracy: 0.8059\n",
      "Epoch 425/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7909 - val_loss: 0.0016 - val_accuracy: 0.8136\n",
      "Epoch 426/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.7949 - val_loss: 0.0016 - val_accuracy: 0.8119\n",
      "Epoch 427/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7928 - val_loss: 0.0016 - val_accuracy: 0.8117\n",
      "Epoch 428/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7953 - val_loss: 0.0016 - val_accuracy: 0.8103\n",
      "Epoch 429/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7980 - val_loss: 0.0016 - val_accuracy: 0.8102\n",
      "Epoch 430/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7927 - val_loss: 0.0016 - val_accuracy: 0.8148\n",
      "Epoch 431/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7985 - val_loss: 0.0016 - val_accuracy: 0.8132\n",
      "Epoch 432/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.7983 - val_loss: 0.0016 - val_accuracy: 0.8110\n",
      "Epoch 433/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7970 - val_loss: 0.0016 - val_accuracy: 0.8148\n",
      "Epoch 434/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7964 - val_loss: 0.0016 - val_accuracy: 0.8105\n",
      "Epoch 435/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7941 - val_loss: 0.0016 - val_accuracy: 0.8085\n",
      "Epoch 436/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7967 - val_loss: 0.0016 - val_accuracy: 0.8143\n",
      "Epoch 437/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.8017 - val_loss: 0.0016 - val_accuracy: 0.8112\n",
      "Epoch 438/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7940 - val_loss: 0.0016 - val_accuracy: 0.8069\n",
      "Epoch 439/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7928 - val_loss: 0.0016 - val_accuracy: 0.8187\n",
      "Epoch 440/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7999 - val_loss: 0.0016 - val_accuracy: 0.8120\n",
      "Epoch 441/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7959 - val_loss: 0.0016 - val_accuracy: 0.8104\n",
      "Epoch 442/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7952 - val_loss: 0.0016 - val_accuracy: 0.8103\n",
      "Epoch 443/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7931 - val_loss: 0.0016 - val_accuracy: 0.8120\n",
      "Epoch 444/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7991 - val_loss: 0.0016 - val_accuracy: 0.8136\n",
      "Epoch 445/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.7998 - val_loss: 0.0016 - val_accuracy: 0.8102\n",
      "Epoch 446/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.7991 - val_loss: 0.0016 - val_accuracy: 0.8120\n",
      "Epoch 447/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7954 - val_loss: 0.0016 - val_accuracy: 0.8192\n",
      "Epoch 448/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7983 - val_loss: 0.0016 - val_accuracy: 0.8175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7989 - val_loss: 0.0016 - val_accuracy: 0.8123\n",
      "Epoch 450/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.8012 - val_loss: 0.0016 - val_accuracy: 0.8131\n",
      "Epoch 451/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7961 - val_loss: 0.0016 - val_accuracy: 0.8200\n",
      "Epoch 452/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7966 - val_loss: 0.0016 - val_accuracy: 0.8189\n",
      "Epoch 453/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.8028 - val_loss: 0.0016 - val_accuracy: 0.8131\n",
      "Epoch 454/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7995 - val_loss: 0.0016 - val_accuracy: 0.8121\n",
      "Epoch 455/10000\n",
      "230/233 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.7986"
     ]
    }
   ],
   "source": [
    "# Fit ML classifier\n",
    "EPOCHS = 10000\n",
    "batch_size = 512\n",
    "num_nodes = 64\n",
    "dropout = 0.1\n",
    "\n",
    "n_models = 10\n",
    "\n",
    "plot_name = 'all_train_feats_updated_full_list_no_phi_10_models'\n",
    "\n",
    "for i in range(n_models):\n",
    "    # Generate and fit model\n",
    "    classifier_4l_DF = Sequential()\n",
    "    classifier_4l_DF.add(Dense(num_nodes, input_dim=x_train.shape[1], activation='relu')) \n",
    "    classifier_4l_DF.add(Dropout(dropout))\n",
    "    classifier_4l_DF.add(Dense(num_nodes, activation='relu'))\n",
    "    classifier_4l_DF.add(Dropout(dropout))\n",
    "    classifier_4l_DF.add(Dense(num_nodes, activation='relu'))\n",
    "    classifier_4l_DF.add(Dropout(dropout))\n",
    "    classifier_4l_DF.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-5)\n",
    "    classifier_4l_DF.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    # Early stopping\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1000, restore_best_weights=True)\n",
    "\n",
    "    history = classifier_4l_DF.fit(x_train, y_train, epochs=EPOCHS, batch_size=batch_size,\n",
    "                                   validation_data=(x_test, y_test, w_test), sample_weight=w_train, \n",
    "                                   verbose=1, callbacks=[callback], shuffle=True)\n",
    "    \n",
    "    bg_test['NN_out_' + str(i)] = classifier_4l_DF.predict(bg_test[combined_train_feats], batch_size=10000)\n",
    "    sig_test['NN_out_' + str(i)] = classifier_4l_DF.predict(sig_test[combined_train_feats], batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_out_cols = ['NN_out_' + str(i) for i in range(n_models)]\n",
    "\n",
    "bg_test['NN_out_mean'] = np.mean(bg_test[nn_out_cols], axis=1)\n",
    "sig_test['NN_out_mean'] = np.mean(sig_test[nn_out_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, b, _ = plt.hist(bg_test.NN_out_mean, bins=20, alpha=0.7, weights=bg_test.wgt, label='Background')\n",
    "plt.hist(sig_test.NN_out_mean, bins=b, alpha=0.7, weights=sig_test.wgt, label='Signal')\n",
    "\n",
    "plt.ylabel('Events', fontsize=14)\n",
    "plt.xlabel('NN output', fontsize=14)\n",
    "plt.title('4$\\ell$-DF', loc='right', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.yscale('log')\n",
    "\n",
    "atlasify('Internal Simulation', outside=True)\n",
    "plt.minorticks_on()\n",
    "\n",
    "plt.savefig('plots/SR_4l_DF_optimization/' + plot_name + '_events.png')\n",
    "plt.savefig('plots/SR_4l_DF_optimization/' + plot_name + '_events.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sig_pts = 100\n",
    "\n",
    "nn_cuts = np.arange(0.0, 1.0, 1.0/n_sig_pts)\n",
    "significances = [float('nan')]*n_sig_pts\n",
    "\n",
    "max_sig_loc = 0\n",
    "max_sig = 0\n",
    "\n",
    "for i, nn_cut in enumerate(nn_cuts):\n",
    "    n_bg = sum(bg_test[bg_test.NN_out_mean > nn_cut].wgt)\n",
    "    n_sig = sum(sig_test[sig_test.NN_out_mean > nn_cut].wgt)\n",
    "    \n",
    "    try:\n",
    "        current_sig = region_sig(n_sig, n_bg)\n",
    "    except ZeroDivisionError:\n",
    "        current_sig = float('nan')\n",
    "    significances[i] = current_sig\n",
    "    \n",
    "    if current_sig > max_sig:\n",
    "        max_sig = current_sig\n",
    "        max_sig_loc = nn_cut\n",
    "        \n",
    "print('Max observed significance:', max_sig, 'sigma at cut of', max_sig_loc)\n",
    "print('Corresponds to', 2*max_sig, 'sigma with full dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nn_cuts, significances)\n",
    "\n",
    "plt.axhline(y=max_sig, color='black', ls='--')\n",
    "plt.axvline(x=max_sig_loc, color='black', ls='--')\n",
    "\n",
    "plt.ylabel('Significance', fontsize=14)\n",
    "plt.xlabel('NN cut', fontsize=14)\n",
    "plt.title('4$\\ell$-DF', loc='right', fontsize=14)\n",
    "\n",
    "plt.text(min(nn_cuts), min(significances), \n",
    "         'Max: %.2f $\\sigma$\\nCorresponds to %.2f $\\sigma$\\nLoc: %.2f'%(max_sig, 2*max_sig, max_sig_loc),\n",
    "         fontsize=14)\n",
    "\n",
    "atlasify('Internal Simulation', outside=True)\n",
    "\n",
    "plt.savefig('plots/SR_4l_DF_optimization/' + plot_name + '.png')\n",
    "plt.savefig('plots/SR_4l_DF_optimization/' + plot_name + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wvz_machine_learning",
   "language": "python",
   "name": "wvz_machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
