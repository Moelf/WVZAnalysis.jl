{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.errors import InvalidArgumentError\n",
    "import tensorflow as tf\n",
    "\n",
    "# Tensorflow GPU settings\n",
    "# gpu_options = tf.GPUOptions(allow_growth=True)#per_process_gpu_memory_fraction=0.5)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from scipy import interpolate\n",
    "\n",
    "from atlasify import atlasify\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/20220117_iso_e4m1_VVZ_RD.arrow')\n",
    "sig['is_signal'] = True\n",
    "# sig = sig[sig.SR == 2]\n",
    "\n",
    "bg = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/20220117_iso_e4m1_FULLBG_RD.arrow')\n",
    "bg['is_signal'] = False\n",
    "# bg = bg[bg.SR == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats_raw = sorted([f for f in sig.columns if f not in ['index', 'wgt', 'is_signal', \n",
    "                                                              'Zcand_mass', 'chisq']])\n",
    "\n",
    "train_feat_sets = [train_feats_raw, \n",
    "                   [f for f in train_feats_raw if f not in ['Wlep1_phi', 'Wlep2_phi', 'Zlep1_phi', 'Zlep2_phi']],\n",
    "                   [f for f in train_feats_raw if f not in ['MET', 'METSig']],\n",
    "                   [f for f in train_feats_raw if f not in ['pt_1', 'pt_2', 'pt_3', 'pt_4']],\n",
    "                   [f for f in train_feats_raw if f not in ['Njet', 'Nlep']]\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize training features\n",
    "X = pd.concat([sig[train_feats_raw], bg[train_feats_raw]], ignore_index=True)\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "min_max_scaler.fit(X)\n",
    "\n",
    "for df in [sig, bg]:\n",
    "    df[train_feats_raw] = min_max_scaler.transform(df[train_feats_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load per-background models\n",
    "models_dir = 'models/background_id_models/'\n",
    "\n",
    "background_classifiers = {'ZZ': 1, 'Zjets': 2, 'WZ': 1, 'ttZ': 0, 'other': 1}\n",
    "\n",
    "for bc_name in background_classifiers:\n",
    "    bc_index = background_classifiers[bc_name]\n",
    "    \n",
    "    classifier = keras.models.load_model((models_dir + 'classifier_' + bc_name \n",
    "                                          + '_train_feat_test_' + str(bc_index)))\n",
    "    sig['classifier_' + bc_name + '_score'] = classifier.predict(sig[train_feat_sets[bc_index]], \n",
    "                                                                    batch_size=10000)\n",
    "    bg['classifier_' + bc_name + '_score'] = classifier.predict(bg[train_feat_sets[bc_index]], \n",
    "                                                                   batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, b, _ = plt.hist(bg.classifier_ZZ_score, bins=100, weights=bg.wgt, density=True, alpha=0.5)\n",
    "plt.hist(sig.classifier_ZZ_score, bins=b, weights=sig.wgt, density=True, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, b, _ = plt.hist(bg.classifier_Zjets_score, bins=100, weights=bg.wgt, density=True, alpha=0.5)\n",
    "plt.hist(sig.classifier_Zjets_score, bins=b, weights=sig.wgt, density=True, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, b, _ = plt.hist(bg.classifier_WZ_score, bins=100, weights=bg.wgt, density=True, alpha=0.5)\n",
    "plt.hist(sig.classifier_WZ_score, bins=b, weights=sig.wgt, density=True, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, b, _ = plt.hist(bg.classifier_ttZ_score, bins=100, weights=bg.wgt, density=True, alpha=0.5)\n",
    "plt.hist(sig.classifier_ttZ_score, bins=b, weights=sig.wgt, density=True, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, b, _ = plt.hist(bg.classifier_other_score, bins=100, weights=bg.wgt, density=True, alpha=0.5)\n",
    "plt.hist(sig.classifier_other_score, bins=b, weights=sig.wgt, density=True, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut to 4l-DF signal region\n",
    "bg = bg[bg.SR == 1]\n",
    "sig = sig[sig.SR == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "\n",
    "First we want to figure out the signal/background ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_sig(s, b):\n",
    "    if s == 0:\n",
    "        return 0\n",
    "    return np.sqrt(2 * ((s + b) * np.log(1 + s / b) - s))\n",
    "\n",
    "n_bg = sum(bg.wgt)\n",
    "n_sig = sum(sig.wgt)\n",
    "\n",
    "print('There are', n_bg, 'background events')\n",
    "print('There are', n_sig, 'signal events')\n",
    "print('')\n",
    "print('S/B =', n_sig/n_bg)\n",
    "print('Starting significance is', region_sig(n_sig, n_bg), 'sigma')\n",
    "print('Corresponds to', np.sqrt(2.0) * region_sig(n_sig, n_bg), 'sigma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg['abs_wgt'] = np.abs(bg.wgt)\n",
    "sig['abs_wgt'] = np.abs(sig.wgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_classifier_score_feats = ['classifier_' + bc + '_score' for bc in background_classifiers]\n",
    "combined_train_feats_raw = train_feats_raw + bg_classifier_score_feats\n",
    "\n",
    "combined_train_feat_sets = [combined_train_feats_raw, \n",
    "                            [f for f in combined_train_feats_raw if f not in bg_classifier_score_feats],\n",
    "                            [f for f in combined_train_feats_raw if f not in ['Wlep1_phi', 'Wlep2_phi', \n",
    "                                                                              'Zlep1_phi', 'Zlep2_phi']],\n",
    "                            [f for f in combined_train_feats_raw if f not in ['MET', 'METSig']],\n",
    "                            [f for f in combined_train_feats_raw if f not in ['pt_1', 'pt_2', 'pt_3', 'pt_4']],\n",
    "                            [f for f in combined_train_feats_raw if f not in ['Njet', 'Nlep']]\n",
    "                           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10000\n",
    "patience = 500\n",
    "batch_size = 256\n",
    "num_nodes = 64\n",
    "dropout = 0.1\n",
    "learn_rate = 1e-5\n",
    "\n",
    "for i, train_feats in enumerate(combined_train_feat_sets):\n",
    "    model_dir = 'models/SR_4l_DF_models/'\n",
    "    model_name = 'classifier_train_feat_test_' + str(i)\n",
    "    \n",
    "    print('Running with training features:', train_feats)\n",
    "    # Save training setup\n",
    "    with open(model_dir + model_name + '_setup.txt', 'w') as file:\n",
    "        file.write('Epochs: ' + str(EPOCHS) + '\\n')\n",
    "        file.write('Patience: ' + str(patience) + '\\n')\n",
    "        file.write('Learning rate: ' + str(learn_rate) + '\\n')\n",
    "        file.write('Batch size: ' + str(batch_size) + '\\n\\n')\n",
    "        file.write('Training features:\\n' + '\\n'.join(train_feats))\n",
    "    \n",
    "    # Generate train and test samples\n",
    "    sig_train, sig_test = train_test_split(sig[train_feats + ['wgt']], train_size=0.5, random_state=314)\n",
    "    bg_train, bg_test = train_test_split(bg[train_feats + ['wgt']], train_size=0.5, random_state=314)\n",
    "\n",
    "    n_sig = sum(sig_train.wgt)\n",
    "    n_bg = sum(bg_train.wgt)\n",
    "\n",
    "    x_train_sig = sig_train[train_feats]\n",
    "    x_train_bg = bg_train[train_feats]\n",
    "\n",
    "    x_train = pd.concat([x_train_sig, x_train_bg])\n",
    "    y_train = np.concatenate([np.ones(len(sig_train)), np.zeros(len(bg_train))])\n",
    "    w_train = pd.Series(np.concatenate([(n_sig + n_bg) / n_sig * sig_train['wgt'], \n",
    "                                        (n_sig + n_bg) / n_bg * bg_train['wgt']]))\n",
    "\n",
    "    n_sig_test = sum(sig_test.wgt)\n",
    "    n_bg_test = sum(bg_test.wgt)\n",
    "\n",
    "    x_test = pd.concat([sig_test[train_feats], bg_test[train_feats]])\n",
    "    y_test = np.concatenate([np.ones(len(sig_test)), np.zeros(len(bg_test))])\n",
    "    w_test = pd.Series(np.concatenate([(n_sig_test + n_bg_test) / n_sig_test * sig_test['wgt'], \n",
    "                                       (n_sig_test + n_bg_test) / n_bg_test * bg_test['wgt']]))\n",
    "    \n",
    "    # Generate and fit model\n",
    "    K.clear_session()\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(num_nodes, input_dim=x_train.shape[1], activation='relu')) \n",
    "    classifier.add(Dropout(dropout))\n",
    "    classifier.add(Dense(num_nodes, activation='relu'))\n",
    "    classifier.add(Dropout(dropout))\n",
    "    classifier.add(Dense(num_nodes, activation='relu'))\n",
    "    classifier.add(Dropout(dropout))\n",
    "    classifier.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=learn_rate)\n",
    "    classifier.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    # Early stopping\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "\n",
    "    history = classifier.fit(x_train, y_train, epochs=EPOCHS, batch_size=batch_size,\n",
    "                             validation_data=(x_test, y_test, w_test), sample_weight=w_train, \n",
    "                             verbose=1, callbacks=[callback], shuffle=True)\n",
    "    \n",
    "    # Save model and history\n",
    "    classifier.save(model_dir + model_name)\n",
    "    with open(model_dir + model_name + '_history.pkl', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wvz_machine_learning",
   "language": "python",
   "name": "wvz_machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
