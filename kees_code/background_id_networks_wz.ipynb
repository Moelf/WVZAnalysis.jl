{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-29 04:36:00.324412: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-29 04:36:01.124588: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-29 04:36:01.125608: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-29 04:36:01.138109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:65:00.0 name: Quadro RTX 4000 computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 387.49GiB/s\n",
      "2022-01-29 04:36:01.138130: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-29 04:36:01.139467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-29 04:36:01.139501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-01-29 04:36:01.140935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-29 04:36:01.141147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-29 04:36:01.142617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-29 04:36:01.143340: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-29 04:36:01.146312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-29 04:36:01.146671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.errors import InvalidArgumentError\n",
    "import tensorflow as tf\n",
    "\n",
    "# Tensorflow GPU settings\n",
    "# gpu_options = tf.GPUOptions(allow_growth=True)#per_process_gpu_memory_fraction=0.5)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from scipy import interpolate\n",
    "\n",
    "from atlasify import atlasify\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/20220117_iso_e4m1_VVZ_RD.arrow')\n",
    "sig['is_signal'] = True\n",
    "# sig_test = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/SIG_2021_11_16_no_iso_TEST.arrow')\n",
    "bg_full = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/20220117_iso_e4m1_FULLBG_RD.arrow')\n",
    "bg_full['is_signal'] = False\n",
    "# bg_test = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/FULLBG_2021_11_16_no_iso_TEST.arrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_ZZ = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/20220117_iso_e4m1_ZZ_RD.arrow')\n",
    "bg_Zjets_old = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/20211129_iso_e4m1_Zjets_RD.arrow')\n",
    "bg_Zjets = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/20220117_iso_e4m1_Zjets_RD.arrow')\n",
    "bg_Zgamma = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/20220117_iso_e4m1_Zgamma_RD.arrow')\n",
    "bg_WZ = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/20220117_iso_e4m1_WZ_RD.arrow')\n",
    "bg_tZ = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/20220117_iso_e4m1_tZ_RD.arrow')\n",
    "bg_tWZ = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/20220117_iso_e4m1_tWZ_RD.arrow')\n",
    "bg_ttZ = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/20220117_iso_e4m1_ttZ_RD.arrow')\n",
    "bg_other = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/20220117_iso_e4m1_others_RD.arrow')\n",
    "\n",
    "bg_sources = [bg_ZZ, bg_Zjets, bg_Zgamma, bg_WZ, bg_tZ, bg_tWZ, bg_ttZ, bg_other]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9717740665613699\n",
      "0.008909331116206785\n",
      "0.0010556883632736617\n",
      "0.004347097929154949\n",
      "0.00016711686720929022\n",
      "0.0025379501654372405\n",
      "0.005859107932870372\n",
      "0.006691005792313908\n"
     ]
    }
   ],
   "source": [
    "for df in bg_sources:\n",
    "    print(sum(df.wgt) / sum(bg_full.wgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bg_Zjets_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bg_Zjets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat = 'Zcand_mass'\n",
    "\n",
    "\n",
    "bg_source = bg_Zjets\n",
    "\n",
    "plt.hist(bg_source[feat], weights=bg_source.wgt, bins=50)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.xlabel(feat, fontsize=12)\n",
    "plt.ylabel('Weighted events', fontsize=12)\n",
    "plt.minorticks_on()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "_, b, _ = plt.hist(bg_source[feat], weights=bg_source.wgt, density=False, bins=50, alpha=0.5, label='Bkg')\n",
    "plt.hist(sig[feat], weights=sig.wgt, density=False, bins=b, alpha=0.5, label='Sig')\n",
    "\n",
    "plt.legend(frameon=False, fontsize=12)\n",
    "\n",
    "plt.xlabel(feat, fontsize=12)\n",
    "plt.ylabel('Weighted density', fontsize=12)\n",
    "plt.minorticks_on()\n",
    "\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feats = ['Zlep1_dphi', 'Zlep2_dphi', 'Wlep1_dphi', 'Wlep2_dphi', 'pt_1', 'pt_2', 'Wlep2_pt_sqrt']\n",
    "# train_feats = ['pt_1', 'pt_2', 'pt_3', 'pt_4', 'pt_4l',\n",
    "#                'Zlep1_dphi', 'Zlep2_dphi', 'Wlep1_dphi', 'Wlep2_dphi', \n",
    "#                'Zlep1_phi', 'Zlep2_phi', 'Wlep1_phi', 'Wlep2_phi', \n",
    "#                'Zlep1_eta', 'Zlep2_eta', 'Wlep1_eta', 'Wlep2_eta',\n",
    "#                'Zlep1_pid', 'Zlep2_pid', 'Wlep1_pid', 'Wlep2_pid',\n",
    "#                'Zlep1_pt', 'Zlep2_pt', 'Wlep1_pt', 'Wlep2_pt',\n",
    "#                'METSig', 'MET', 'Nlep', 'Njet',\n",
    "#                'other_mass', 'leptonic_HT', 'total_HT', 'HT', \n",
    "#                'SR']\n",
    "\n",
    "train_feats_raw = sorted([f for f in sig.columns if f not in ['index', 'wgt', 'is_signal', 'Zcand_mass', 'chisq']])\n",
    "\n",
    "X = pd.concat([sig[train_feats_raw], bg_full[train_feats_raw]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize inputs for NN training\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "min_max_scaler.fit(X)\n",
    "\n",
    "for df in [sig, bg_full] + bg_sources:\n",
    "    df[train_feats_raw] = min_max_scaler.transform(df[train_feats_raw])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal vs WZ\n",
    "\n",
    "WZ events account for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43470979291549483"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_bg = bg_WZ\n",
    "sum(current_bg.wgt) / sum(bg_full.wgt) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "percent of the total background. The amount relative to signal is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number: 2.1478386340407623 %\n",
      "Weight: 36.52049729605499 %\n"
     ]
    }
   ],
   "source": [
    "print('Number:', len(current_bg)/len(sig) * 100, '%')\n",
    "print('Weight:', sum(current_bg.wgt)/sum(sig.wgt) * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can scan over different training setups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HT', 'MET', 'METSig', 'Njet', 'Nlep', 'SR', 'Wlep1_dphi',\n",
       "       'Wlep1_eta', 'Wlep1_phi', 'Wlep1_pid', 'Wlep1_pt', 'Wlep2_dphi',\n",
       "       'Wlep2_eta', 'Wlep2_phi', 'Wlep2_pid', 'Wlep2_pt', 'Zlep1_dphi',\n",
       "       'Zlep1_eta', 'Zlep1_phi', 'Zlep1_pid', 'Zlep1_pt', 'Zlep2_dphi',\n",
       "       'Zlep2_eta', 'Zlep2_phi', 'Zlep2_pid', 'Zlep2_pt', 'leptonic_HT',\n",
       "       'mass_4l', 'other_mass', 'pt_1', 'pt_2', 'pt_3', 'pt_4', 'pt_4l',\n",
       "       'total_HT'], dtype='<U11')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_feats_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_sets = [train_feats_raw, \n",
    "                   [f for f in train_feats_raw if f not in ['Wlep1_phi', 'Wlep2_phi', 'Zlep1_phi', 'Zlep2_phi']],\n",
    "                   [f for f in train_feats_raw if f not in ['MET', 'METSig']],\n",
    "                   [f for f in train_feats_raw if f not in ['pt_1', 'pt_2', 'pt_3', 'pt_4']],\n",
    "                   [f for f in train_feats_raw if f not in ['Njet', 'Nlep']]\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with training features: ['HT', 'MET', 'METSig', 'Njet', 'Nlep', 'SR', 'Wlep1_dphi', 'Wlep1_eta', 'Wlep1_phi', 'Wlep1_pid', 'Wlep1_pt', 'Wlep2_dphi', 'Wlep2_eta', 'Wlep2_phi', 'Wlep2_pid', 'Wlep2_pt', 'Zlep1_dphi', 'Zlep1_eta', 'Zlep1_phi', 'Zlep1_pid', 'Zlep1_pt', 'Zlep2_dphi', 'Zlep2_eta', 'Zlep2_phi', 'Zlep2_pid', 'Zlep2_pt', 'leptonic_HT', 'mass_4l', 'other_mass', 'pt_1', 'pt_2', 'pt_3', 'pt_4', 'pt_4l', 'total_HT']\n",
      "Epoch 1/5000\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 5.2510e-04 - accuracy: 0.0215 - val_loss: 5.4824e-04 - val_accuracy: 0.0210\n",
      "Epoch 2/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1789e-04 - accuracy: 0.0196 - val_loss: 5.4578e-04 - val_accuracy: 0.0210\n",
      "Epoch 3/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.3420e-04 - accuracy: 0.0210 - val_loss: 5.4375e-04 - val_accuracy: 0.0210\n",
      "Epoch 4/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.4930e-04 - accuracy: 0.0218 - val_loss: 5.4172e-04 - val_accuracy: 0.0210\n",
      "Epoch 5/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2386e-04 - accuracy: 0.0214 - val_loss: 5.3986e-04 - val_accuracy: 0.0210\n",
      "Epoch 6/5000\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 5.5396e-04 - accuracy: 0.0216 - val_loss: 5.3843e-04 - val_accuracy: 0.0210\n",
      "Epoch 7/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.3102e-04 - accuracy: 0.0207 - val_loss: 5.3690e-04 - val_accuracy: 0.0210\n",
      "Epoch 8/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.3692e-04 - accuracy: 0.0216 - val_loss: 5.3560e-04 - val_accuracy: 0.0210\n",
      "Epoch 9/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1757e-04 - accuracy: 0.0207 - val_loss: 5.3427e-04 - val_accuracy: 0.0210\n",
      "Epoch 10/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2976e-04 - accuracy: 0.0212 - val_loss: 5.3330e-04 - val_accuracy: 0.0210\n",
      "Epoch 11/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.4197e-04 - accuracy: 0.0227 - val_loss: 5.3232e-04 - val_accuracy: 0.0210\n",
      "Epoch 12/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.4436e-04 - accuracy: 0.0226 - val_loss: 5.3141e-04 - val_accuracy: 0.0210\n",
      "Epoch 13/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1297e-04 - accuracy: 0.0234 - val_loss: 5.3057e-04 - val_accuracy: 0.0210\n",
      "Epoch 14/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0223e-04 - accuracy: 0.0223 - val_loss: 5.2985e-04 - val_accuracy: 0.0210\n",
      "Epoch 15/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1532e-04 - accuracy: 0.0241 - val_loss: 5.2914e-04 - val_accuracy: 0.0210\n",
      "Epoch 16/5000\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 5.0678e-04 - accuracy: 0.0238 - val_loss: 5.2842e-04 - val_accuracy: 0.0210\n",
      "Epoch 17/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9772e-04 - accuracy: 0.0261 - val_loss: 5.2782e-04 - val_accuracy: 0.0210\n",
      "Epoch 18/5000\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 5.3005e-04 - accuracy: 0.0264 - val_loss: 5.2731e-04 - val_accuracy: 0.0210\n",
      "Epoch 19/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.3551e-04 - accuracy: 0.0271 - val_loss: 5.2683e-04 - val_accuracy: 0.0210\n",
      "Epoch 20/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.4972e-04 - accuracy: 0.0267 - val_loss: 5.2631e-04 - val_accuracy: 0.0210\n",
      "Epoch 21/5000\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 5.2866e-04 - accuracy: 0.0289 - val_loss: 5.2584e-04 - val_accuracy: 0.0210\n",
      "Epoch 22/5000\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 5.3753e-04 - accuracy: 0.0304 - val_loss: 5.2544e-04 - val_accuracy: 0.0210\n",
      "Epoch 23/5000\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 5.1893e-04 - accuracy: 0.0280 - val_loss: 5.2505e-04 - val_accuracy: 0.0210\n",
      "Epoch 24/5000\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 5.1513e-04 - accuracy: 0.0300 - val_loss: 5.2470e-04 - val_accuracy: 0.0210\n",
      "Epoch 25/5000\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 5.4678e-04 - accuracy: 0.0312 - val_loss: 5.2435e-04 - val_accuracy: 0.0210\n",
      "Epoch 26/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2032e-04 - accuracy: 0.0323 - val_loss: 5.2406e-04 - val_accuracy: 0.0211\n",
      "Epoch 27/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1941e-04 - accuracy: 0.0330 - val_loss: 5.2373e-04 - val_accuracy: 0.0211\n",
      "Epoch 28/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1105e-04 - accuracy: 0.0361 - val_loss: 5.2347e-04 - val_accuracy: 0.0212\n",
      "Epoch 29/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0746e-04 - accuracy: 0.0358 - val_loss: 5.2322e-04 - val_accuracy: 0.0213\n",
      "Epoch 30/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0498e-04 - accuracy: 0.0361 - val_loss: 5.2301e-04 - val_accuracy: 0.0215\n",
      "Epoch 31/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0608e-04 - accuracy: 0.0406 - val_loss: 5.2275e-04 - val_accuracy: 0.0217\n",
      "Epoch 32/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.3323e-04 - accuracy: 0.0421 - val_loss: 5.2256e-04 - val_accuracy: 0.0219\n",
      "Epoch 33/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.3024e-04 - accuracy: 0.0429 - val_loss: 5.2237e-04 - val_accuracy: 0.0221\n",
      "Epoch 34/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0411e-04 - accuracy: 0.0442 - val_loss: 5.2213e-04 - val_accuracy: 0.0226\n",
      "Epoch 35/5000\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 4.7944e-04 - accuracy: 0.0459 - val_loss: 5.2196e-04 - val_accuracy: 0.0231\n",
      "Epoch 36/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1181e-04 - accuracy: 0.0477 - val_loss: 5.2173e-04 - val_accuracy: 0.0241\n",
      "Epoch 37/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1613e-04 - accuracy: 0.0509 - val_loss: 5.2160e-04 - val_accuracy: 0.0247\n",
      "Epoch 38/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2086e-04 - accuracy: 0.0517 - val_loss: 5.2143e-04 - val_accuracy: 0.0262\n",
      "Epoch 39/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1942e-04 - accuracy: 0.0568 - val_loss: 5.2129e-04 - val_accuracy: 0.0273\n",
      "Epoch 40/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.3032e-04 - accuracy: 0.0573 - val_loss: 5.2116e-04 - val_accuracy: 0.0285\n",
      "Epoch 41/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1846e-04 - accuracy: 0.0608 - val_loss: 5.2102e-04 - val_accuracy: 0.0301\n",
      "Epoch 42/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0234e-04 - accuracy: 0.0637 - val_loss: 5.2091e-04 - val_accuracy: 0.0312\n",
      "Epoch 43/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.6556e-04 - accuracy: 0.0638 - val_loss: 5.2082e-04 - val_accuracy: 0.0325\n",
      "Epoch 44/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9773e-04 - accuracy: 0.0707 - val_loss: 5.2071e-04 - val_accuracy: 0.0348\n",
      "Epoch 45/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9567e-04 - accuracy: 0.0684 - val_loss: 5.2060e-04 - val_accuracy: 0.0370\n",
      "Epoch 46/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1139e-04 - accuracy: 0.0758 - val_loss: 5.2047e-04 - val_accuracy: 0.0404\n",
      "Epoch 47/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9473e-04 - accuracy: 0.0780 - val_loss: 5.2035e-04 - val_accuracy: 0.0449\n",
      "Epoch 48/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1074e-04 - accuracy: 0.0819 - val_loss: 5.2027e-04 - val_accuracy: 0.0473\n",
      "Epoch 49/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.4646e-04 - accuracy: 0.0850 - val_loss: 5.2020e-04 - val_accuracy: 0.0505\n",
      "Epoch 50/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9780e-04 - accuracy: 0.0877 - val_loss: 5.2014e-04 - val_accuracy: 0.0534\n",
      "Epoch 51/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9071e-04 - accuracy: 0.0912 - val_loss: 5.2007e-04 - val_accuracy: 0.0576\n",
      "Epoch 52/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9172e-04 - accuracy: 0.0937 - val_loss: 5.1999e-04 - val_accuracy: 0.0632\n",
      "Epoch 53/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9253e-04 - accuracy: 0.1022 - val_loss: 5.1992e-04 - val_accuracy: 0.0685\n",
      "Epoch 54/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0187e-04 - accuracy: 0.1043 - val_loss: 5.1985e-04 - val_accuracy: 0.0740\n",
      "Epoch 55/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2646e-04 - accuracy: 0.1056 - val_loss: 5.1980e-04 - val_accuracy: 0.0780\n",
      "Epoch 56/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0886e-04 - accuracy: 0.1099 - val_loss: 5.1976e-04 - val_accuracy: 0.0836\n",
      "Epoch 57/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7436e-04 - accuracy: 0.1125 - val_loss: 5.1970e-04 - val_accuracy: 0.0906\n",
      "Epoch 58/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8358e-04 - accuracy: 0.1175 - val_loss: 5.1964e-04 - val_accuracy: 0.0958\n",
      "Epoch 59/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9725e-04 - accuracy: 0.1237 - val_loss: 5.1958e-04 - val_accuracy: 0.1044\n",
      "Epoch 60/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0022e-04 - accuracy: 0.1258 - val_loss: 5.1953e-04 - val_accuracy: 0.1126\n",
      "Epoch 61/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8664e-04 - accuracy: 0.1308 - val_loss: 5.1949e-04 - val_accuracy: 0.1195\n",
      "Epoch 62/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8822e-04 - accuracy: 0.1318 - val_loss: 5.1945e-04 - val_accuracy: 0.1248\n",
      "Epoch 63/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1890e-04 - accuracy: 0.1375 - val_loss: 5.1939e-04 - val_accuracy: 0.1369\n",
      "Epoch 64/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1574e-04 - accuracy: 0.1375 - val_loss: 5.1935e-04 - val_accuracy: 0.1425\n",
      "Epoch 65/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.4987e-04 - accuracy: 0.1420 - val_loss: 5.1930e-04 - val_accuracy: 0.1511\n",
      "Epoch 66/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2310e-04 - accuracy: 0.1517 - val_loss: 5.1926e-04 - val_accuracy: 0.1585\n",
      "Epoch 67/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9281e-04 - accuracy: 0.1547 - val_loss: 5.1921e-04 - val_accuracy: 0.1689\n",
      "Epoch 68/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0686e-04 - accuracy: 0.1587 - val_loss: 5.1918e-04 - val_accuracy: 0.1747\n",
      "Epoch 69/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.4487e-04 - accuracy: 0.1654 - val_loss: 5.1915e-04 - val_accuracy: 0.1788\n",
      "Epoch 70/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0337e-04 - accuracy: 0.1691 - val_loss: 5.1911e-04 - val_accuracy: 0.1910\n",
      "Epoch 71/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2669e-04 - accuracy: 0.1676 - val_loss: 5.1910e-04 - val_accuracy: 0.1989\n",
      "Epoch 72/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9022e-04 - accuracy: 0.1733 - val_loss: 5.1907e-04 - val_accuracy: 0.2099\n",
      "Epoch 73/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1248e-04 - accuracy: 0.1753 - val_loss: 5.1904e-04 - val_accuracy: 0.2219\n",
      "Epoch 74/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0551e-04 - accuracy: 0.1852 - val_loss: 5.1903e-04 - val_accuracy: 0.2279\n",
      "Epoch 75/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0593e-04 - accuracy: 0.1864 - val_loss: 5.1901e-04 - val_accuracy: 0.2364\n",
      "Epoch 76/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7933e-04 - accuracy: 0.1931 - val_loss: 5.1898e-04 - val_accuracy: 0.2468\n",
      "Epoch 77/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1820e-04 - accuracy: 0.1981 - val_loss: 5.1896e-04 - val_accuracy: 0.2514\n",
      "Epoch 78/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0933e-04 - accuracy: 0.2049 - val_loss: 5.1891e-04 - val_accuracy: 0.2670\n",
      "Epoch 79/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8421e-04 - accuracy: 0.2052 - val_loss: 5.1890e-04 - val_accuracy: 0.2723\n",
      "Epoch 80/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0733e-04 - accuracy: 0.2102 - val_loss: 5.1887e-04 - val_accuracy: 0.2867\n",
      "Epoch 81/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1628e-04 - accuracy: 0.2152 - val_loss: 5.1885e-04 - val_accuracy: 0.2934\n",
      "Epoch 82/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8709e-04 - accuracy: 0.2186 - val_loss: 5.1882e-04 - val_accuracy: 0.3082\n",
      "Epoch 83/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2807e-04 - accuracy: 0.2203 - val_loss: 5.1880e-04 - val_accuracy: 0.3115\n",
      "Epoch 84/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2901e-04 - accuracy: 0.2272 - val_loss: 5.1879e-04 - val_accuracy: 0.3199\n",
      "Epoch 85/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7507e-04 - accuracy: 0.2346 - val_loss: 5.1878e-04 - val_accuracy: 0.3262\n",
      "Epoch 86/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8702e-04 - accuracy: 0.2380 - val_loss: 5.1876e-04 - val_accuracy: 0.3304\n",
      "Epoch 87/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2752e-04 - accuracy: 0.2331 - val_loss: 5.1874e-04 - val_accuracy: 0.3370\n",
      "Epoch 88/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2279e-04 - accuracy: 0.2452 - val_loss: 5.1872e-04 - val_accuracy: 0.3463\n",
      "Epoch 89/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9496e-04 - accuracy: 0.2464 - val_loss: 5.1870e-04 - val_accuracy: 0.3595\n",
      "Epoch 90/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.5383e-04 - accuracy: 0.2515 - val_loss: 5.1868e-04 - val_accuracy: 0.3632\n",
      "Epoch 91/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8098e-04 - accuracy: 0.2531 - val_loss: 5.1864e-04 - val_accuracy: 0.3703\n",
      "Epoch 92/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1063e-04 - accuracy: 0.2549 - val_loss: 5.1862e-04 - val_accuracy: 0.3731\n",
      "Epoch 93/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2690e-04 - accuracy: 0.2521 - val_loss: 5.1859e-04 - val_accuracy: 0.3817\n",
      "Epoch 94/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1388e-04 - accuracy: 0.2636 - val_loss: 5.1856e-04 - val_accuracy: 0.3920\n",
      "Epoch 95/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8988e-04 - accuracy: 0.2685 - val_loss: 5.1855e-04 - val_accuracy: 0.4008\n",
      "Epoch 96/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0303e-04 - accuracy: 0.2831 - val_loss: 5.1853e-04 - val_accuracy: 0.4080\n",
      "Epoch 97/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9901e-04 - accuracy: 0.2825 - val_loss: 5.1852e-04 - val_accuracy: 0.4109\n",
      "Epoch 98/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0661e-04 - accuracy: 0.2862 - val_loss: 5.1850e-04 - val_accuracy: 0.4212\n",
      "Epoch 99/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1830e-04 - accuracy: 0.2903 - val_loss: 5.1847e-04 - val_accuracy: 0.4253\n",
      "Epoch 100/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0470e-04 - accuracy: 0.2898 - val_loss: 5.1845e-04 - val_accuracy: 0.4332\n",
      "Epoch 101/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0940e-04 - accuracy: 0.2917 - val_loss: 5.1844e-04 - val_accuracy: 0.4406\n",
      "Epoch 102/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7670e-04 - accuracy: 0.2987 - val_loss: 5.1842e-04 - val_accuracy: 0.4495\n",
      "Epoch 103/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0219e-04 - accuracy: 0.2967 - val_loss: 5.1841e-04 - val_accuracy: 0.4526\n",
      "Epoch 104/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.5261e-04 - accuracy: 0.2986 - val_loss: 5.1839e-04 - val_accuracy: 0.4555\n",
      "Epoch 105/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9103e-04 - accuracy: 0.3132 - val_loss: 5.1837e-04 - val_accuracy: 0.4663\n",
      "Epoch 106/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2680e-04 - accuracy: 0.3135 - val_loss: 5.1836e-04 - val_accuracy: 0.4702\n",
      "Epoch 107/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0680e-04 - accuracy: 0.3093 - val_loss: 5.1833e-04 - val_accuracy: 0.4753\n",
      "Epoch 108/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9573e-04 - accuracy: 0.3158 - val_loss: 5.1830e-04 - val_accuracy: 0.4772\n",
      "Epoch 109/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2248e-04 - accuracy: 0.3178 - val_loss: 5.1828e-04 - val_accuracy: 0.4797\n",
      "Epoch 110/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8154e-04 - accuracy: 0.3278 - val_loss: 5.1828e-04 - val_accuracy: 0.4888\n",
      "Epoch 111/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0658e-04 - accuracy: 0.3288 - val_loss: 5.1827e-04 - val_accuracy: 0.4884\n",
      "Epoch 112/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1548e-04 - accuracy: 0.3260 - val_loss: 5.1825e-04 - val_accuracy: 0.4907\n",
      "Epoch 113/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8426e-04 - accuracy: 0.3214 - val_loss: 5.1824e-04 - val_accuracy: 0.4917\n",
      "Epoch 114/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8089e-04 - accuracy: 0.3330 - val_loss: 5.1822e-04 - val_accuracy: 0.4937\n",
      "Epoch 115/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9858e-04 - accuracy: 0.3340 - val_loss: 5.1821e-04 - val_accuracy: 0.4958\n",
      "Epoch 116/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2364e-04 - accuracy: 0.3369 - val_loss: 5.1819e-04 - val_accuracy: 0.5006\n",
      "Epoch 117/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8096e-04 - accuracy: 0.3364 - val_loss: 5.1817e-04 - val_accuracy: 0.5074\n",
      "Epoch 118/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6824e-04 - accuracy: 0.3440 - val_loss: 5.1814e-04 - val_accuracy: 0.5038\n",
      "Epoch 119/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8590e-04 - accuracy: 0.3418 - val_loss: 5.1812e-04 - val_accuracy: 0.5054\n",
      "Epoch 120/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9005e-04 - accuracy: 0.3479 - val_loss: 5.1809e-04 - val_accuracy: 0.5154\n",
      "Epoch 121/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1454e-04 - accuracy: 0.3505 - val_loss: 5.1808e-04 - val_accuracy: 0.5187\n",
      "Epoch 122/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9931e-04 - accuracy: 0.3573 - val_loss: 5.1805e-04 - val_accuracy: 0.5236\n",
      "Epoch 123/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7106e-04 - accuracy: 0.3652 - val_loss: 5.1805e-04 - val_accuracy: 0.5277\n",
      "Epoch 124/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9750e-04 - accuracy: 0.3579 - val_loss: 5.1803e-04 - val_accuracy: 0.5291\n",
      "Epoch 125/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0048e-04 - accuracy: 0.3638 - val_loss: 5.1802e-04 - val_accuracy: 0.5338\n",
      "Epoch 126/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1116e-04 - accuracy: 0.3661 - val_loss: 5.1801e-04 - val_accuracy: 0.5384\n",
      "Epoch 127/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0602e-04 - accuracy: 0.3670 - val_loss: 5.1800e-04 - val_accuracy: 0.5370\n",
      "Epoch 128/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.2853e-04 - accuracy: 0.3718 - val_loss: 5.1798e-04 - val_accuracy: 0.5463\n",
      "Epoch 129/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8286e-04 - accuracy: 0.3798 - val_loss: 5.1797e-04 - val_accuracy: 0.5478\n",
      "Epoch 130/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8603e-04 - accuracy: 0.3748 - val_loss: 5.1795e-04 - val_accuracy: 0.5514\n",
      "Epoch 131/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8955e-04 - accuracy: 0.3857 - val_loss: 5.1794e-04 - val_accuracy: 0.5530\n",
      "Epoch 132/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1374e-04 - accuracy: 0.3842 - val_loss: 5.1794e-04 - val_accuracy: 0.5632\n",
      "Epoch 133/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2752e-04 - accuracy: 0.3919 - val_loss: 5.1793e-04 - val_accuracy: 0.5626\n",
      "Epoch 134/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1841e-04 - accuracy: 0.3933 - val_loss: 5.1793e-04 - val_accuracy: 0.5614\n",
      "Epoch 135/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2704e-04 - accuracy: 0.3976 - val_loss: 5.1793e-04 - val_accuracy: 0.5648\n",
      "Epoch 136/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8313e-04 - accuracy: 0.3957 - val_loss: 5.1791e-04 - val_accuracy: 0.5690\n",
      "Epoch 137/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2135e-04 - accuracy: 0.3980 - val_loss: 5.1791e-04 - val_accuracy: 0.5670\n",
      "Epoch 138/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9284e-04 - accuracy: 0.4061 - val_loss: 5.1789e-04 - val_accuracy: 0.5754\n",
      "Epoch 139/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1194e-04 - accuracy: 0.4012 - val_loss: 5.1788e-04 - val_accuracy: 0.5734\n",
      "Epoch 140/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2658e-04 - accuracy: 0.4029 - val_loss: 5.1787e-04 - val_accuracy: 0.5740\n",
      "Epoch 141/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8108e-04 - accuracy: 0.4087 - val_loss: 5.1785e-04 - val_accuracy: 0.5784\n",
      "Epoch 142/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0400e-04 - accuracy: 0.4143 - val_loss: 5.1784e-04 - val_accuracy: 0.5812\n",
      "Epoch 143/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0046e-04 - accuracy: 0.4130 - val_loss: 5.1782e-04 - val_accuracy: 0.5847\n",
      "Epoch 144/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8585e-04 - accuracy: 0.4236 - val_loss: 5.1780e-04 - val_accuracy: 0.5822\n",
      "Epoch 145/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9335e-04 - accuracy: 0.4187 - val_loss: 5.1777e-04 - val_accuracy: 0.5841\n",
      "Epoch 146/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7505e-04 - accuracy: 0.4214 - val_loss: 5.1775e-04 - val_accuracy: 0.5877\n",
      "Epoch 147/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9360e-04 - accuracy: 0.4214 - val_loss: 5.1773e-04 - val_accuracy: 0.5852\n",
      "Epoch 148/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6431e-04 - accuracy: 0.4262 - val_loss: 5.1771e-04 - val_accuracy: 0.5860\n",
      "Epoch 149/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1470e-04 - accuracy: 0.4268 - val_loss: 5.1769e-04 - val_accuracy: 0.5867\n",
      "Epoch 150/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1468e-04 - accuracy: 0.4195 - val_loss: 5.1767e-04 - val_accuracy: 0.5867\n",
      "Epoch 151/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0157e-04 - accuracy: 0.4302 - val_loss: 5.1765e-04 - val_accuracy: 0.5844\n",
      "Epoch 152/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9579e-04 - accuracy: 0.4285 - val_loss: 5.1763e-04 - val_accuracy: 0.5865\n",
      "Epoch 153/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2948e-04 - accuracy: 0.4209 - val_loss: 5.1761e-04 - val_accuracy: 0.5866\n",
      "Epoch 154/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8318e-04 - accuracy: 0.4330 - val_loss: 5.1760e-04 - val_accuracy: 0.5871\n",
      "Epoch 155/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9792e-04 - accuracy: 0.4330 - val_loss: 5.1758e-04 - val_accuracy: 0.5902\n",
      "Epoch 156/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7872e-04 - accuracy: 0.4382 - val_loss: 5.1756e-04 - val_accuracy: 0.5853\n",
      "Epoch 157/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2107e-04 - accuracy: 0.4309 - val_loss: 5.1755e-04 - val_accuracy: 0.5842\n",
      "Epoch 158/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0334e-04 - accuracy: 0.4339 - val_loss: 5.1754e-04 - val_accuracy: 0.5811\n",
      "Epoch 159/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8212e-04 - accuracy: 0.4387 - val_loss: 5.1752e-04 - val_accuracy: 0.5857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1659e-04 - accuracy: 0.4354 - val_loss: 5.1751e-04 - val_accuracy: 0.5882\n",
      "Epoch 161/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1315e-04 - accuracy: 0.4398 - val_loss: 5.1749e-04 - val_accuracy: 0.5867\n",
      "Epoch 162/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7210e-04 - accuracy: 0.4414 - val_loss: 5.1748e-04 - val_accuracy: 0.5873\n",
      "Epoch 163/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0321e-04 - accuracy: 0.4434 - val_loss: 5.1745e-04 - val_accuracy: 0.5891\n",
      "Epoch 164/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1254e-04 - accuracy: 0.4527 - val_loss: 5.1744e-04 - val_accuracy: 0.5915\n",
      "Epoch 165/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.3578e-04 - accuracy: 0.4451 - val_loss: 5.1742e-04 - val_accuracy: 0.5905\n",
      "Epoch 166/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8525e-04 - accuracy: 0.4507 - val_loss: 5.1740e-04 - val_accuracy: 0.5932\n",
      "Epoch 167/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8450e-04 - accuracy: 0.4517 - val_loss: 5.1739e-04 - val_accuracy: 0.5937\n",
      "Epoch 168/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1306e-04 - accuracy: 0.4570 - val_loss: 5.1738e-04 - val_accuracy: 0.5932\n",
      "Epoch 169/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1331e-04 - accuracy: 0.4509 - val_loss: 5.1736e-04 - val_accuracy: 0.5931\n",
      "Epoch 170/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1268e-04 - accuracy: 0.4516 - val_loss: 5.1735e-04 - val_accuracy: 0.5904\n",
      "Epoch 171/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2318e-04 - accuracy: 0.4550 - val_loss: 5.1734e-04 - val_accuracy: 0.5932\n",
      "Epoch 172/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7525e-04 - accuracy: 0.4637 - val_loss: 5.1735e-04 - val_accuracy: 0.6006\n",
      "Epoch 173/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0971e-04 - accuracy: 0.4587 - val_loss: 5.1734e-04 - val_accuracy: 0.5975\n",
      "Epoch 174/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2076e-04 - accuracy: 0.4581 - val_loss: 5.1733e-04 - val_accuracy: 0.5986\n",
      "Epoch 175/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1420e-04 - accuracy: 0.4642 - val_loss: 5.1732e-04 - val_accuracy: 0.5962\n",
      "Epoch 176/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1158e-04 - accuracy: 0.4630 - val_loss: 5.1730e-04 - val_accuracy: 0.5952\n",
      "Epoch 177/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0331e-04 - accuracy: 0.4672 - val_loss: 5.1729e-04 - val_accuracy: 0.5957\n",
      "Epoch 178/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7837e-04 - accuracy: 0.4605 - val_loss: 5.1728e-04 - val_accuracy: 0.5935\n",
      "Epoch 179/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8002e-04 - accuracy: 0.4649 - val_loss: 5.1726e-04 - val_accuracy: 0.5927\n",
      "Epoch 180/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1186e-04 - accuracy: 0.4711 - val_loss: 5.1725e-04 - val_accuracy: 0.5917\n",
      "Epoch 181/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0591e-04 - accuracy: 0.4715 - val_loss: 5.1723e-04 - val_accuracy: 0.5885\n",
      "Epoch 182/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7674e-04 - accuracy: 0.4658 - val_loss: 5.1721e-04 - val_accuracy: 0.5898\n",
      "Epoch 183/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7282e-04 - accuracy: 0.4653 - val_loss: 5.1719e-04 - val_accuracy: 0.5886\n",
      "Epoch 184/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2143e-04 - accuracy: 0.4624 - val_loss: 5.1718e-04 - val_accuracy: 0.5877\n",
      "Epoch 185/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2653e-04 - accuracy: 0.4707 - val_loss: 5.1717e-04 - val_accuracy: 0.5907\n",
      "Epoch 186/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9903e-04 - accuracy: 0.4656 - val_loss: 5.1716e-04 - val_accuracy: 0.5941\n",
      "Epoch 187/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8467e-04 - accuracy: 0.4705 - val_loss: 5.1714e-04 - val_accuracy: 0.5940\n",
      "Epoch 188/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7782e-04 - accuracy: 0.4709 - val_loss: 5.1712e-04 - val_accuracy: 0.5925\n",
      "Epoch 189/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8997e-04 - accuracy: 0.4738 - val_loss: 5.1710e-04 - val_accuracy: 0.5912\n",
      "Epoch 190/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0533e-04 - accuracy: 0.4765 - val_loss: 5.1708e-04 - val_accuracy: 0.5893\n",
      "Epoch 191/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8278e-04 - accuracy: 0.4787 - val_loss: 5.1707e-04 - val_accuracy: 0.5944\n",
      "Epoch 192/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8121e-04 - accuracy: 0.4855 - val_loss: 5.1706e-04 - val_accuracy: 0.5961\n",
      "Epoch 193/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6165e-04 - accuracy: 0.4809 - val_loss: 5.1705e-04 - val_accuracy: 0.5979\n",
      "Epoch 194/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.3687e-04 - accuracy: 0.4779 - val_loss: 5.1704e-04 - val_accuracy: 0.5946\n",
      "Epoch 195/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0935e-04 - accuracy: 0.4890 - val_loss: 5.1703e-04 - val_accuracy: 0.5972\n",
      "Epoch 196/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9187e-04 - accuracy: 0.4830 - val_loss: 5.1701e-04 - val_accuracy: 0.5977\n",
      "Epoch 197/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.5190e-04 - accuracy: 0.4857 - val_loss: 5.1700e-04 - val_accuracy: 0.6031\n",
      "Epoch 198/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6616e-04 - accuracy: 0.4897 - val_loss: 5.1697e-04 - val_accuracy: 0.6027\n",
      "Epoch 199/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2052e-04 - accuracy: 0.4841 - val_loss: 5.1696e-04 - val_accuracy: 0.5992\n",
      "Epoch 200/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.3129e-04 - accuracy: 0.4849 - val_loss: 5.1695e-04 - val_accuracy: 0.6027\n",
      "Epoch 201/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8635e-04 - accuracy: 0.4917 - val_loss: 5.1694e-04 - val_accuracy: 0.6011\n",
      "Epoch 202/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6643e-04 - accuracy: 0.4941 - val_loss: 5.1694e-04 - val_accuracy: 0.6030\n",
      "Epoch 203/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9395e-04 - accuracy: 0.4911 - val_loss: 5.1691e-04 - val_accuracy: 0.6017\n",
      "Epoch 204/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9434e-04 - accuracy: 0.4932 - val_loss: 5.1690e-04 - val_accuracy: 0.6042\n",
      "Epoch 205/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2363e-04 - accuracy: 0.4912 - val_loss: 5.1689e-04 - val_accuracy: 0.6064\n",
      "Epoch 206/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9896e-04 - accuracy: 0.5026 - val_loss: 5.1687e-04 - val_accuracy: 0.6063\n",
      "Epoch 207/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0128e-04 - accuracy: 0.5004 - val_loss: 5.1685e-04 - val_accuracy: 0.6081\n",
      "Epoch 208/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6845e-04 - accuracy: 0.5043 - val_loss: 5.1684e-04 - val_accuracy: 0.6101\n",
      "Epoch 209/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7644e-04 - accuracy: 0.5027 - val_loss: 5.1681e-04 - val_accuracy: 0.6109\n",
      "Epoch 210/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.4239e-04 - accuracy: 0.5110 - val_loss: 5.1680e-04 - val_accuracy: 0.6098\n",
      "Epoch 211/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1552e-04 - accuracy: 0.5094 - val_loss: 5.1679e-04 - val_accuracy: 0.6106\n",
      "Epoch 212/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7847e-04 - accuracy: 0.5052 - val_loss: 5.1677e-04 - val_accuracy: 0.6129\n",
      "Epoch 213/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7789e-04 - accuracy: 0.5113 - val_loss: 5.1676e-04 - val_accuracy: 0.6123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.5648e-04 - accuracy: 0.5129 - val_loss: 5.1674e-04 - val_accuracy: 0.6116\n",
      "Epoch 215/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.3004e-04 - accuracy: 0.5074 - val_loss: 5.1671e-04 - val_accuracy: 0.6098\n",
      "Epoch 216/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8800e-04 - accuracy: 0.5125 - val_loss: 5.1670e-04 - val_accuracy: 0.6105\n",
      "Epoch 217/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8369e-04 - accuracy: 0.5080 - val_loss: 5.1667e-04 - val_accuracy: 0.6103\n",
      "Epoch 218/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1691e-04 - accuracy: 0.5063 - val_loss: 5.1666e-04 - val_accuracy: 0.6110\n",
      "Epoch 219/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1278e-04 - accuracy: 0.5033 - val_loss: 5.1665e-04 - val_accuracy: 0.6130\n",
      "Epoch 220/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7326e-04 - accuracy: 0.5143 - val_loss: 5.1663e-04 - val_accuracy: 0.6141\n",
      "Epoch 221/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1932e-04 - accuracy: 0.5109 - val_loss: 5.1661e-04 - val_accuracy: 0.6103\n",
      "Epoch 222/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1594e-04 - accuracy: 0.5162 - val_loss: 5.1660e-04 - val_accuracy: 0.6145\n",
      "Epoch 223/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6811e-04 - accuracy: 0.5245 - val_loss: 5.1659e-04 - val_accuracy: 0.6150\n",
      "Epoch 224/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1606e-04 - accuracy: 0.5171 - val_loss: 5.1657e-04 - val_accuracy: 0.6143\n",
      "Epoch 225/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1863e-04 - accuracy: 0.5203 - val_loss: 5.1656e-04 - val_accuracy: 0.6157\n",
      "Epoch 226/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0257e-04 - accuracy: 0.5210 - val_loss: 5.1656e-04 - val_accuracy: 0.6169\n",
      "Epoch 227/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6718e-04 - accuracy: 0.5208 - val_loss: 5.1654e-04 - val_accuracy: 0.6171\n",
      "Epoch 228/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9498e-04 - accuracy: 0.5162 - val_loss: 5.1652e-04 - val_accuracy: 0.6170\n",
      "Epoch 229/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7938e-04 - accuracy: 0.5250 - val_loss: 5.1649e-04 - val_accuracy: 0.6170\n",
      "Epoch 230/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1504e-04 - accuracy: 0.5253 - val_loss: 5.1646e-04 - val_accuracy: 0.6148\n",
      "Epoch 231/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.4029e-04 - accuracy: 0.5220 - val_loss: 5.1645e-04 - val_accuracy: 0.6164\n",
      "Epoch 232/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9337e-04 - accuracy: 0.5254 - val_loss: 5.1643e-04 - val_accuracy: 0.6181\n",
      "Epoch 233/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0936e-04 - accuracy: 0.5282 - val_loss: 5.1640e-04 - val_accuracy: 0.6152\n",
      "Epoch 234/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0436e-04 - accuracy: 0.5248 - val_loss: 5.1639e-04 - val_accuracy: 0.6160\n",
      "Epoch 235/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6930e-04 - accuracy: 0.5293 - val_loss: 5.1637e-04 - val_accuracy: 0.6190\n",
      "Epoch 236/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1575e-04 - accuracy: 0.5230 - val_loss: 5.1636e-04 - val_accuracy: 0.6185\n",
      "Epoch 237/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7651e-04 - accuracy: 0.5277 - val_loss: 5.1633e-04 - val_accuracy: 0.6183\n",
      "Epoch 238/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9977e-04 - accuracy: 0.5275 - val_loss: 5.1631e-04 - val_accuracy: 0.6171\n",
      "Epoch 239/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2245e-04 - accuracy: 0.5339 - val_loss: 5.1630e-04 - val_accuracy: 0.6199\n",
      "Epoch 240/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6522e-04 - accuracy: 0.5321 - val_loss: 5.1628e-04 - val_accuracy: 0.6216\n",
      "Epoch 241/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9560e-04 - accuracy: 0.5294 - val_loss: 5.1626e-04 - val_accuracy: 0.6213\n",
      "Epoch 242/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0176e-04 - accuracy: 0.5280 - val_loss: 5.1623e-04 - val_accuracy: 0.6193\n",
      "Epoch 243/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8697e-04 - accuracy: 0.5348 - val_loss: 5.1622e-04 - val_accuracy: 0.6231\n",
      "Epoch 244/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0065e-04 - accuracy: 0.5324 - val_loss: 5.1619e-04 - val_accuracy: 0.6228\n",
      "Epoch 245/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7683e-04 - accuracy: 0.5404 - val_loss: 5.1618e-04 - val_accuracy: 0.6226\n",
      "Epoch 246/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8457e-04 - accuracy: 0.5306 - val_loss: 5.1616e-04 - val_accuracy: 0.6233\n",
      "Epoch 247/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2031e-04 - accuracy: 0.5393 - val_loss: 5.1613e-04 - val_accuracy: 0.6223\n",
      "Epoch 248/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9523e-04 - accuracy: 0.5362 - val_loss: 5.1611e-04 - val_accuracy: 0.6223\n",
      "Epoch 249/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.3654e-04 - accuracy: 0.5344 - val_loss: 5.1609e-04 - val_accuracy: 0.6213\n",
      "Epoch 250/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9852e-04 - accuracy: 0.5418 - val_loss: 5.1607e-04 - val_accuracy: 0.6224\n",
      "Epoch 251/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8331e-04 - accuracy: 0.5389 - val_loss: 5.1605e-04 - val_accuracy: 0.6208\n",
      "Epoch 252/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8713e-04 - accuracy: 0.5405 - val_loss: 5.1603e-04 - val_accuracy: 0.6185\n",
      "Epoch 253/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2957e-04 - accuracy: 0.5314 - val_loss: 5.1600e-04 - val_accuracy: 0.6151\n",
      "Epoch 254/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6315e-04 - accuracy: 0.5340 - val_loss: 5.1597e-04 - val_accuracy: 0.6148\n",
      "Epoch 255/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.6749e-04 - accuracy: 0.5327 - val_loss: 5.1594e-04 - val_accuracy: 0.6128\n",
      "Epoch 256/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2237e-04 - accuracy: 0.5295 - val_loss: 5.1591e-04 - val_accuracy: 0.6118\n",
      "Epoch 257/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1110e-04 - accuracy: 0.5381 - val_loss: 5.1589e-04 - val_accuracy: 0.6130\n",
      "Epoch 258/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7419e-04 - accuracy: 0.5386 - val_loss: 5.1589e-04 - val_accuracy: 0.6178\n",
      "Epoch 259/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0489e-04 - accuracy: 0.5365 - val_loss: 5.1589e-04 - val_accuracy: 0.6206\n",
      "Epoch 260/5000\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 4.9305e-04 - accuracy: 0.5390 - val_loss: 5.1588e-04 - val_accuracy: 0.6246\n",
      "Epoch 261/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.6420e-04 - accuracy: 0.5457 - val_loss: 5.1586e-04 - val_accuracy: 0.6235\n",
      "Epoch 262/5000\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 5.1403e-04 - accuracy: 0.5459 - val_loss: 5.1586e-04 - val_accuracy: 0.6282\n",
      "Epoch 263/5000\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 4.9120e-04 - accuracy: 0.5554 - val_loss: 5.1584e-04 - val_accuracy: 0.6289\n",
      "Epoch 264/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6883e-04 - accuracy: 0.5453 - val_loss: 5.1582e-04 - val_accuracy: 0.6291\n",
      "Epoch 265/5000\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 5.0503e-04 - accuracy: 0.5511 - val_loss: 5.1580e-04 - val_accuracy: 0.6302\n",
      "Epoch 266/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1594e-04 - accuracy: 0.5505 - val_loss: 5.1580e-04 - val_accuracy: 0.6336\n",
      "Epoch 267/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7978e-04 - accuracy: 0.5569 - val_loss: 5.1579e-04 - val_accuracy: 0.6340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0701e-04 - accuracy: 0.5535 - val_loss: 5.1577e-04 - val_accuracy: 0.6345\n",
      "Epoch 269/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9876e-04 - accuracy: 0.5593 - val_loss: 5.1574e-04 - val_accuracy: 0.6346\n",
      "Epoch 270/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6709e-04 - accuracy: 0.5557 - val_loss: 5.1571e-04 - val_accuracy: 0.6341\n",
      "Epoch 271/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6731e-04 - accuracy: 0.5597 - val_loss: 5.1570e-04 - val_accuracy: 0.6361\n",
      "Epoch 272/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6977e-04 - accuracy: 0.5569 - val_loss: 5.1569e-04 - val_accuracy: 0.6372\n",
      "Epoch 273/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9432e-04 - accuracy: 0.5655 - val_loss: 5.1565e-04 - val_accuracy: 0.6341\n",
      "Epoch 274/5000\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 4.8242e-04 - accuracy: 0.5567 - val_loss: 5.1563e-04 - val_accuracy: 0.6358\n",
      "Epoch 275/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7908e-04 - accuracy: 0.5567 - val_loss: 5.1561e-04 - val_accuracy: 0.6357\n",
      "Epoch 276/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1924e-04 - accuracy: 0.5636 - val_loss: 5.1557e-04 - val_accuracy: 0.6325\n",
      "Epoch 277/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0164e-04 - accuracy: 0.5520 - val_loss: 5.1555e-04 - val_accuracy: 0.6334\n",
      "Epoch 278/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7916e-04 - accuracy: 0.5592 - val_loss: 5.1554e-04 - val_accuracy: 0.6343\n",
      "Epoch 279/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0771e-04 - accuracy: 0.5660 - val_loss: 5.1551e-04 - val_accuracy: 0.6331\n",
      "Epoch 280/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6659e-04 - accuracy: 0.5608 - val_loss: 5.1549e-04 - val_accuracy: 0.6353\n",
      "Epoch 281/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0157e-04 - accuracy: 0.5645 - val_loss: 5.1548e-04 - val_accuracy: 0.6350\n",
      "Epoch 282/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8946e-04 - accuracy: 0.5627 - val_loss: 5.1546e-04 - val_accuracy: 0.6354\n",
      "Epoch 283/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6911e-04 - accuracy: 0.5650 - val_loss: 5.1543e-04 - val_accuracy: 0.6365\n",
      "Epoch 284/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8320e-04 - accuracy: 0.5630 - val_loss: 5.1540e-04 - val_accuracy: 0.6377\n",
      "Epoch 285/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9911e-04 - accuracy: 0.5597 - val_loss: 5.1539e-04 - val_accuracy: 0.6404\n",
      "Epoch 286/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0474e-04 - accuracy: 0.5742 - val_loss: 5.1535e-04 - val_accuracy: 0.6361\n",
      "Epoch 287/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1048e-04 - accuracy: 0.5673 - val_loss: 5.1534e-04 - val_accuracy: 0.6421\n",
      "Epoch 288/5000\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 4.6551e-04 - accuracy: 0.5699 - val_loss: 5.1531e-04 - val_accuracy: 0.6402\n",
      "Epoch 289/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8852e-04 - accuracy: 0.5687 - val_loss: 5.1529e-04 - val_accuracy: 0.6412\n",
      "Epoch 290/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0007e-04 - accuracy: 0.5717 - val_loss: 5.1526e-04 - val_accuracy: 0.6417\n",
      "Epoch 291/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6970e-04 - accuracy: 0.5763 - val_loss: 5.1524e-04 - val_accuracy: 0.6429\n",
      "Epoch 292/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.9916e-04 - accuracy: 0.5735 - val_loss: 5.1521e-04 - val_accuracy: 0.6404\n",
      "Epoch 293/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.0431e-04 - accuracy: 0.5769 - val_loss: 5.1521e-04 - val_accuracy: 0.6463\n",
      "Epoch 294/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1087e-04 - accuracy: 0.5777 - val_loss: 5.1518e-04 - val_accuracy: 0.6457\n",
      "Epoch 295/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2027e-04 - accuracy: 0.5759 - val_loss: 5.1516e-04 - val_accuracy: 0.6443\n",
      "Epoch 296/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.5998e-04 - accuracy: 0.5753 - val_loss: 5.1512e-04 - val_accuracy: 0.6430\n",
      "Epoch 297/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6072e-04 - accuracy: 0.5772 - val_loss: 5.1511e-04 - val_accuracy: 0.6441\n",
      "Epoch 298/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8187e-04 - accuracy: 0.5761 - val_loss: 5.1509e-04 - val_accuracy: 0.6441\n",
      "Epoch 299/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7961e-04 - accuracy: 0.5830 - val_loss: 5.1508e-04 - val_accuracy: 0.6468\n",
      "Epoch 300/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1296e-04 - accuracy: 0.5844 - val_loss: 5.1504e-04 - val_accuracy: 0.6449\n",
      "Epoch 301/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8820e-04 - accuracy: 0.5862 - val_loss: 5.1503e-04 - val_accuracy: 0.6448\n",
      "Epoch 302/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.2594e-04 - accuracy: 0.5791 - val_loss: 5.1501e-04 - val_accuracy: 0.6449\n",
      "Epoch 303/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8887e-04 - accuracy: 0.5734 - val_loss: 5.1499e-04 - val_accuracy: 0.6461\n",
      "Epoch 304/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.7681e-04 - accuracy: 0.5799 - val_loss: 5.1497e-04 - val_accuracy: 0.6486\n",
      "Epoch 305/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8866e-04 - accuracy: 0.5801 - val_loss: 5.1495e-04 - val_accuracy: 0.6472\n",
      "Epoch 306/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.6686e-04 - accuracy: 0.5870 - val_loss: 5.1491e-04 - val_accuracy: 0.6445\n",
      "Epoch 307/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8202e-04 - accuracy: 0.5771 - val_loss: 5.1488e-04 - val_accuracy: 0.6444\n",
      "Epoch 308/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 4.8770e-04 - accuracy: 0.5777 - val_loss: 5.1485e-04 - val_accuracy: 0.6441\n",
      "Epoch 309/5000\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 5.1858e-04 - accuracy: 0.5773 - val_loss: 5.1482e-04 - val_accuracy: 0.6427\n",
      "Epoch 310/5000\n",
      "41/67 [=================>............] - ETA: 0s - loss: 5.1078e-04 - accuracy: 0.5840"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5000\n",
    "patience = 500\n",
    "batch_size = 512\n",
    "num_nodes = 32\n",
    "dropout = 0.1\n",
    "learn_rate = 1e-5\n",
    "\n",
    "for i, train_feats in enumerate(train_feat_sets):\n",
    "    print('Running with training features:', train_feats)\n",
    "    # Save training setup\n",
    "    with open('models/background_id_models/classifier_WZ_train_feat_test_' + str(i) + '_setup.txt', \n",
    "              'w') as file:\n",
    "        file.write('Epochs: ' + str(EPOCHS) + '\\n')\n",
    "        file.write('Patience: ' + str(patience) + '\\n')\n",
    "        file.write('Learning rate: ' + str(learn_rate) + '\\n')\n",
    "        file.write('Batch size: ' + str(batch_size) + '\\n\\n')\n",
    "        file.write('Training features:\\n' + '\\n'.join(train_feats))\n",
    "    \n",
    "    # Generate train and test samples\n",
    "    sig_train, sig_test = train_test_split(sig[train_feats + ['wgt']], train_size=0.5, random_state=314)\n",
    "    bg_train, bg_test = train_test_split(current_bg[train_feats + ['wgt']], train_size=0.5, random_state=314)\n",
    "\n",
    "    n_sig = sum(sig_train.wgt)\n",
    "    n_bg = sum(bg_train.wgt)\n",
    "\n",
    "    x_train_sig = sig_train[train_feats]\n",
    "    x_train_bg = bg_train[train_feats]\n",
    "\n",
    "    x_train = pd.concat([x_train_sig, x_train_bg])\n",
    "    y_train = np.concatenate([np.ones(len(sig_train)), np.zeros(len(bg_train))])\n",
    "    w_train = pd.Series(np.concatenate([(n_sig + n_bg) / n_sig * sig_train['wgt'], \n",
    "                                        (n_sig + n_bg) / n_bg * bg_train['wgt']]))\n",
    "\n",
    "    n_sig_test = sum(sig_test.wgt)\n",
    "    n_bg_test = sum(bg_test.wgt)\n",
    "\n",
    "    x_test = pd.concat([sig_test[train_feats], bg_test[train_feats]])\n",
    "    y_test = np.concatenate([np.ones(len(sig_test)), np.zeros(len(bg_test))])\n",
    "    w_test = pd.Series(np.concatenate([(n_sig_test + n_bg_test) / n_sig_test * sig_test['wgt'], \n",
    "                                       (n_sig_test + n_bg_test) / n_bg_test * bg_test['wgt']]))\n",
    "    \n",
    "    # Generate and fit model\n",
    "    K.clear_session()\n",
    "    classifier_WZ = Sequential()\n",
    "    classifier_WZ.add(Dense(num_nodes, input_dim=x_train.shape[1], activation='relu')) \n",
    "    classifier_WZ.add(Dropout(dropout))\n",
    "    classifier_WZ.add(Dense(num_nodes, activation='relu'))\n",
    "    classifier_WZ.add(Dropout(dropout))\n",
    "    classifier_WZ.add(Dense(num_nodes, activation='relu'))\n",
    "    classifier_WZ.add(Dropout(dropout))\n",
    "    classifier_WZ.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=learn_rate)\n",
    "    classifier_WZ.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    # Early stopping\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "\n",
    "    history = classifier_WZ.fit(x_train, y_train, epochs=EPOCHS, batch_size=batch_size,\n",
    "                                validation_data=(x_test, y_test, w_test), sample_weight=w_train, \n",
    "                                verbose=1, callbacks=[callback], shuffle=True)\n",
    "    \n",
    "    # Save model and history\n",
    "    classifier_WZ.save('models/background_id_models/classifier_WZ_train_feat_test_' + str(i))\n",
    "    with open('models/background_id_models/classifier_WZ_train_feat_test_' + str(i) + '_history.pkl', \n",
    "              'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wvz_machine_learning",
   "language": "python",
   "name": "wvz_machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
