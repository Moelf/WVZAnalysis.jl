{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.errors import InvalidArgumentError\n",
    "import tensorflow as tf\n",
    "\n",
    "# Tensorflow GPU settings\n",
    "# gpu_options = tf.GPUOptions(allow_growth=True)#per_process_gpu_memory_fraction=0.5)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from scipy import interpolate\n",
    "\n",
    "from atlasify import atlasify\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import plot_util\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we are loading the FULL signal and background datasets\n",
    "sig = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/20220301_ELReLMIs54_MUReLMIs31_btag77_VVZ.arrow')\n",
    "sig['source'] = 'Signal'\n",
    "sig['is_signal'] = True\n",
    "# bg = pd.read_feather(('/home/grabanal/WVZ/gabriel_ML_data/'\n",
    "#                            + '20220301_ELReLMIs54_MUReLMIs31_btag77_FULLBG.arrow'))\n",
    "# bg['is_signal'] = False\n",
    "\n",
    "bg_others = pd.read_feather(('/home/grabanal/WVZ/gabriel_ML_data/'\n",
    "                             + '20220301_ELReLMIs54_MUReLMIs31_btag77_others.arrow'))\n",
    "bg_others['source'] = 'Other'\n",
    "\n",
    "bg_ttZ = pd.read_feather(('/home/grabanal/WVZ/gabriel_ML_data/'\n",
    "                          + '20220301_ELReLMIs54_MUReLMIs31_btag77_ttZ.arrow'))\n",
    "bg_ttZ['source'] = 'ttZ'\n",
    "\n",
    "bg_tWZ = pd.read_feather(('/home/grabanal/WVZ/gabriel_ML_data/'\n",
    "                          + '20220301_ELReLMIs54_MUReLMIs31_btag77_tWZ.arrow'))\n",
    "bg_tWZ['source'] = 'tWZ'\n",
    "\n",
    "bg_tZ = pd.read_feather(('/home/grabanal/WVZ/gabriel_ML_data/'\n",
    "                         + '20220301_ELReLMIs54_MUReLMIs31_btag77_tZ.arrow'))\n",
    "bg_tZ['source'] = 'tZ'\n",
    "\n",
    "bg_WZ = pd.read_feather(('/home/grabanal/WVZ/gabriel_ML_data/'\n",
    "                         + '20220301_ELReLMIs54_MUReLMIs31_btag77_WZ.arrow'))\n",
    "bg_WZ['source'] = 'WZ'\n",
    "\n",
    "bg_Zgamma = pd.read_feather(('/home/grabanal/WVZ/gabriel_ML_data/'\n",
    "                             + '20220301_ELReLMIs54_MUReLMIs31_btag77_Zgamma.arrow'))\n",
    "bg_Zgamma['source'] = 'Z + gamma'\n",
    "\n",
    "bg_Zjets = pd.read_feather(('/home/grabanal/WVZ/gabriel_ML_data/'\n",
    "                            + '20220301_ELReLMIs54_MUReLMIs31_btag77_Zjets.arrow'))\n",
    "bg_Zjets['source'] = 'Z + jets'\n",
    "\n",
    "bg_ZZ = pd.read_feather(('/home/grabanal/WVZ/gabriel_ML_data/'\n",
    "                         + '20220301_ELReLMIs54_MUReLMIs31_btag77_ZZ.arrow'))\n",
    "bg_ZZ['source'] = 'ZZ'\n",
    "\n",
    "bg = pd.concat([bg_others, bg_ttZ, bg_tWZ, bg_tZ, bg_WZ, bg_Zgamma, bg_Zjets, bg_ZZ])\n",
    "bg['is_signal'] = False\n",
    "\n",
    "train_feats = sorted([f for f in sig.columns if f not in ['index', 'wgt', 'is_signal', \n",
    "                                                          'v_j_btag77', 'v_j_btag60', \n",
    "                                                          'v_j_btag85', 'v_j_btagCont', 'v_j_btag70', \n",
    "                                                          'source']])\n",
    "print('Using the following training features:')\n",
    "print(sorted(train_feats))\n",
    "\n",
    "with open('../min_max_scale_params.json') as json_file:\n",
    "    min_max_scale_params = json.load(json_file)\n",
    "\n",
    "for df in [sig, bg]:\n",
    "    for train_feat in train_feats:\n",
    "        scale_val = min_max_scale_params['scale'][train_feat]\n",
    "        min_val = min_max_scale_params['min'][train_feat]\n",
    "        \n",
    "        df[train_feat] = df[train_feat] * scale_val + min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut to 4l-SF (in Z) signal region\n",
    "bg = bg[bg.SR == 0]\n",
    "sig = sig[sig.SR == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup k-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat([sig[train_feats + ['wgt', 'is_signal', 'source']], \n",
    "                           bg[train_feats + ['wgt', 'is_signal', 'source']]], \n",
    "                          ignore_index=True)\n",
    "combined_labels = np.concatenate([np.ones(len(sig)), np.zeros(len(bg))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_FOLDS = 5\n",
    "k_folder = StratifiedKFold(n_splits = K_FOLDS, random_state=314, shuffle=True)\n",
    "\n",
    "# Assign k-folds\n",
    "combined_data['k_fold'] = -1\n",
    "for i, (_, test_index) in enumerate(k_folder.split(combined_data, combined_labels)):\n",
    "    combined_data.loc[test_index, 'k_fold'] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10000\n",
    "PATIENCE = 200\n",
    "BATCH_SIZE = 1024\n",
    "NUM_NODES = 64\n",
    "DROPOUT = 0.1\n",
    "LEARN_RATE = 1e-5\n",
    "\n",
    "def make_model(input_dim, num_nodes, dropout, learn_rate):\n",
    "    # Generate and fit model\n",
    "    K.clear_session()\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(num_nodes, input_dim=input_dim, activation='relu')) \n",
    "    classifier.add(Dropout(dropout))\n",
    "    classifier.add(Dense(num_nodes, activation='relu'))\n",
    "    classifier.add(Dropout(dropout))\n",
    "    classifier.add(Dense(num_nodes, activation='relu'))\n",
    "    classifier.add(Dropout(dropout))\n",
    "    classifier.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=learn_rate)\n",
    "    classifier.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "models = [None] * K_FOLDS\n",
    "\n",
    "for k in range(K_FOLDS):\n",
    "    # Generate train and validation samples\n",
    "    # The test sample has k-index k\n",
    "    # The validation sample has k-index k - 1\n",
    "    # The rest is for training\n",
    "    val_k_index = k - 1\n",
    "    if val_k_index < 0:\n",
    "        val_k_index = K_FOLDS - 1\n",
    "        \n",
    "    x_val = combined_data[combined_data.k_fold == val_k_index]\n",
    "    y_val = combined_labels[combined_data.k_fold == val_k_index]\n",
    "    w_val = np.abs(x_val.wgt)\n",
    "    \n",
    "    x_train = combined_data[(combined_data.k_fold != k)&(combined_data.k_fold != val_k_index)]\n",
    "    y_train = combined_labels[(combined_data.k_fold != k)&(combined_data.k_fold != val_k_index)]\n",
    "    \n",
    "    n_train_sig = sum(x_train[y_train == 1].wgt)\n",
    "    n_train_bg = sum(x_train[y_train == 0].wgt)\n",
    "    \n",
    "    sig_correction = (n_train_sig + n_train_bg) / (2 * n_train_sig)\n",
    "    bg_correction = (n_train_sig + n_train_bg) / (2 * n_train_bg)\n",
    "    w_train = (sig_correction * y_train + bg_correction * (1 - y_train)) * np.abs(x_train.wgt)\n",
    "    \n",
    "    # Restrict to training features\n",
    "    x_train = x_train[train_feats]\n",
    "    x_val = x_val[train_feats]\n",
    "    \n",
    "    # Generate and fit model\n",
    "    classifier = make_model(input_dim=x_train.shape[1], num_nodes=NUM_NODES, \n",
    "                            dropout=DROPOUT, learn_rate=LEARN_RATE)\n",
    "    \n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE, \n",
    "                                                   restore_best_weights=True)\n",
    "\n",
    "    history = classifier.fit(x_train, y_train, sample_weight=w_train, \n",
    "                             validation_data=(x_val, y_val, w_val),\n",
    "                             epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                             verbose=1, callbacks=[es_callback], shuffle=True)\n",
    "    \n",
    "    # Save model and history\n",
    "    model_dir = 'models/SR_SF_inZ/'\n",
    "    model_name = 'classifier_abs_wgt_k_' + str(k)\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "        \n",
    "    classifier.save(model_dir + model_name)\n",
    "    with open(model_dir + model_name + '_history.pkl', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training history plots\n",
    "for k in range(K_FOLDS):\n",
    "    # Load model\n",
    "    model_dir = 'models/SR_SF_inZ/'\n",
    "    plot_dir = 'plots/SR_SF_inZ/'\n",
    "    model_name = 'classifier_abs_wgt_k_' + str(k)\n",
    "    \n",
    "    with open(model_dir + model_name + '_history.pkl', 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "        \n",
    "    # Loss\n",
    "    plt.plot(history['loss'], label='loss')\n",
    "    plt.plot(history['val_loss'], label='val loss')\n",
    "    \n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xlabel('NN output', fontsize=12)\n",
    "    plt.ylabel('Density', fontsize=12)\n",
    "    \n",
    "    atlasify('Internal simulation', outside=True)\n",
    "    \n",
    "    plt.title('4$\\ell$-SF (in Z) history\\nk = ' + str(k), fontsize=14, loc='right')\n",
    "    \n",
    "    plot_util.save_fig(plot_dir, model_name + '_loss')\n",
    "    plt.show()\n",
    "    \n",
    "    # Accuracy\n",
    "    plt.plot(history['accuracy'], label='acc')\n",
    "    plt.plot(history['val_accuracy'], label='val acc')\n",
    "    \n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xlabel('NN output', fontsize=12)\n",
    "    plt.ylabel('Density', fontsize=12)\n",
    "    \n",
    "    atlasify('Internal simulation', outside=True)\n",
    "    \n",
    "    plt.title('4$\\ell$-SF (in Z) history\\nk = ' + str(k), fontsize=14, loc='right')\n",
    "    \n",
    "    plot_util.save_fig(plot_dir, model_name + '_acc')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_out_col = 'nn_out'\n",
    "\n",
    "combined_data[nn_out_col] = -1\n",
    "\n",
    "for k in range(K_FOLDS):\n",
    "    # Load model\n",
    "    model_dir = 'models/SR_SF_inZ/'\n",
    "    model_name = 'classifier_abs_wgt_k_' + str(k)\n",
    "    \n",
    "    K.clear_session()\n",
    "    classifier = keras.models.load_model(model_dir + model_name)\n",
    "    \n",
    "    # We test classifier k on slice k\n",
    "    x_test = combined_data[combined_data.k_fold == k][train_feats]\n",
    "    combined_data.loc[combined_data.k_fold == k, nn_out_col] = classifier.predict(x_test, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_sample = combined_data[combined_data.is_signal == 0]\n",
    "sig_sample = combined_data[combined_data.is_signal == 1]\n",
    "\n",
    "bg_ZZ_sample = bg_sample[bg_sample.source == 'ZZ']\n",
    "bg_Zjets_sample = bg_sample[bg_sample.source == 'Z + jets']\n",
    "bg_ttZ_sample = bg_sample[bg_sample.source == 'ttZ']\n",
    "bg_WZ_sample = bg_sample[bg_sample.source == 'WZ']\n",
    "bg_tWZ_sample = bg_sample[bg_sample.source == 'tWZ']\n",
    "bg_other_sample = bg_sample[bg_sample.source == 'Other']\n",
    "# bg_Zgamma_sample = bg_sample[bg_sample.source == 'Z + gamma']\n",
    "bg_tZ_sample = bg_sample[bg_sample.source == 'tZ']\n",
    "\n",
    "color_palette = plot_util.color_scheme\n",
    "colors = [color_palette['tZ'],\n",
    "#           color_palette['Zgamma'],\n",
    "          color_palette['others'],\n",
    "          color_palette['tWZ'],\n",
    "          color_palette['WZ'],\n",
    "          color_palette['ttZ'],\n",
    "          color_palette['Zjets'],\n",
    "          color_palette['ZZ'],\n",
    "          color_palette['WVZ']\n",
    "         ]\n",
    "\n",
    "plot_util.make_nn_output_source_plot(bg_tZ_sample, \n",
    "#                                      bg_Zgamma_sample,\n",
    "                                     bg_other_sample,\n",
    "                                     bg_tWZ_sample,\n",
    "                                     bg_WZ_sample,\n",
    "                                     bg_ttZ_sample,\n",
    "                                     bg_Zjets_sample,\n",
    "                                     bg_ZZ_sample,\n",
    "                                     sig_sample, colors=colors, column='nn_out', bins=15, log=True, \n",
    "                                     save=True, \n",
    "                                     save_dir='plots/SR_SF_inZ/', save_name='nn_output_density_stacked', \n",
    "                                     title='4$\\ell$-SF (in Z)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_sample = combined_data[combined_data.is_signal == 0]\n",
    "sig_sample = combined_data[combined_data.is_signal == 1]\n",
    "\n",
    "\n",
    "plot_util.make_nn_output_plot(bg_sample, sig_sample, 'nn_out', 'Background', 'Signal', \n",
    "                              save=True, save_dir='plots/SR_SF_inZ/', save_name='nn_output', \n",
    "                              title='4$\\ell$-SF (in Z)', log=True)\n",
    "plot_util.make_nn_output_plot(bg_sample, sig_sample, 'nn_out', 'Background', 'Signal', density=True, \n",
    "                              save=True, save_dir='plots/SR_SF_inZ/', save_name='nn_output_density', \n",
    "                              title='4$\\ell$-SF (in Z)', log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cuts = 100\n",
    "\n",
    "cuts = np.arange(0, 1, 1./n_cuts)\n",
    "sigs = [-1]*n_cuts\n",
    "\n",
    "max_sig = -1\n",
    "max_sig_loc = -1\n",
    "\n",
    "for i, nn_cut in enumerate(cuts):\n",
    "    bg_sample = combined_data[(combined_data.is_signal == 0)&(combined_data.nn_out >= nn_cut)]\n",
    "    sig_sample = combined_data[(combined_data.is_signal == 1)&(combined_data.nn_out >= nn_cut)]\n",
    "\n",
    "    n_sig = sum(sig_sample.wgt)\n",
    "    n_bg = sum(bg_sample.wgt)\n",
    "\n",
    "    sig = util.significance(n_sig, n_bg)\n",
    "    sigs[i] = sig\n",
    "    if sig > max_sig:\n",
    "        max_sig = sig\n",
    "        max_sig_loc = nn_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scan\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(cuts, sigs)\n",
    "\n",
    "plt.axhline(y=max_sig, color='black', ls='--', alpha=0.5)\n",
    "plt.axvline(x=max_sig_loc, color='black', ls='--', alpha=0.5)\n",
    "\n",
    "plt.ylabel('Significance', fontsize=14)\n",
    "plt.xlabel('NN cut', fontsize=14)\n",
    "plt.title('4$\\ell$-SF (in Z)', loc='right', fontsize=14)\n",
    "\n",
    "plt.text(min(cuts), min(sigs), \n",
    "         'Max: %.2f $\\sigma$\\nLoc: %.2f'%(max_sig, max_sig_loc),\n",
    "         fontsize=14)\n",
    "\n",
    "atlasify('Internal Simulation', outside=True)\n",
    "\n",
    "plot_util.save_fig('plots/SR_SF_inZ/', 'sig_scan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_out_col = 'nn_out'\n",
    "\n",
    "x_test = combined_data[train_feats]\n",
    "\n",
    "for k in range(K_FOLDS):\n",
    "    # Load model\n",
    "    model_dir = 'models/SR_SF_inZ/'\n",
    "    model_name = 'classifier_abs_wgt_k_' + str(k)\n",
    "    \n",
    "    K.clear_session()\n",
    "    classifier = keras.models.load_model(model_dir + model_name)\n",
    "    \n",
    "    # We test classifier k on the entire dataset\n",
    "    combined_data[nn_out_col + '_k_' + str(k)] = classifier.predict(x_test, batch_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import k_fold_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 10))\n",
    "gs = matplotlib.gridspec.GridSpec(ncols=3, nrows=4, height_ratios=[1, 0.1]*2)\n",
    "\n",
    "for k in range(K_FOLDS):\n",
    "    nn_out_col = 'nn_out_k_' + str(k)\n",
    "    \n",
    "    test_data = combined_data[combined_data.k_fold == k][train_feats + ['is_signal', 'wgt', nn_out_col]]\n",
    "    train_data = combined_data[combined_data.k_fold != k][train_feats + ['is_signal', 'wgt', nn_out_col]]\n",
    "    \n",
    "    test_sig = test_data[test_data.is_signal == True]\n",
    "    test_bg = test_data[test_data.is_signal == False]\n",
    "    \n",
    "    train_sig = train_data[train_data.is_signal == True]\n",
    "    train_bg = train_data[train_data.is_signal == False]\n",
    "    \n",
    "    fig.add_subplot(gs[2 * math.floor(k / 3), k % 3])\n",
    "    k_fold_util.make_output_overfit_plot(test_sig, test_bg, train_sig, train_bg, nn_out_col)\n",
    "    plt.title('4$\\ell$-SF (in Z)\\nk = %i'%k, fontsize=14, loc='right')\n",
    "    \n",
    "plot_util.save_fig('plots/SR_SF_inZ/', 'overfitting_outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wvz_machine_learning",
   "language": "python",
   "name": "wvz_machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
