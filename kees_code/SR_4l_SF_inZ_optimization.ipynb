{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.errors import InvalidArgumentError\n",
    "import tensorflow as tf\n",
    "\n",
    "# Tensorflow GPU settings\n",
    "# gpu_options = tf.GPUOptions(allow_growth=True)#per_process_gpu_memory_fraction=0.5)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from scipy import interpolate\n",
    "\n",
    "from atlasify import atlasify\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/20220117_iso_e4m1_VVZ_RD.arrow')\n",
    "sig['is_signal'] = True\n",
    "# sig = sig[sig.SR == 2]\n",
    "\n",
    "bg = pd.read_feather('/home/grabanal/WVZ/gabriel_ML_data/20220117_iso_e4m1_FULLBG_RD.arrow')\n",
    "bg['is_signal'] = False\n",
    "# bg = bg[bg.SR == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats_raw = sorted([f for f in sig.columns if f not in ['index', 'wgt', 'is_signal', \n",
    "                                                              'Zcand_mass', 'chisq']])\n",
    "\n",
    "train_feat_sets = [train_feats_raw, \n",
    "                   [f for f in train_feats_raw if f not in ['Wlep1_phi', 'Wlep2_phi', 'Zlep1_phi', 'Zlep2_phi']],\n",
    "                   [f for f in train_feats_raw if f not in ['MET', 'METSig']],\n",
    "                   [f for f in train_feats_raw if f not in ['pt_1', 'pt_2', 'pt_3', 'pt_4']],\n",
    "                   [f for f in train_feats_raw if f not in ['Njet', 'Nlep']]\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize training features\n",
    "X = pd.concat([sig[train_feats_raw], bg[train_feats_raw]], ignore_index=True)\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "min_max_scaler.fit(X)\n",
    "\n",
    "for df in [sig, bg]:\n",
    "    df[train_feats_raw] = min_max_scaler.transform(df[train_feats_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-31 16:07:01.832322: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-31 16:07:01.835069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:65:00.0 name: Quadro RTX 4000 computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 387.49GiB/s\n",
      "2022-01-31 16:07:01.835143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-31 16:07:01.835170: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-31 16:07:01.835185: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-01-31 16:07:01.835199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-31 16:07:01.835213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-31 16:07:01.835227: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-31 16:07:01.835241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-31 16:07:01.835255: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-31 16:07:01.835763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-01-31 16:07:01.835815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-31 16:07:02.231851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-31 16:07:02.231881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-01-31 16:07:02.231888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-01-31 16:07:02.232459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6256 MB memory) -> physical GPU (device: 0, name: Quadro RTX 4000, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "2022-01-31 16:07:02.232845: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-31 16:07:02.566037: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-01-31 16:07:02.566423: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3500000000 Hz\n",
      "2022-01-31 16:07:02.617382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    }
   ],
   "source": [
    "# Load per-background models\n",
    "models_dir = 'models/background_id_models/'\n",
    "\n",
    "background_classifiers = {'ZZ': 1, 'Zjets': 2, 'WZ': 1, 'ttZ': 0, 'other': 1}\n",
    "\n",
    "for bc_name in background_classifiers:\n",
    "    bc_index = background_classifiers[bc_name]\n",
    "    \n",
    "    classifier = keras.models.load_model((models_dir + 'classifier_' + bc_name \n",
    "                                          + '_train_feat_test_' + str(bc_index)))\n",
    "    sig['classifier_' + bc_name + '_score'] = classifier.predict(sig[train_feat_sets[bc_index]], \n",
    "                                                                    batch_size=10000)\n",
    "    bg['classifier_' + bc_name + '_score'] = classifier.predict(bg[train_feat_sets[bc_index]], \n",
    "                                                                   batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut to 4l-DF signal region\n",
    "bg = bg[bg.SR == 0]\n",
    "sig = sig[sig.SR == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, b, _ = plt.hist(bg.classifier_ZZ_score, bins=100, weights=bg.wgt, density=True, alpha=0.5)\n",
    "plt.hist(sig.classifier_ZZ_score, bins=b, weights=sig.wgt, density=True, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, b, _ = plt.hist(bg.classifier_Zjets_score, bins=50, weights=bg.wgt, density=True, alpha=0.5)\n",
    "plt.hist(sig.classifier_Zjets_score, bins=b, weights=sig.wgt, density=True, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, b, _ = plt.hist(bg.classifier_WZ_score, bins=50, weights=bg.wgt, density=True, alpha=0.5)\n",
    "plt.hist(sig.classifier_WZ_score, bins=b, weights=sig.wgt, density=True, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, b, _ = plt.hist(bg.classifier_ttZ_score, bins=50, weights=bg.wgt, density=True, alpha=0.5)\n",
    "plt.hist(sig.classifier_ttZ_score, bins=b, weights=sig.wgt, density=True, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, b, _ = plt.hist(bg.classifier_other_score, bins=100, weights=bg.wgt, density=True, alpha=0.5)\n",
    "plt.hist(sig.classifier_other_score, bins=b, weights=sig.wgt, density=True, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "\n",
    "First we want to figure out the signal/background ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1156.3337963132874 background events\n",
      "There are 5.726832988559573 signal events\n",
      "\n",
      "S/B = 0.004952577713129464\n",
      "Starting significance is 0.1682732254181331 sigma\n",
      "Corresponds to 0.2379742775705889 sigma\n"
     ]
    }
   ],
   "source": [
    "def region_sig(s, b):\n",
    "    if s == 0:\n",
    "        return 0\n",
    "    return np.sqrt(2 * ((s + b) * np.log(1 + s / b) - s))\n",
    "\n",
    "n_bg = sum(bg.wgt)\n",
    "n_sig = sum(sig.wgt)\n",
    "\n",
    "print('There are', n_bg, 'background events')\n",
    "print('There are', n_sig, 'signal events')\n",
    "print('')\n",
    "print('S/B =', n_sig/n_bg)\n",
    "print('Starting significance is', region_sig(n_sig, n_bg), 'sigma')\n",
    "print('Corresponds to', np.sqrt(2.0) * region_sig(n_sig, n_bg), 'sigma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/kbenkend/ipykernel_68339/2235700710.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bg['abs_wgt'] = np.abs(bg.wgt)\n"
     ]
    }
   ],
   "source": [
    "bg['abs_wgt'] = np.abs(bg.wgt)\n",
    "sig['abs_wgt'] = np.abs(sig.wgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_classifier_score_feats = ['classifier_' + bc + '_score' for bc in background_classifiers]\n",
    "combined_train_feats_raw = train_feats_raw + bg_classifier_score_feats\n",
    "\n",
    "combined_train_feat_sets = [combined_train_feats_raw, \n",
    "                            [f for f in combined_train_feats_raw if f not in bg_classifier_score_feats],\n",
    "                            [f for f in combined_train_feats_raw if f not in ['Wlep1_phi', 'Wlep2_phi', \n",
    "                                                                              'Zlep1_phi', 'Zlep2_phi']],\n",
    "                            [f for f in combined_train_feats_raw if f not in ['MET', 'METSig']],\n",
    "                            [f for f in combined_train_feats_raw if f not in ['pt_1', 'pt_2', 'pt_3', 'pt_4']],\n",
    "                            [f for f in combined_train_feats_raw if f not in ['Njet', 'Nlep']]\n",
    "                           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with training features: ['HT', 'MET', 'METSig', 'Njet', 'Nlep', 'SR', 'Wlep1_dphi', 'Wlep1_eta', 'Wlep1_phi', 'Wlep1_pid', 'Wlep1_pt', 'Wlep2_dphi', 'Wlep2_eta', 'Wlep2_phi', 'Wlep2_pid', 'Wlep2_pt', 'Zlep1_dphi', 'Zlep1_eta', 'Zlep1_phi', 'Zlep1_pid', 'Zlep1_pt', 'Zlep2_dphi', 'Zlep2_eta', 'Zlep2_phi', 'Zlep2_pid', 'Zlep2_pt', 'leptonic_HT', 'mass_4l', 'other_mass', 'pt_1', 'pt_2', 'pt_3', 'pt_4', 'pt_4l', 'total_HT', 'classifier_ZZ_score', 'classifier_Zjets_score', 'classifier_WZ_score', 'classifier_ttZ_score', 'classifier_other_score']\n",
      "Epoch 1/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0018 - accuracy: 0.4231 - val_loss: 0.0018 - val_accuracy: 0.3696\n",
      "Epoch 2/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0018 - accuracy: 0.5492 - val_loss: 0.0017 - val_accuracy: 0.5969\n",
      "Epoch 3/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0017 - accuracy: 0.6109 - val_loss: 0.0017 - val_accuracy: 0.6702\n",
      "Epoch 4/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0017 - accuracy: 0.6475 - val_loss: 0.0016 - val_accuracy: 0.6849\n",
      "Epoch 5/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0016 - accuracy: 0.6687 - val_loss: 0.0016 - val_accuracy: 0.6935\n",
      "Epoch 6/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0016 - accuracy: 0.6786 - val_loss: 0.0015 - val_accuracy: 0.6911\n",
      "Epoch 7/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0015 - accuracy: 0.6714 - val_loss: 0.0014 - val_accuracy: 0.6926\n",
      "Epoch 8/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0014 - accuracy: 0.6775 - val_loss: 0.0013 - val_accuracy: 0.6877\n",
      "Epoch 9/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0014 - accuracy: 0.6695 - val_loss: 0.0013 - val_accuracy: 0.6871\n",
      "Epoch 10/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0013 - accuracy: 0.6736 - val_loss: 0.0013 - val_accuracy: 0.6839\n",
      "Epoch 11/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0013 - accuracy: 0.6708 - val_loss: 0.0012 - val_accuracy: 0.6915\n",
      "Epoch 12/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0013 - accuracy: 0.6793 - val_loss: 0.0012 - val_accuracy: 0.6848\n",
      "Epoch 13/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0013 - accuracy: 0.6780 - val_loss: 0.0012 - val_accuracy: 0.6715\n",
      "Epoch 14/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0013 - accuracy: 0.6686 - val_loss: 0.0012 - val_accuracy: 0.6874\n",
      "Epoch 15/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0013 - accuracy: 0.6768 - val_loss: 0.0012 - val_accuracy: 0.6695\n",
      "Epoch 16/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0013 - accuracy: 0.6712 - val_loss: 0.0012 - val_accuracy: 0.6727\n",
      "Epoch 17/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0013 - accuracy: 0.6686 - val_loss: 0.0012 - val_accuracy: 0.6762\n",
      "Epoch 18/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6721 - val_loss: 0.0012 - val_accuracy: 0.6661\n",
      "Epoch 19/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0013 - accuracy: 0.6631 - val_loss: 0.0012 - val_accuracy: 0.6756\n",
      "Epoch 20/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0013 - accuracy: 0.6695 - val_loss: 0.0012 - val_accuracy: 0.6747\n",
      "Epoch 21/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0013 - accuracy: 0.6676 - val_loss: 0.0012 - val_accuracy: 0.6708\n",
      "Epoch 22/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0013 - accuracy: 0.6693 - val_loss: 0.0012 - val_accuracy: 0.6695\n",
      "Epoch 23/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6705 - val_loss: 0.0012 - val_accuracy: 0.6660\n",
      "Epoch 24/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6625 - val_loss: 0.0012 - val_accuracy: 0.6688\n",
      "Epoch 25/10000\n",
      "870/870 [==============================] - 4s 5ms/step - loss: 0.0012 - accuracy: 0.6706 - val_loss: 0.0012 - val_accuracy: 0.6634\n",
      "Epoch 26/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0013 - accuracy: 0.6670 - val_loss: 0.0012 - val_accuracy: 0.6534\n",
      "Epoch 27/10000\n",
      "870/870 [==============================] - 4s 5ms/step - loss: 0.0013 - accuracy: 0.6619 - val_loss: 0.0012 - val_accuracy: 0.6710\n",
      "Epoch 28/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6670 - val_loss: 0.0012 - val_accuracy: 0.6697\n",
      "Epoch 29/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0013 - accuracy: 0.6659 - val_loss: 0.0012 - val_accuracy: 0.6657\n",
      "Epoch 30/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6633 - val_loss: 0.0012 - val_accuracy: 0.6596\n",
      "Epoch 31/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6635 - val_loss: 0.0012 - val_accuracy: 0.6557\n",
      "Epoch 32/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6627 - val_loss: 0.0012 - val_accuracy: 0.6587\n",
      "Epoch 33/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6632 - val_loss: 0.0012 - val_accuracy: 0.6611\n",
      "Epoch 34/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6613 - val_loss: 0.0012 - val_accuracy: 0.6570\n",
      "Epoch 35/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6601 - val_loss: 0.0012 - val_accuracy: 0.6652\n",
      "Epoch 36/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6612 - val_loss: 0.0012 - val_accuracy: 0.6588\n",
      "Epoch 37/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6599 - val_loss: 0.0012 - val_accuracy: 0.6553\n",
      "Epoch 38/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6586 - val_loss: 0.0012 - val_accuracy: 0.6554\n",
      "Epoch 39/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6558 - val_loss: 0.0012 - val_accuracy: 0.6627\n",
      "Epoch 40/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6607 - val_loss: 0.0012 - val_accuracy: 0.6567\n",
      "Epoch 41/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6576 - val_loss: 0.0012 - val_accuracy: 0.6556\n",
      "Epoch 42/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6579 - val_loss: 0.0012 - val_accuracy: 0.6627\n",
      "Epoch 43/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6595 - val_loss: 0.0012 - val_accuracy: 0.6496\n",
      "Epoch 44/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6560 - val_loss: 0.0012 - val_accuracy: 0.6528\n",
      "Epoch 45/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6561 - val_loss: 0.0012 - val_accuracy: 0.6443\n",
      "Epoch 46/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6507 - val_loss: 0.0012 - val_accuracy: 0.6537\n",
      "Epoch 47/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6557 - val_loss: 0.0012 - val_accuracy: 0.6564\n",
      "Epoch 48/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6585 - val_loss: 0.0012 - val_accuracy: 0.6470\n",
      "Epoch 49/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6512 - val_loss: 0.0012 - val_accuracy: 0.6469\n",
      "Epoch 50/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6538 - val_loss: 0.0012 - val_accuracy: 0.6463\n",
      "Epoch 51/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6530 - val_loss: 0.0012 - val_accuracy: 0.6368\n",
      "Epoch 52/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6479 - val_loss: 0.0012 - val_accuracy: 0.6451\n",
      "Epoch 53/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6538 - val_loss: 0.0012 - val_accuracy: 0.6402\n",
      "Epoch 54/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6483 - val_loss: 0.0012 - val_accuracy: 0.6457\n",
      "Epoch 55/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6496 - val_loss: 0.0012 - val_accuracy: 0.6515\n",
      "Epoch 56/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6568 - val_loss: 0.0012 - val_accuracy: 0.6381\n",
      "Epoch 57/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6435 - val_loss: 0.0012 - val_accuracy: 0.6425\n",
      "Epoch 58/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6492 - val_loss: 0.0012 - val_accuracy: 0.6405\n",
      "Epoch 59/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6503 - val_loss: 0.0012 - val_accuracy: 0.6404\n",
      "Epoch 60/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6446 - val_loss: 0.0012 - val_accuracy: 0.6470\n",
      "Epoch 61/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6494 - val_loss: 0.0012 - val_accuracy: 0.6406\n",
      "Epoch 62/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6450 - val_loss: 0.0012 - val_accuracy: 0.6474\n",
      "Epoch 63/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6502 - val_loss: 0.0012 - val_accuracy: 0.6347\n",
      "Epoch 64/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6483 - val_loss: 0.0012 - val_accuracy: 0.6306\n",
      "Epoch 65/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6427 - val_loss: 0.0012 - val_accuracy: 0.6435\n",
      "Epoch 66/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6472 - val_loss: 0.0012 - val_accuracy: 0.6445\n",
      "Epoch 67/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6498 - val_loss: 0.0012 - val_accuracy: 0.6342\n",
      "Epoch 68/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6446 - val_loss: 0.0012 - val_accuracy: 0.6416\n",
      "Epoch 69/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6481 - val_loss: 0.0012 - val_accuracy: 0.6380\n",
      "Epoch 70/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6452 - val_loss: 0.0012 - val_accuracy: 0.6365\n",
      "Epoch 71/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6440 - val_loss: 0.0012 - val_accuracy: 0.6364\n",
      "Epoch 72/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6427 - val_loss: 0.0012 - val_accuracy: 0.6392\n",
      "Epoch 73/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6447 - val_loss: 0.0012 - val_accuracy: 0.6363\n",
      "Epoch 74/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6401 - val_loss: 0.0012 - val_accuracy: 0.6438\n",
      "Epoch 75/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6465 - val_loss: 0.0012 - val_accuracy: 0.6340\n",
      "Epoch 76/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6435 - val_loss: 0.0012 - val_accuracy: 0.6377\n",
      "Epoch 77/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6422 - val_loss: 0.0012 - val_accuracy: 0.6407\n",
      "Epoch 78/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6465 - val_loss: 0.0012 - val_accuracy: 0.6307\n",
      "Epoch 79/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6429 - val_loss: 0.0012 - val_accuracy: 0.6257\n",
      "Epoch 80/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6365 - val_loss: 0.0012 - val_accuracy: 0.6349\n",
      "Epoch 81/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6390 - val_loss: 0.0012 - val_accuracy: 0.6367\n",
      "Epoch 82/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6429 - val_loss: 0.0012 - val_accuracy: 0.6315\n",
      "Epoch 83/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6404 - val_loss: 0.0012 - val_accuracy: 0.6366\n",
      "Epoch 84/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6430 - val_loss: 0.0012 - val_accuracy: 0.6316\n",
      "Epoch 85/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6379 - val_loss: 0.0012 - val_accuracy: 0.6407\n",
      "Epoch 86/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6438 - val_loss: 0.0012 - val_accuracy: 0.6340\n",
      "Epoch 87/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6423 - val_loss: 0.0012 - val_accuracy: 0.6328\n",
      "Epoch 88/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6395 - val_loss: 0.0012 - val_accuracy: 0.6342\n",
      "Epoch 89/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6393 - val_loss: 0.0012 - val_accuracy: 0.6314\n",
      "Epoch 90/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6428 - val_loss: 0.0012 - val_accuracy: 0.6300\n",
      "Epoch 91/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6362 - val_loss: 0.0012 - val_accuracy: 0.6345\n",
      "Epoch 92/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6417 - val_loss: 0.0012 - val_accuracy: 0.6333\n",
      "Epoch 93/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6415 - val_loss: 0.0012 - val_accuracy: 0.6314\n",
      "Epoch 94/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6375 - val_loss: 0.0012 - val_accuracy: 0.6312\n",
      "Epoch 95/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6397 - val_loss: 0.0012 - val_accuracy: 0.6335\n",
      "Epoch 96/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6404 - val_loss: 0.0012 - val_accuracy: 0.6307\n",
      "Epoch 97/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6368 - val_loss: 0.0012 - val_accuracy: 0.6367\n",
      "Epoch 98/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6386 - val_loss: 0.0012 - val_accuracy: 0.6263\n",
      "Epoch 99/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6364 - val_loss: 0.0012 - val_accuracy: 0.6298\n",
      "Epoch 100/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6338 - val_loss: 0.0012 - val_accuracy: 0.6397\n",
      "Epoch 101/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6379 - val_loss: 0.0012 - val_accuracy: 0.6357\n",
      "Epoch 102/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6390 - val_loss: 0.0012 - val_accuracy: 0.6263\n",
      "Epoch 103/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6348 - val_loss: 0.0012 - val_accuracy: 0.6335\n",
      "Epoch 104/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6428 - val_loss: 0.0012 - val_accuracy: 0.6202\n",
      "Epoch 105/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6313 - val_loss: 0.0012 - val_accuracy: 0.6344\n",
      "Epoch 106/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6396 - val_loss: 0.0012 - val_accuracy: 0.6242\n",
      "Epoch 107/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6352 - val_loss: 0.0012 - val_accuracy: 0.6223\n",
      "Epoch 108/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6321 - val_loss: 0.0012 - val_accuracy: 0.6303\n",
      "Epoch 109/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6368 - val_loss: 0.0012 - val_accuracy: 0.6359\n",
      "Epoch 110/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6351 - val_loss: 0.0012 - val_accuracy: 0.6318\n",
      "Epoch 111/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6346 - val_loss: 0.0012 - val_accuracy: 0.6336\n",
      "Epoch 112/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6362 - val_loss: 0.0012 - val_accuracy: 0.6316\n",
      "Epoch 113/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6340 - val_loss: 0.0012 - val_accuracy: 0.6357\n",
      "Epoch 114/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6393 - val_loss: 0.0012 - val_accuracy: 0.6280\n",
      "Epoch 115/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6332 - val_loss: 0.0012 - val_accuracy: 0.6323\n",
      "Epoch 116/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6383 - val_loss: 0.0012 - val_accuracy: 0.6210\n",
      "Epoch 117/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6317 - val_loss: 0.0012 - val_accuracy: 0.6311\n",
      "Epoch 118/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6370 - val_loss: 0.0012 - val_accuracy: 0.6277\n",
      "Epoch 119/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6338 - val_loss: 0.0012 - val_accuracy: 0.6294\n",
      "Epoch 120/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6320 - val_loss: 0.0012 - val_accuracy: 0.6291\n",
      "Epoch 121/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6365 - val_loss: 0.0012 - val_accuracy: 0.6228\n",
      "Epoch 122/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6320 - val_loss: 0.0012 - val_accuracy: 0.6283\n",
      "Epoch 123/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6360 - val_loss: 0.0012 - val_accuracy: 0.6279\n",
      "Epoch 124/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6312 - val_loss: 0.0012 - val_accuracy: 0.6325\n",
      "Epoch 125/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6353 - val_loss: 0.0012 - val_accuracy: 0.6304\n",
      "Epoch 126/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6322 - val_loss: 0.0012 - val_accuracy: 0.6251\n",
      "Epoch 127/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6362 - val_loss: 0.0012 - val_accuracy: 0.6266\n",
      "Epoch 128/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6326 - val_loss: 0.0012 - val_accuracy: 0.6292\n",
      "Epoch 129/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6341 - val_loss: 0.0012 - val_accuracy: 0.6285\n",
      "Epoch 130/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6317 - val_loss: 0.0012 - val_accuracy: 0.6325\n",
      "Epoch 131/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6359 - val_loss: 0.0012 - val_accuracy: 0.6246\n",
      "Epoch 132/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6340 - val_loss: 0.0012 - val_accuracy: 0.6250\n",
      "Epoch 133/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6308 - val_loss: 0.0012 - val_accuracy: 0.6310\n",
      "Epoch 134/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6328 - val_loss: 0.0012 - val_accuracy: 0.6277\n",
      "Epoch 135/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6355 - val_loss: 0.0012 - val_accuracy: 0.6237\n",
      "Epoch 136/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6305 - val_loss: 0.0012 - val_accuracy: 0.6294\n",
      "Epoch 137/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6308 - val_loss: 0.0012 - val_accuracy: 0.6296\n",
      "Epoch 138/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6320 - val_loss: 0.0012 - val_accuracy: 0.6278\n",
      "Epoch 139/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6322 - val_loss: 0.0012 - val_accuracy: 0.6280\n",
      "Epoch 140/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6332 - val_loss: 0.0012 - val_accuracy: 0.6214\n",
      "Epoch 141/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6252 - val_loss: 0.0012 - val_accuracy: 0.6326\n",
      "Epoch 142/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6336 - val_loss: 0.0012 - val_accuracy: 0.6279\n",
      "Epoch 143/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6309 - val_loss: 0.0012 - val_accuracy: 0.6252\n",
      "Epoch 144/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6328 - val_loss: 0.0012 - val_accuracy: 0.6234\n",
      "Epoch 145/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6268 - val_loss: 0.0012 - val_accuracy: 0.6314\n",
      "Epoch 146/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6339 - val_loss: 0.0012 - val_accuracy: 0.6231\n",
      "Epoch 147/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6291 - val_loss: 0.0012 - val_accuracy: 0.6260\n",
      "Epoch 148/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6312 - val_loss: 0.0012 - val_accuracy: 0.6215\n",
      "Epoch 149/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6298 - val_loss: 0.0012 - val_accuracy: 0.6270\n",
      "Epoch 150/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6301 - val_loss: 0.0012 - val_accuracy: 0.6216\n",
      "Epoch 151/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6265 - val_loss: 0.0012 - val_accuracy: 0.6219\n",
      "Epoch 152/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6299 - val_loss: 0.0012 - val_accuracy: 0.6234\n",
      "Epoch 153/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6292 - val_loss: 0.0012 - val_accuracy: 0.6268\n",
      "Epoch 154/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6315 - val_loss: 0.0012 - val_accuracy: 0.6250\n",
      "Epoch 155/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6313 - val_loss: 0.0012 - val_accuracy: 0.6222\n",
      "Epoch 156/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6267 - val_loss: 0.0012 - val_accuracy: 0.6254\n",
      "Epoch 157/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6299 - val_loss: 0.0012 - val_accuracy: 0.6247\n",
      "Epoch 158/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6316 - val_loss: 0.0012 - val_accuracy: 0.6221\n",
      "Epoch 159/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6291 - val_loss: 0.0012 - val_accuracy: 0.6217\n",
      "Epoch 160/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6293 - val_loss: 0.0012 - val_accuracy: 0.6266\n",
      "Epoch 161/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6299 - val_loss: 0.0012 - val_accuracy: 0.6243\n",
      "Epoch 162/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6273 - val_loss: 0.0012 - val_accuracy: 0.6268\n",
      "Epoch 163/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6277 - val_loss: 0.0012 - val_accuracy: 0.6261\n",
      "Epoch 164/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6310 - val_loss: 0.0012 - val_accuracy: 0.6214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6279 - val_loss: 0.0012 - val_accuracy: 0.6213\n",
      "Epoch 166/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6291 - val_loss: 0.0012 - val_accuracy: 0.6187\n",
      "Epoch 167/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6252 - val_loss: 0.0012 - val_accuracy: 0.6274\n",
      "Epoch 168/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6276 - val_loss: 0.0012 - val_accuracy: 0.6242\n",
      "Epoch 169/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6293 - val_loss: 0.0012 - val_accuracy: 0.6172\n",
      "Epoch 170/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6235 - val_loss: 0.0012 - val_accuracy: 0.6215\n",
      "Epoch 171/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0011 - accuracy: 0.6274 - val_loss: 0.0012 - val_accuracy: 0.6249\n",
      "Epoch 172/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0011 - accuracy: 0.6284 - val_loss: 0.0012 - val_accuracy: 0.6173\n",
      "Epoch 173/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6252 - val_loss: 0.0012 - val_accuracy: 0.6246\n",
      "Epoch 174/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6276 - val_loss: 0.0012 - val_accuracy: 0.6236\n",
      "Epoch 175/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6298 - val_loss: 0.0012 - val_accuracy: 0.6171\n",
      "Epoch 176/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6204 - val_loss: 0.0012 - val_accuracy: 0.6236\n",
      "Epoch 177/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6263 - val_loss: 0.0012 - val_accuracy: 0.6206\n",
      "Epoch 178/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6224 - val_loss: 0.0012 - val_accuracy: 0.6274\n",
      "Epoch 179/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6279 - val_loss: 0.0012 - val_accuracy: 0.6233\n",
      "Epoch 180/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6230 - val_loss: 0.0012 - val_accuracy: 0.6263\n",
      "Epoch 181/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6301 - val_loss: 0.0012 - val_accuracy: 0.6192\n",
      "Epoch 182/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6252 - val_loss: 0.0012 - val_accuracy: 0.6216\n",
      "Epoch 183/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6258 - val_loss: 0.0012 - val_accuracy: 0.6212\n",
      "Epoch 184/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6231 - val_loss: 0.0012 - val_accuracy: 0.6288\n",
      "Epoch 185/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6273 - val_loss: 0.0012 - val_accuracy: 0.6204\n",
      "Epoch 186/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6238 - val_loss: 0.0012 - val_accuracy: 0.6224\n",
      "Epoch 187/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6264 - val_loss: 0.0012 - val_accuracy: 0.6205\n",
      "Epoch 188/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6222 - val_loss: 0.0012 - val_accuracy: 0.6202\n",
      "Epoch 189/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6251 - val_loss: 0.0012 - val_accuracy: 0.6167\n",
      "Epoch 190/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6215 - val_loss: 0.0012 - val_accuracy: 0.6218\n",
      "Epoch 191/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6252 - val_loss: 0.0012 - val_accuracy: 0.6172\n",
      "Epoch 192/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6202 - val_loss: 0.0012 - val_accuracy: 0.6226\n",
      "Epoch 193/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6250 - val_loss: 0.0012 - val_accuracy: 0.6189\n",
      "Epoch 194/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6255 - val_loss: 0.0012 - val_accuracy: 0.6149\n",
      "Epoch 195/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6227 - val_loss: 0.0012 - val_accuracy: 0.6158\n",
      "Epoch 196/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6249 - val_loss: 0.0012 - val_accuracy: 0.6109\n",
      "Epoch 197/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6178 - val_loss: 0.0012 - val_accuracy: 0.6189\n",
      "Epoch 198/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6239 - val_loss: 0.0012 - val_accuracy: 0.6164\n",
      "Epoch 199/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6219 - val_loss: 0.0012 - val_accuracy: 0.6180\n",
      "Epoch 200/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6219 - val_loss: 0.0012 - val_accuracy: 0.6128\n",
      "Epoch 201/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6179 - val_loss: 0.0012 - val_accuracy: 0.6144\n",
      "Epoch 202/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6208 - val_loss: 0.0012 - val_accuracy: 0.6162\n",
      "Epoch 203/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6216 - val_loss: 0.0012 - val_accuracy: 0.6142\n",
      "Epoch 204/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6202 - val_loss: 0.0012 - val_accuracy: 0.6136\n",
      "Epoch 205/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6203 - val_loss: 0.0012 - val_accuracy: 0.6164\n",
      "Epoch 206/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6207 - val_loss: 0.0012 - val_accuracy: 0.6182\n",
      "Epoch 207/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6179 - val_loss: 0.0012 - val_accuracy: 0.6227\n",
      "Epoch 208/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6230 - val_loss: 0.0012 - val_accuracy: 0.6172\n",
      "Epoch 209/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6223 - val_loss: 0.0012 - val_accuracy: 0.6173\n",
      "Epoch 210/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6191 - val_loss: 0.0012 - val_accuracy: 0.6209\n",
      "Epoch 211/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6212 - val_loss: 0.0012 - val_accuracy: 0.6218\n",
      "Epoch 212/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6242 - val_loss: 0.0012 - val_accuracy: 0.6194\n",
      "Epoch 213/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0011 - accuracy: 0.6226 - val_loss: 0.0012 - val_accuracy: 0.6184\n",
      "Epoch 214/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6222 - val_loss: 0.0012 - val_accuracy: 0.6147\n",
      "Epoch 215/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6189 - val_loss: 0.0012 - val_accuracy: 0.6168\n",
      "Epoch 216/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6209 - val_loss: 0.0012 - val_accuracy: 0.6184\n",
      "Epoch 217/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6235 - val_loss: 0.0012 - val_accuracy: 0.6141\n",
      "Epoch 218/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6191 - val_loss: 0.0012 - val_accuracy: 0.6201\n",
      "Epoch 219/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6229 - val_loss: 0.0012 - val_accuracy: 0.6174\n",
      "Epoch 220/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6194 - val_loss: 0.0012 - val_accuracy: 0.6169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6217 - val_loss: 0.0012 - val_accuracy: 0.6164\n",
      "Epoch 222/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6173 - val_loss: 0.0012 - val_accuracy: 0.6203\n",
      "Epoch 223/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6200 - val_loss: 0.0012 - val_accuracy: 0.6189\n",
      "Epoch 224/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6199 - val_loss: 0.0012 - val_accuracy: 0.6156\n",
      "Epoch 225/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0011 - accuracy: 0.6212 - val_loss: 0.0012 - val_accuracy: 0.6134\n",
      "Epoch 226/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6176 - val_loss: 0.0011 - val_accuracy: 0.6120\n",
      "Epoch 227/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6167 - val_loss: 0.0011 - val_accuracy: 0.6147\n",
      "Epoch 228/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6176 - val_loss: 0.0011 - val_accuracy: 0.6114\n",
      "Epoch 229/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6171 - val_loss: 0.0011 - val_accuracy: 0.6153\n",
      "Epoch 230/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6171 - val_loss: 0.0011 - val_accuracy: 0.6175\n",
      "Epoch 231/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6197 - val_loss: 0.0011 - val_accuracy: 0.6131\n",
      "Epoch 232/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6184 - val_loss: 0.0011 - val_accuracy: 0.6102\n",
      "Epoch 233/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0011 - accuracy: 0.6207 - val_loss: 0.0011 - val_accuracy: 0.6045\n",
      "Epoch 234/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6146 - val_loss: 0.0011 - val_accuracy: 0.6100\n",
      "Epoch 235/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6159 - val_loss: 0.0011 - val_accuracy: 0.6198\n",
      "Epoch 236/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6211 - val_loss: 0.0011 - val_accuracy: 0.6127\n",
      "Epoch 237/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6184 - val_loss: 0.0011 - val_accuracy: 0.6117\n",
      "Epoch 238/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6172 - val_loss: 0.0011 - val_accuracy: 0.6139\n",
      "Epoch 239/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6164 - val_loss: 0.0011 - val_accuracy: 0.6150\n",
      "Epoch 241/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6194 - val_loss: 0.0011 - val_accuracy: 0.6156\n",
      "Epoch 242/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6159 - val_loss: 0.0011 - val_accuracy: 0.6183\n",
      "Epoch 243/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6192 - val_loss: 0.0011 - val_accuracy: 0.6135\n",
      "Epoch 244/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6149 - val_loss: 0.0011 - val_accuracy: 0.6131\n",
      "Epoch 245/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0011 - accuracy: 0.6174 - val_loss: 0.0011 - val_accuracy: 0.6136\n",
      "Epoch 246/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6160 - val_loss: 0.0011 - val_accuracy: 0.6136\n",
      "Epoch 247/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6157 - val_loss: 0.0011 - val_accuracy: 0.6178\n",
      "Epoch 248/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6194 - val_loss: 0.0011 - val_accuracy: 0.6084\n",
      "Epoch 249/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0011 - accuracy: 0.6157 - val_loss: 0.0011 - val_accuracy: 0.6139\n",
      "Epoch 250/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6170 - val_loss: 0.0011 - val_accuracy: 0.6142\n",
      "Epoch 251/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0011 - accuracy: 0.6173 - val_loss: 0.0011 - val_accuracy: 0.6118\n",
      "Epoch 252/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6168 - val_loss: 0.0011 - val_accuracy: 0.6121\n",
      "Epoch 253/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6158 - val_loss: 0.0011 - val_accuracy: 0.6162\n",
      "Epoch 254/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6184 - val_loss: 0.0011 - val_accuracy: 0.6166\n",
      "Epoch 255/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0011 - accuracy: 0.6188 - val_loss: 0.0011 - val_accuracy: 0.6081\n",
      "Epoch 256/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6153 - val_loss: 0.0011 - val_accuracy: 0.6100\n",
      "Epoch 257/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6154 - val_loss: 0.0011 - val_accuracy: 0.6177\n",
      "Epoch 258/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6180 - val_loss: 0.0011 - val_accuracy: 0.6169\n",
      "Epoch 259/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6194 - val_loss: 0.0011 - val_accuracy: 0.6082\n",
      "Epoch 260/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6129 - val_loss: 0.0011 - val_accuracy: 0.6116\n",
      "Epoch 261/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6172 - val_loss: 0.0011 - val_accuracy: 0.6079\n",
      "Epoch 262/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6136 - val_loss: 0.0011 - val_accuracy: 0.6173\n",
      "Epoch 263/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6175 - val_loss: 0.0011 - val_accuracy: 0.6149\n",
      "Epoch 264/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0011 - accuracy: 0.6175 - val_loss: 0.0011 - val_accuracy: 0.6170\n",
      "Epoch 265/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6198 - val_loss: 0.0011 - val_accuracy: 0.6133\n",
      "Epoch 266/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6163 - val_loss: 0.0011 - val_accuracy: 0.6084\n",
      "Epoch 267/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0011 - accuracy: 0.6157 - val_loss: 0.0011 - val_accuracy: 0.6088\n",
      "Epoch 268/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0011 - accuracy: 0.6147 - val_loss: 0.0011 - val_accuracy: 0.6092\n",
      "Epoch 269/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6119 - val_loss: 0.0011 - val_accuracy: 0.6133\n",
      "Epoch 270/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6143 - val_loss: 0.0011 - val_accuracy: 0.6187\n",
      "Epoch 271/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6176 - val_loss: 0.0011 - val_accuracy: 0.6143\n",
      "Epoch 272/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6158 - val_loss: 0.0011 - val_accuracy: 0.6133\n",
      "Epoch 273/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6152 - val_loss: 0.0011 - val_accuracy: 0.6131\n",
      "Epoch 274/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6182 - val_loss: 0.0011 - val_accuracy: 0.6127\n",
      "Epoch 275/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6144 - val_loss: 0.0011 - val_accuracy: 0.6165\n",
      "Epoch 276/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0011 - accuracy: 0.6199 - val_loss: 0.0011 - val_accuracy: 0.6075\n",
      "Epoch 277/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6145 - val_loss: 0.0011 - val_accuracy: 0.6144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6173 - val_loss: 0.0011 - val_accuracy: 0.6101\n",
      "Epoch 279/10000\n",
      "870/870 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.6160 - val_loss: 0.0011 - val_accuracy: 0.6122\n",
      "Epoch 280/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6156 - val_loss: 0.0011 - val_accuracy: 0.6096\n",
      "Epoch 281/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6149 - val_loss: 0.0011 - val_accuracy: 0.6116\n",
      "Epoch 282/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6131 - val_loss: 0.0011 - val_accuracy: 0.6126\n",
      "Epoch 283/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0012 - accuracy: 0.6147 - val_loss: 0.0011 - val_accuracy: 0.6132\n",
      "Epoch 284/10000\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 0.0011 - accuracy: 0.6166 - val_loss: 0.0011 - val_accuracy: 0.6040\n",
      "Epoch 285/10000\n",
      "861/870 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.6131"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10000\n",
    "patience = 500\n",
    "batch_size = 512\n",
    "num_nodes = 64\n",
    "dropout = 0.1\n",
    "learn_rate = 1e-5\n",
    "\n",
    "for i, train_feats in enumerate(combined_train_feat_sets):\n",
    "    model_dir = 'models/SR_4l_SF_inZ_models/'\n",
    "    model_name = 'classifier_train_feat_test_' + str(i)\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    print('Running with training features:', train_feats)\n",
    "    # Save training setup\n",
    "    with open(model_dir + model_name + '_setup.txt', 'w') as file:\n",
    "        file.write('Epochs: ' + str(EPOCHS) + '\\n')\n",
    "        file.write('Patience: ' + str(patience) + '\\n')\n",
    "        file.write('Learning rate: ' + str(learn_rate) + '\\n')\n",
    "        file.write('Batch size: ' + str(batch_size) + '\\n\\n')\n",
    "        file.write('Training features:\\n' + '\\n'.join(train_feats))\n",
    "    \n",
    "    # Generate train and test samples\n",
    "    sig_train, sig_test = train_test_split(sig[train_feats + ['wgt']], train_size=0.5, random_state=314)\n",
    "    bg_train, bg_test = train_test_split(bg[train_feats + ['wgt']], train_size=0.5, random_state=314)\n",
    "\n",
    "    n_sig = sum(sig_train.wgt)\n",
    "    n_bg = sum(bg_train.wgt)\n",
    "\n",
    "    x_train_sig = sig_train[train_feats]\n",
    "    x_train_bg = bg_train[train_feats]\n",
    "\n",
    "    x_train = pd.concat([x_train_sig, x_train_bg])\n",
    "    y_train = np.concatenate([np.ones(len(sig_train)), np.zeros(len(bg_train))])\n",
    "    w_train = pd.Series(np.concatenate([(n_sig + n_bg) / n_sig * sig_train['wgt'], \n",
    "                                        (n_sig + n_bg) / n_bg * bg_train['wgt']]))\n",
    "\n",
    "    n_sig_test = sum(sig_test.wgt)\n",
    "    n_bg_test = sum(bg_test.wgt)\n",
    "\n",
    "    x_test = pd.concat([sig_test[train_feats], bg_test[train_feats]])\n",
    "    y_test = np.concatenate([np.ones(len(sig_test)), np.zeros(len(bg_test))])\n",
    "    w_test = pd.Series(np.concatenate([(n_sig_test + n_bg_test) / n_sig_test * sig_test['wgt'], \n",
    "                                       (n_sig_test + n_bg_test) / n_bg_test * bg_test['wgt']]))\n",
    "    \n",
    "    # Generate and fit model\n",
    "    K.clear_session()\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(num_nodes, input_dim=x_train.shape[1], activation='relu')) \n",
    "    classifier.add(Dropout(dropout))\n",
    "    classifier.add(Dense(num_nodes, activation='relu'))\n",
    "    classifier.add(Dropout(dropout))\n",
    "    classifier.add(Dense(num_nodes, activation='relu'))\n",
    "    classifier.add(Dropout(dropout))\n",
    "    classifier.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=learn_rate)\n",
    "    classifier.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    # Early stopping\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "\n",
    "    history = classifier.fit(x_train, y_train, epochs=EPOCHS, batch_size=batch_size,\n",
    "                             validation_data=(x_test, y_test, w_test), sample_weight=w_train, \n",
    "                             verbose=1, callbacks=[callback], shuffle=True)\n",
    "    \n",
    "    # Save model and history\n",
    "    classifier.save(model_dir + model_name)\n",
    "    with open(model_dir + model_name + '_history.pkl', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data\n",
    "sig_train, sig_test = train_test_split(sig[combined_train_feats + ['wgt', 'abs_wgt']], train_size=0.5)\n",
    "bg_train, bg_test = train_test_split(bg[combined_train_feats + ['wgt', 'abs_wgt']], train_size=0.5)\n",
    "\n",
    "n_sig = sum(sig_train.wgt)\n",
    "n_bg = sum(bg_train.wgt)\n",
    "\n",
    "x_train_sig = pd.concat([sig_train[combined_train_feats]])\n",
    "x_train_bg = bg_train[combined_train_feats]\n",
    "\n",
    "x_train = pd.concat([x_train_sig, x_train_bg])\n",
    "y_train = np.concatenate([np.ones(len(sig_train))] + [np.zeros(len(bg_train))])\n",
    "w_train = pd.Series(np.concatenate([(n_sig + n_bg) / n_sig * sig_train['abs_wgt'], \n",
    "                                    (n_sig + n_bg) / n_bg * bg_train['abs_wgt']]))\n",
    "# w_train = pd.Series(np.concatenate([sig_train['wgt']]*n_sig_copies + [bg_train['wgt']]))\n",
    "\n",
    "n_sig_test = sum(sig_test.wgt)\n",
    "n_bg_test = sum(bg_test.wgt)\n",
    "\n",
    "x_test = pd.concat([sig_test[combined_train_feats], bg_test[combined_train_feats]])\n",
    "y_test = np.concatenate([np.ones(len(sig_test)), np.zeros(len(bg_test))])\n",
    "w_test = pd.Series(np.concatenate([(n_sig_test + n_bg_test) / n_sig_test * sig_test['abs_wgt'], \n",
    "                                   (n_sig_test + n_bg_test) / n_bg_test * bg_test['abs_wgt']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "233/233 [==============================] - 2s 6ms/step - loss: 0.0027 - accuracy: 0.3298 - val_loss: 0.0027 - val_accuracy: 0.7700\n",
      "Epoch 2/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.6858 - val_loss: 0.0027 - val_accuracy: 0.9414\n",
      "Epoch 3/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.8669 - val_loss: 0.0026 - val_accuracy: 0.9457\n",
      "Epoch 4/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9161 - val_loss: 0.0026 - val_accuracy: 0.9458\n",
      "Epoch 5/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9312 - val_loss: 0.0026 - val_accuracy: 0.9459\n",
      "Epoch 6/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9356 - val_loss: 0.0026 - val_accuracy: 0.9458\n",
      "Epoch 7/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9379 - val_loss: 0.0025 - val_accuracy: 0.9458\n",
      "Epoch 8/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9339 - val_loss: 0.0025 - val_accuracy: 0.9455\n",
      "Epoch 9/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9326 - val_loss: 0.0025 - val_accuracy: 0.9444\n",
      "Epoch 10/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9285 - val_loss: 0.0025 - val_accuracy: 0.9414\n",
      "Epoch 11/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9188 - val_loss: 0.0024 - val_accuracy: 0.9353\n",
      "Epoch 12/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.9101 - val_loss: 0.0024 - val_accuracy: 0.9233\n",
      "Epoch 13/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.8930 - val_loss: 0.0024 - val_accuracy: 0.9084\n",
      "Epoch 14/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.8745 - val_loss: 0.0023 - val_accuracy: 0.8956\n",
      "Epoch 15/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.8684 - val_loss: 0.0023 - val_accuracy: 0.8702\n",
      "Epoch 16/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.8466 - val_loss: 0.0023 - val_accuracy: 0.8515\n",
      "Epoch 17/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.8366 - val_loss: 0.0022 - val_accuracy: 0.8297\n",
      "Epoch 18/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 0.8237 - val_loss: 0.0022 - val_accuracy: 0.8008\n",
      "Epoch 19/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0022 - accuracy: 0.8025 - val_loss: 0.0022 - val_accuracy: 0.7888\n",
      "Epoch 20/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0022 - accuracy: 0.7888 - val_loss: 0.0021 - val_accuracy: 0.7710\n",
      "Epoch 21/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 0.7746 - val_loss: 0.0021 - val_accuracy: 0.7580\n",
      "Epoch 22/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 0.7640 - val_loss: 0.0021 - val_accuracy: 0.7396\n",
      "Epoch 23/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 0.7548 - val_loss: 0.0021 - val_accuracy: 0.7341\n",
      "Epoch 24/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 0.7484 - val_loss: 0.0020 - val_accuracy: 0.7213\n",
      "Epoch 25/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7461 - val_loss: 0.0020 - val_accuracy: 0.7045\n",
      "Epoch 26/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7287 - val_loss: 0.0020 - val_accuracy: 0.7009\n",
      "Epoch 27/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7311 - val_loss: 0.0020 - val_accuracy: 0.6889\n",
      "Epoch 28/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7180 - val_loss: 0.0020 - val_accuracy: 0.6840\n",
      "Epoch 29/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7129 - val_loss: 0.0020 - val_accuracy: 0.6822\n",
      "Epoch 30/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7097 - val_loss: 0.0020 - val_accuracy: 0.6858\n",
      "Epoch 31/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7111 - val_loss: 0.0020 - val_accuracy: 0.6854\n",
      "Epoch 32/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7110 - val_loss: 0.0019 - val_accuracy: 0.6795\n",
      "Epoch 33/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7015 - val_loss: 0.0019 - val_accuracy: 0.6764\n",
      "Epoch 34/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7083 - val_loss: 0.0019 - val_accuracy: 0.6748\n",
      "Epoch 35/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7002 - val_loss: 0.0019 - val_accuracy: 0.6737\n",
      "Epoch 36/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7019 - val_loss: 0.0019 - val_accuracy: 0.6705\n",
      "Epoch 37/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7025 - val_loss: 0.0019 - val_accuracy: 0.6765\n",
      "Epoch 38/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.7056 - val_loss: 0.0019 - val_accuracy: 0.6744\n",
      "Epoch 39/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7003 - val_loss: 0.0019 - val_accuracy: 0.6693\n",
      "Epoch 40/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6964 - val_loss: 0.0019 - val_accuracy: 0.6721\n",
      "Epoch 41/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6970 - val_loss: 0.0019 - val_accuracy: 0.6764\n",
      "Epoch 42/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6972 - val_loss: 0.0019 - val_accuracy: 0.6695\n",
      "Epoch 43/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6990 - val_loss: 0.0019 - val_accuracy: 0.6741\n",
      "Epoch 44/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6958 - val_loss: 0.0019 - val_accuracy: 0.6750\n",
      "Epoch 45/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6988 - val_loss: 0.0019 - val_accuracy: 0.6783\n",
      "Epoch 46/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.6978 - val_loss: 0.0019 - val_accuracy: 0.6802\n",
      "Epoch 47/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7021 - val_loss: 0.0019 - val_accuracy: 0.6732\n",
      "Epoch 48/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.6978 - val_loss: 0.0019 - val_accuracy: 0.6699\n",
      "Epoch 49/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6956 - val_loss: 0.0019 - val_accuracy: 0.6775\n",
      "Epoch 50/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6951 - val_loss: 0.0019 - val_accuracy: 0.6795\n",
      "Epoch 51/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7039 - val_loss: 0.0019 - val_accuracy: 0.6697\n",
      "Epoch 52/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6956 - val_loss: 0.0019 - val_accuracy: 0.6729\n",
      "Epoch 53/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6982 - val_loss: 0.0019 - val_accuracy: 0.6703\n",
      "Epoch 54/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6966 - val_loss: 0.0019 - val_accuracy: 0.6744\n",
      "Epoch 55/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6945 - val_loss: 0.0019 - val_accuracy: 0.6730\n",
      "Epoch 56/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7021 - val_loss: 0.0019 - val_accuracy: 0.6700\n",
      "Epoch 57/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6947 - val_loss: 0.0019 - val_accuracy: 0.6752\n",
      "Epoch 58/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.6968 - val_loss: 0.0019 - val_accuracy: 0.6768\n",
      "Epoch 59/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6947 - val_loss: 0.0019 - val_accuracy: 0.6777\n",
      "Epoch 60/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6960 - val_loss: 0.0019 - val_accuracy: 0.6765\n",
      "Epoch 61/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6941 - val_loss: 0.0019 - val_accuracy: 0.6793\n",
      "Epoch 62/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6993 - val_loss: 0.0019 - val_accuracy: 0.6782\n",
      "Epoch 63/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6980 - val_loss: 0.0019 - val_accuracy: 0.6782\n",
      "Epoch 64/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7015 - val_loss: 0.0019 - val_accuracy: 0.6781\n",
      "Epoch 65/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6984 - val_loss: 0.0019 - val_accuracy: 0.6807\n",
      "Epoch 66/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6986 - val_loss: 0.0019 - val_accuracy: 0.6778\n",
      "Epoch 67/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.6974 - val_loss: 0.0019 - val_accuracy: 0.6809\n",
      "Epoch 68/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6961 - val_loss: 0.0019 - val_accuracy: 0.6842\n",
      "Epoch 69/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7031 - val_loss: 0.0019 - val_accuracy: 0.6756\n",
      "Epoch 70/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6929 - val_loss: 0.0019 - val_accuracy: 0.6791\n",
      "Epoch 71/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6969 - val_loss: 0.0019 - val_accuracy: 0.6842\n",
      "Epoch 72/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7007 - val_loss: 0.0019 - val_accuracy: 0.6812\n",
      "Epoch 73/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6974 - val_loss: 0.0019 - val_accuracy: 0.6879\n",
      "Epoch 74/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7026 - val_loss: 0.0019 - val_accuracy: 0.6817\n",
      "Epoch 75/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6971 - val_loss: 0.0019 - val_accuracy: 0.6880\n",
      "Epoch 76/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7031 - val_loss: 0.0019 - val_accuracy: 0.6845\n",
      "Epoch 77/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7003 - val_loss: 0.0019 - val_accuracy: 0.6802\n",
      "Epoch 78/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6958 - val_loss: 0.0019 - val_accuracy: 0.6877\n",
      "Epoch 79/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7029 - val_loss: 0.0019 - val_accuracy: 0.6787\n",
      "Epoch 80/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6999 - val_loss: 0.0019 - val_accuracy: 0.6846\n",
      "Epoch 81/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.6998 - val_loss: 0.0018 - val_accuracy: 0.6856\n",
      "Epoch 82/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7018 - val_loss: 0.0018 - val_accuracy: 0.6861\n",
      "Epoch 83/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7054 - val_loss: 0.0018 - val_accuracy: 0.6863\n",
      "Epoch 84/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7020 - val_loss: 0.0018 - val_accuracy: 0.6855\n",
      "Epoch 85/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7056 - val_loss: 0.0018 - val_accuracy: 0.6884\n",
      "Epoch 86/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7017 - val_loss: 0.0018 - val_accuracy: 0.6925\n",
      "Epoch 87/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7058 - val_loss: 0.0018 - val_accuracy: 0.6884\n",
      "Epoch 88/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7024 - val_loss: 0.0018 - val_accuracy: 0.6900\n",
      "Epoch 89/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7041 - val_loss: 0.0018 - val_accuracy: 0.6935\n",
      "Epoch 90/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7142 - val_loss: 0.0018 - val_accuracy: 0.6823\n",
      "Epoch 91/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.6972 - val_loss: 0.0018 - val_accuracy: 0.6885\n",
      "Epoch 92/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7048 - val_loss: 0.0018 - val_accuracy: 0.6866\n",
      "Epoch 93/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.6998 - val_loss: 0.0018 - val_accuracy: 0.6917\n",
      "Epoch 94/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7026 - val_loss: 0.0018 - val_accuracy: 0.6966\n",
      "Epoch 95/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7057 - val_loss: 0.0018 - val_accuracy: 0.6899\n",
      "Epoch 96/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7045 - val_loss: 0.0018 - val_accuracy: 0.6856\n",
      "Epoch 97/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7032 - val_loss: 0.0018 - val_accuracy: 0.6874\n",
      "Epoch 98/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.6997 - val_loss: 0.0018 - val_accuracy: 0.6948\n",
      "Epoch 99/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7038 - val_loss: 0.0018 - val_accuracy: 0.6948\n",
      "Epoch 100/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7065 - val_loss: 0.0018 - val_accuracy: 0.6907\n",
      "Epoch 101/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7011 - val_loss: 0.0018 - val_accuracy: 0.6952\n",
      "Epoch 102/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7053 - val_loss: 0.0018 - val_accuracy: 0.6983\n",
      "Epoch 103/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7122 - val_loss: 0.0018 - val_accuracy: 0.6926\n",
      "Epoch 104/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7095 - val_loss: 0.0018 - val_accuracy: 0.6896\n",
      "Epoch 105/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7051 - val_loss: 0.0018 - val_accuracy: 0.6924\n",
      "Epoch 106/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7042 - val_loss: 0.0018 - val_accuracy: 0.6962\n",
      "Epoch 107/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7089 - val_loss: 0.0018 - val_accuracy: 0.6991\n",
      "Epoch 108/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7092 - val_loss: 0.0018 - val_accuracy: 0.6949\n",
      "Epoch 109/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7062 - val_loss: 0.0018 - val_accuracy: 0.7017\n",
      "Epoch 110/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7096 - val_loss: 0.0018 - val_accuracy: 0.6971\n",
      "Epoch 111/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7085 - val_loss: 0.0018 - val_accuracy: 0.7016\n",
      "Epoch 112/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7108 - val_loss: 0.0018 - val_accuracy: 0.6985\n",
      "Epoch 113/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7082 - val_loss: 0.0018 - val_accuracy: 0.6976\n",
      "Epoch 114/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7090 - val_loss: 0.0018 - val_accuracy: 0.7031\n",
      "Epoch 115/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7148 - val_loss: 0.0018 - val_accuracy: 0.7023\n",
      "Epoch 116/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7102 - val_loss: 0.0018 - val_accuracy: 0.7008\n",
      "Epoch 117/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7134 - val_loss: 0.0018 - val_accuracy: 0.7006\n",
      "Epoch 118/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7135 - val_loss: 0.0018 - val_accuracy: 0.7014\n",
      "Epoch 119/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7127 - val_loss: 0.0018 - val_accuracy: 0.6948\n",
      "Epoch 120/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7116 - val_loss: 0.0018 - val_accuracy: 0.7037\n",
      "Epoch 121/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7135 - val_loss: 0.0018 - val_accuracy: 0.7030\n",
      "Epoch 122/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7150 - val_loss: 0.0018 - val_accuracy: 0.7013\n",
      "Epoch 123/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7131 - val_loss: 0.0018 - val_accuracy: 0.6998\n",
      "Epoch 124/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7148 - val_loss: 0.0018 - val_accuracy: 0.7072\n",
      "Epoch 125/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7128 - val_loss: 0.0018 - val_accuracy: 0.7081\n",
      "Epoch 126/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7123 - val_loss: 0.0018 - val_accuracy: 0.7051\n",
      "Epoch 127/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7142 - val_loss: 0.0018 - val_accuracy: 0.7008\n",
      "Epoch 128/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7076 - val_loss: 0.0018 - val_accuracy: 0.7086\n",
      "Epoch 129/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7170 - val_loss: 0.0018 - val_accuracy: 0.7049\n",
      "Epoch 130/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7090 - val_loss: 0.0018 - val_accuracy: 0.7144\n",
      "Epoch 131/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7155 - val_loss: 0.0018 - val_accuracy: 0.7094\n",
      "Epoch 132/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7167 - val_loss: 0.0018 - val_accuracy: 0.7088\n",
      "Epoch 133/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7117 - val_loss: 0.0018 - val_accuracy: 0.7138\n",
      "Epoch 134/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7185 - val_loss: 0.0018 - val_accuracy: 0.7098\n",
      "Epoch 135/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7116 - val_loss: 0.0018 - val_accuracy: 0.7136\n",
      "Epoch 136/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7187 - val_loss: 0.0018 - val_accuracy: 0.7101\n",
      "Epoch 137/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7105 - val_loss: 0.0018 - val_accuracy: 0.7139\n",
      "Epoch 138/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7169 - val_loss: 0.0018 - val_accuracy: 0.7098\n",
      "Epoch 139/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7189 - val_loss: 0.0018 - val_accuracy: 0.7099\n",
      "Epoch 140/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7158 - val_loss: 0.0018 - val_accuracy: 0.7070\n",
      "Epoch 141/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7120 - val_loss: 0.0018 - val_accuracy: 0.7063\n",
      "Epoch 142/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7136 - val_loss: 0.0018 - val_accuracy: 0.7143\n",
      "Epoch 143/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7192 - val_loss: 0.0018 - val_accuracy: 0.7167\n",
      "Epoch 144/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7244 - val_loss: 0.0018 - val_accuracy: 0.7086\n",
      "Epoch 145/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7158 - val_loss: 0.0018 - val_accuracy: 0.7117\n",
      "Epoch 146/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7167 - val_loss: 0.0018 - val_accuracy: 0.7168\n",
      "Epoch 147/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7237 - val_loss: 0.0018 - val_accuracy: 0.7177\n",
      "Epoch 148/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7235 - val_loss: 0.0018 - val_accuracy: 0.7115\n",
      "Epoch 149/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7230 - val_loss: 0.0018 - val_accuracy: 0.7096\n",
      "Epoch 150/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7171 - val_loss: 0.0018 - val_accuracy: 0.7170\n",
      "Epoch 151/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7181 - val_loss: 0.0018 - val_accuracy: 0.7168\n",
      "Epoch 152/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7230 - val_loss: 0.0018 - val_accuracy: 0.7167\n",
      "Epoch 153/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7245 - val_loss: 0.0018 - val_accuracy: 0.7137\n",
      "Epoch 154/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7189 - val_loss: 0.0018 - val_accuracy: 0.7198\n",
      "Epoch 155/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7234 - val_loss: 0.0018 - val_accuracy: 0.7185\n",
      "Epoch 156/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7244 - val_loss: 0.0018 - val_accuracy: 0.7215\n",
      "Epoch 157/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7231 - val_loss: 0.0018 - val_accuracy: 0.7166\n",
      "Epoch 158/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7214 - val_loss: 0.0018 - val_accuracy: 0.7172\n",
      "Epoch 159/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7242 - val_loss: 0.0018 - val_accuracy: 0.7226\n",
      "Epoch 160/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7275 - val_loss: 0.0018 - val_accuracy: 0.7257\n",
      "Epoch 161/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7284 - val_loss: 0.0018 - val_accuracy: 0.7239\n",
      "Epoch 162/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7238 - val_loss: 0.0018 - val_accuracy: 0.7213\n",
      "Epoch 163/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7192 - val_loss: 0.0018 - val_accuracy: 0.7255\n",
      "Epoch 164/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7229 - val_loss: 0.0018 - val_accuracy: 0.7278\n",
      "Epoch 165/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7297 - val_loss: 0.0018 - val_accuracy: 0.7230\n",
      "Epoch 166/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7261 - val_loss: 0.0018 - val_accuracy: 0.7252\n",
      "Epoch 167/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7283 - val_loss: 0.0018 - val_accuracy: 0.7240\n",
      "Epoch 168/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7318 - val_loss: 0.0018 - val_accuracy: 0.7186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7226 - val_loss: 0.0018 - val_accuracy: 0.7251\n",
      "Epoch 170/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7254 - val_loss: 0.0018 - val_accuracy: 0.7234\n",
      "Epoch 171/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7279 - val_loss: 0.0018 - val_accuracy: 0.7238\n",
      "Epoch 172/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7221 - val_loss: 0.0018 - val_accuracy: 0.7311\n",
      "Epoch 173/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7301 - val_loss: 0.0018 - val_accuracy: 0.7251\n",
      "Epoch 174/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7257 - val_loss: 0.0018 - val_accuracy: 0.7298\n",
      "Epoch 175/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7268 - val_loss: 0.0018 - val_accuracy: 0.7285\n",
      "Epoch 176/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7325 - val_loss: 0.0018 - val_accuracy: 0.7269\n",
      "Epoch 177/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7314 - val_loss: 0.0018 - val_accuracy: 0.7344\n",
      "Epoch 178/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7321 - val_loss: 0.0018 - val_accuracy: 0.7275\n",
      "Epoch 179/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7315 - val_loss: 0.0018 - val_accuracy: 0.7299\n",
      "Epoch 180/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7299 - val_loss: 0.0018 - val_accuracy: 0.7287\n",
      "Epoch 181/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7316 - val_loss: 0.0018 - val_accuracy: 0.7311\n",
      "Epoch 182/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7350 - val_loss: 0.0018 - val_accuracy: 0.7285\n",
      "Epoch 183/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7321 - val_loss: 0.0018 - val_accuracy: 0.7339\n",
      "Epoch 184/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7351 - val_loss: 0.0018 - val_accuracy: 0.7291\n",
      "Epoch 185/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7321 - val_loss: 0.0018 - val_accuracy: 0.7353\n",
      "Epoch 186/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7320 - val_loss: 0.0018 - val_accuracy: 0.7347\n",
      "Epoch 187/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7339 - val_loss: 0.0018 - val_accuracy: 0.7336\n",
      "Epoch 188/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7370 - val_loss: 0.0018 - val_accuracy: 0.7296\n",
      "Epoch 189/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7302 - val_loss: 0.0018 - val_accuracy: 0.7345\n",
      "Epoch 190/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7296 - val_loss: 0.0018 - val_accuracy: 0.7367\n",
      "Epoch 191/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7390 - val_loss: 0.0018 - val_accuracy: 0.7309\n",
      "Epoch 192/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7317 - val_loss: 0.0018 - val_accuracy: 0.7336\n",
      "Epoch 193/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7357 - val_loss: 0.0018 - val_accuracy: 0.7336\n",
      "Epoch 194/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7329 - val_loss: 0.0018 - val_accuracy: 0.7380\n",
      "Epoch 195/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7375 - val_loss: 0.0018 - val_accuracy: 0.7380\n",
      "Epoch 196/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7383 - val_loss: 0.0018 - val_accuracy: 0.7368\n",
      "Epoch 197/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7336 - val_loss: 0.0018 - val_accuracy: 0.7390\n",
      "Epoch 198/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7389 - val_loss: 0.0018 - val_accuracy: 0.7372\n",
      "Epoch 199/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7369 - val_loss: 0.0018 - val_accuracy: 0.7370\n",
      "Epoch 200/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7340 - val_loss: 0.0018 - val_accuracy: 0.7382\n",
      "Epoch 201/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7388 - val_loss: 0.0018 - val_accuracy: 0.7385\n",
      "Epoch 202/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7371 - val_loss: 0.0017 - val_accuracy: 0.7373\n",
      "Epoch 203/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7360 - val_loss: 0.0017 - val_accuracy: 0.7359\n",
      "Epoch 204/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7376 - val_loss: 0.0017 - val_accuracy: 0.7367\n",
      "Epoch 205/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7361 - val_loss: 0.0017 - val_accuracy: 0.7411\n",
      "Epoch 206/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7370 - val_loss: 0.0017 - val_accuracy: 0.7452\n",
      "Epoch 207/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7445 - val_loss: 0.0017 - val_accuracy: 0.7388\n",
      "Epoch 208/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7394 - val_loss: 0.0017 - val_accuracy: 0.7413\n",
      "Epoch 209/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7381 - val_loss: 0.0017 - val_accuracy: 0.7418\n",
      "Epoch 210/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7400 - val_loss: 0.0017 - val_accuracy: 0.7384\n",
      "Epoch 211/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7432 - val_loss: 0.0017 - val_accuracy: 0.7418\n",
      "Epoch 212/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7380 - val_loss: 0.0017 - val_accuracy: 0.7455\n",
      "Epoch 213/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7451 - val_loss: 0.0017 - val_accuracy: 0.7410\n",
      "Epoch 214/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7338 - val_loss: 0.0017 - val_accuracy: 0.7516\n",
      "Epoch 215/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7481 - val_loss: 0.0017 - val_accuracy: 0.7421\n",
      "Epoch 216/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7396 - val_loss: 0.0017 - val_accuracy: 0.7473\n",
      "Epoch 217/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.7420 - val_loss: 0.0017 - val_accuracy: 0.7468\n",
      "Epoch 218/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7401 - val_loss: 0.0017 - val_accuracy: 0.7454\n",
      "Epoch 219/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7431 - val_loss: 0.0017 - val_accuracy: 0.7421\n",
      "Epoch 220/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7387 - val_loss: 0.0017 - val_accuracy: 0.7487\n",
      "Epoch 221/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7482 - val_loss: 0.0017 - val_accuracy: 0.7516\n",
      "Epoch 222/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7485 - val_loss: 0.0017 - val_accuracy: 0.7508\n",
      "Epoch 223/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7476 - val_loss: 0.0017 - val_accuracy: 0.7477\n",
      "Epoch 224/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7442 - val_loss: 0.0017 - val_accuracy: 0.7509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7455 - val_loss: 0.0017 - val_accuracy: 0.7447\n",
      "Epoch 226/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7444 - val_loss: 0.0017 - val_accuracy: 0.7451\n",
      "Epoch 227/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7444 - val_loss: 0.0017 - val_accuracy: 0.7475\n",
      "Epoch 228/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7435 - val_loss: 0.0017 - val_accuracy: 0.7539\n",
      "Epoch 229/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7474 - val_loss: 0.0017 - val_accuracy: 0.7503\n",
      "Epoch 230/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7427 - val_loss: 0.0017 - val_accuracy: 0.7545\n",
      "Epoch 231/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7511 - val_loss: 0.0017 - val_accuracy: 0.7543\n",
      "Epoch 232/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7501 - val_loss: 0.0017 - val_accuracy: 0.7469\n",
      "Epoch 233/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7450 - val_loss: 0.0017 - val_accuracy: 0.7497\n",
      "Epoch 234/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7433 - val_loss: 0.0017 - val_accuracy: 0.7560\n",
      "Epoch 235/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7494 - val_loss: 0.0017 - val_accuracy: 0.7562\n",
      "Epoch 236/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7484 - val_loss: 0.0017 - val_accuracy: 0.7532\n",
      "Epoch 237/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7510 - val_loss: 0.0017 - val_accuracy: 0.7522\n",
      "Epoch 238/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7424 - val_loss: 0.0017 - val_accuracy: 0.7551\n",
      "Epoch 239/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7510 - val_loss: 0.0017 - val_accuracy: 0.7544\n",
      "Epoch 240/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7489 - val_loss: 0.0017 - val_accuracy: 0.7534\n",
      "Epoch 241/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7518 - val_loss: 0.0017 - val_accuracy: 0.7521\n",
      "Epoch 242/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7490 - val_loss: 0.0017 - val_accuracy: 0.7552\n",
      "Epoch 243/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7506 - val_loss: 0.0017 - val_accuracy: 0.7566\n",
      "Epoch 244/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7503 - val_loss: 0.0017 - val_accuracy: 0.7504\n",
      "Epoch 245/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7494 - val_loss: 0.0017 - val_accuracy: 0.7516\n",
      "Epoch 246/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7494 - val_loss: 0.0017 - val_accuracy: 0.7548\n",
      "Epoch 247/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7519 - val_loss: 0.0017 - val_accuracy: 0.7563\n",
      "Epoch 248/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7528 - val_loss: 0.0017 - val_accuracy: 0.7597\n",
      "Epoch 249/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7542 - val_loss: 0.0017 - val_accuracy: 0.7599\n",
      "Epoch 250/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7540 - val_loss: 0.0017 - val_accuracy: 0.7621\n",
      "Epoch 251/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7534 - val_loss: 0.0017 - val_accuracy: 0.7634\n",
      "Epoch 252/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7560 - val_loss: 0.0017 - val_accuracy: 0.7635\n",
      "Epoch 253/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7561 - val_loss: 0.0017 - val_accuracy: 0.7689\n",
      "Epoch 254/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7578 - val_loss: 0.0017 - val_accuracy: 0.7609\n",
      "Epoch 255/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7562 - val_loss: 0.0017 - val_accuracy: 0.7616\n",
      "Epoch 256/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7571 - val_loss: 0.0017 - val_accuracy: 0.7647\n",
      "Epoch 257/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7560 - val_loss: 0.0017 - val_accuracy: 0.7605\n",
      "Epoch 258/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7571 - val_loss: 0.0017 - val_accuracy: 0.7614\n",
      "Epoch 259/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7524 - val_loss: 0.0017 - val_accuracy: 0.7648\n",
      "Epoch 260/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7554 - val_loss: 0.0017 - val_accuracy: 0.7648\n",
      "Epoch 261/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7609 - val_loss: 0.0017 - val_accuracy: 0.7599\n",
      "Epoch 262/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7565 - val_loss: 0.0017 - val_accuracy: 0.7608\n",
      "Epoch 263/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7541 - val_loss: 0.0017 - val_accuracy: 0.7706\n",
      "Epoch 264/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7618 - val_loss: 0.0017 - val_accuracy: 0.7653\n",
      "Epoch 265/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7563 - val_loss: 0.0017 - val_accuracy: 0.7655\n",
      "Epoch 266/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7590 - val_loss: 0.0017 - val_accuracy: 0.7633\n",
      "Epoch 267/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7607 - val_loss: 0.0017 - val_accuracy: 0.7684\n",
      "Epoch 268/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7636 - val_loss: 0.0017 - val_accuracy: 0.7676\n",
      "Epoch 269/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7619 - val_loss: 0.0017 - val_accuracy: 0.7605\n",
      "Epoch 270/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7595 - val_loss: 0.0017 - val_accuracy: 0.7642\n",
      "Epoch 271/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7617 - val_loss: 0.0017 - val_accuracy: 0.7590\n",
      "Epoch 272/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7592 - val_loss: 0.0017 - val_accuracy: 0.7716\n",
      "Epoch 273/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7593 - val_loss: 0.0017 - val_accuracy: 0.7739\n",
      "Epoch 274/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7662 - val_loss: 0.0017 - val_accuracy: 0.7789\n",
      "Epoch 275/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7641 - val_loss: 0.0017 - val_accuracy: 0.7735\n",
      "Epoch 276/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7673 - val_loss: 0.0017 - val_accuracy: 0.7662\n",
      "Epoch 277/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7587 - val_loss: 0.0017 - val_accuracy: 0.7695\n",
      "Epoch 278/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7630 - val_loss: 0.0017 - val_accuracy: 0.7725\n",
      "Epoch 279/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7633 - val_loss: 0.0017 - val_accuracy: 0.7693\n",
      "Epoch 280/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7644 - val_loss: 0.0017 - val_accuracy: 0.7701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7616 - val_loss: 0.0017 - val_accuracy: 0.7692\n",
      "Epoch 282/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7643 - val_loss: 0.0017 - val_accuracy: 0.7696\n",
      "Epoch 283/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7612 - val_loss: 0.0017 - val_accuracy: 0.7757\n",
      "Epoch 284/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7629 - val_loss: 0.0017 - val_accuracy: 0.7749\n",
      "Epoch 285/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7721 - val_loss: 0.0017 - val_accuracy: 0.7745\n",
      "Epoch 286/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7662 - val_loss: 0.0017 - val_accuracy: 0.7720\n",
      "Epoch 287/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7660 - val_loss: 0.0017 - val_accuracy: 0.7690\n",
      "Epoch 288/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7660 - val_loss: 0.0017 - val_accuracy: 0.7719\n",
      "Epoch 289/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7633 - val_loss: 0.0017 - val_accuracy: 0.7732\n",
      "Epoch 290/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7665 - val_loss: 0.0017 - val_accuracy: 0.7770\n",
      "Epoch 291/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7674 - val_loss: 0.0017 - val_accuracy: 0.7725\n",
      "Epoch 292/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7652 - val_loss: 0.0017 - val_accuracy: 0.7787\n",
      "Epoch 293/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7646 - val_loss: 0.0017 - val_accuracy: 0.7765\n",
      "Epoch 294/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7670 - val_loss: 0.0017 - val_accuracy: 0.7760\n",
      "Epoch 295/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7682 - val_loss: 0.0017 - val_accuracy: 0.7704\n",
      "Epoch 296/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7636 - val_loss: 0.0017 - val_accuracy: 0.7773\n",
      "Epoch 297/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7657 - val_loss: 0.0017 - val_accuracy: 0.7736\n",
      "Epoch 298/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7668 - val_loss: 0.0017 - val_accuracy: 0.7741\n",
      "Epoch 299/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7635 - val_loss: 0.0017 - val_accuracy: 0.7781\n",
      "Epoch 300/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7680 - val_loss: 0.0017 - val_accuracy: 0.7749\n",
      "Epoch 301/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7669 - val_loss: 0.0017 - val_accuracy: 0.7804\n",
      "Epoch 302/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7700 - val_loss: 0.0017 - val_accuracy: 0.7853\n",
      "Epoch 303/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7744 - val_loss: 0.0017 - val_accuracy: 0.7874\n",
      "Epoch 304/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7706 - val_loss: 0.0017 - val_accuracy: 0.7819\n",
      "Epoch 305/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7718 - val_loss: 0.0017 - val_accuracy: 0.7797\n",
      "Epoch 306/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7746 - val_loss: 0.0017 - val_accuracy: 0.7751\n",
      "Epoch 307/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7665 - val_loss: 0.0017 - val_accuracy: 0.7758\n",
      "Epoch 308/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7653 - val_loss: 0.0017 - val_accuracy: 0.7768\n",
      "Epoch 309/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7716 - val_loss: 0.0017 - val_accuracy: 0.7778\n",
      "Epoch 310/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7662 - val_loss: 0.0017 - val_accuracy: 0.7782\n",
      "Epoch 311/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7715 - val_loss: 0.0017 - val_accuracy: 0.7793\n",
      "Epoch 312/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7737 - val_loss: 0.0017 - val_accuracy: 0.7819\n",
      "Epoch 313/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7728 - val_loss: 0.0017 - val_accuracy: 0.7859\n",
      "Epoch 314/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7764 - val_loss: 0.0017 - val_accuracy: 0.7820\n",
      "Epoch 315/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7723 - val_loss: 0.0017 - val_accuracy: 0.7866\n",
      "Epoch 316/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7739 - val_loss: 0.0017 - val_accuracy: 0.7807\n",
      "Epoch 317/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7670 - val_loss: 0.0017 - val_accuracy: 0.7939\n",
      "Epoch 318/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7795 - val_loss: 0.0017 - val_accuracy: 0.7852\n",
      "Epoch 319/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7748 - val_loss: 0.0017 - val_accuracy: 0.7793\n",
      "Epoch 320/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7711 - val_loss: 0.0017 - val_accuracy: 0.7793\n",
      "Epoch 321/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7662 - val_loss: 0.0017 - val_accuracy: 0.7867\n",
      "Epoch 322/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7739 - val_loss: 0.0017 - val_accuracy: 0.7839\n",
      "Epoch 323/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7731 - val_loss: 0.0017 - val_accuracy: 0.7853\n",
      "Epoch 324/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7746 - val_loss: 0.0017 - val_accuracy: 0.7895\n",
      "Epoch 325/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7746 - val_loss: 0.0017 - val_accuracy: 0.7870\n",
      "Epoch 326/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7753 - val_loss: 0.0017 - val_accuracy: 0.7906\n",
      "Epoch 327/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7777 - val_loss: 0.0017 - val_accuracy: 0.7840\n",
      "Epoch 328/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7719 - val_loss: 0.0017 - val_accuracy: 0.7909\n",
      "Epoch 329/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7797 - val_loss: 0.0017 - val_accuracy: 0.7861\n",
      "Epoch 330/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7755 - val_loss: 0.0017 - val_accuracy: 0.7899\n",
      "Epoch 331/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7824 - val_loss: 0.0017 - val_accuracy: 0.7850\n",
      "Epoch 332/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7732 - val_loss: 0.0017 - val_accuracy: 0.7924\n",
      "Epoch 333/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7761 - val_loss: 0.0017 - val_accuracy: 0.7853\n",
      "Epoch 334/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7736 - val_loss: 0.0017 - val_accuracy: 0.7923\n",
      "Epoch 335/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7745 - val_loss: 0.0017 - val_accuracy: 0.7930\n",
      "Epoch 336/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7810 - val_loss: 0.0017 - val_accuracy: 0.7929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7788 - val_loss: 0.0017 - val_accuracy: 0.7916\n",
      "Epoch 338/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7815 - val_loss: 0.0017 - val_accuracy: 0.7864\n",
      "Epoch 339/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7738 - val_loss: 0.0017 - val_accuracy: 0.7906\n",
      "Epoch 340/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7795 - val_loss: 0.0017 - val_accuracy: 0.7866\n",
      "Epoch 341/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7705 - val_loss: 0.0017 - val_accuracy: 0.7930\n",
      "Epoch 342/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7792 - val_loss: 0.0017 - val_accuracy: 0.7900\n",
      "Epoch 343/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7808 - val_loss: 0.0017 - val_accuracy: 0.7936\n",
      "Epoch 344/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7847 - val_loss: 0.0017 - val_accuracy: 0.7874\n",
      "Epoch 345/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7812 - val_loss: 0.0017 - val_accuracy: 0.7847\n",
      "Epoch 346/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7768 - val_loss: 0.0017 - val_accuracy: 0.7910\n",
      "Epoch 347/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7818 - val_loss: 0.0017 - val_accuracy: 0.7964\n",
      "Epoch 348/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7789 - val_loss: 0.0017 - val_accuracy: 0.7932\n",
      "Epoch 349/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7815 - val_loss: 0.0017 - val_accuracy: 0.7934\n",
      "Epoch 350/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7823 - val_loss: 0.0017 - val_accuracy: 0.7905\n",
      "Epoch 351/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7776 - val_loss: 0.0017 - val_accuracy: 0.7969\n",
      "Epoch 352/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7822 - val_loss: 0.0017 - val_accuracy: 0.7941\n",
      "Epoch 353/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7817 - val_loss: 0.0017 - val_accuracy: 0.7940\n",
      "Epoch 354/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7808 - val_loss: 0.0017 - val_accuracy: 0.7948\n",
      "Epoch 355/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7809 - val_loss: 0.0017 - val_accuracy: 0.7975\n",
      "Epoch 356/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7836 - val_loss: 0.0017 - val_accuracy: 0.7965\n",
      "Epoch 357/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.7810 - val_loss: 0.0017 - val_accuracy: 0.7993\n",
      "Epoch 358/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7826 - val_loss: 0.0017 - val_accuracy: 0.7946\n",
      "Epoch 359/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7818 - val_loss: 0.0017 - val_accuracy: 0.7960\n",
      "Epoch 360/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7838 - val_loss: 0.0017 - val_accuracy: 0.7938\n",
      "Epoch 361/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7822 - val_loss: 0.0017 - val_accuracy: 0.7927\n",
      "Epoch 362/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7813 - val_loss: 0.0017 - val_accuracy: 0.7932\n",
      "Epoch 363/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7812 - val_loss: 0.0017 - val_accuracy: 0.7911\n",
      "Epoch 364/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7818 - val_loss: 0.0017 - val_accuracy: 0.7958\n",
      "Epoch 365/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7847 - val_loss: 0.0017 - val_accuracy: 0.7960\n",
      "Epoch 366/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7792 - val_loss: 0.0017 - val_accuracy: 0.7941\n",
      "Epoch 367/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7839 - val_loss: 0.0017 - val_accuracy: 0.7927\n",
      "Epoch 368/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7798 - val_loss: 0.0017 - val_accuracy: 0.7972\n",
      "Epoch 369/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7856 - val_loss: 0.0017 - val_accuracy: 0.7921\n",
      "Epoch 370/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7816 - val_loss: 0.0017 - val_accuracy: 0.7978\n",
      "Epoch 371/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7855 - val_loss: 0.0017 - val_accuracy: 0.8000\n",
      "Epoch 372/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7851 - val_loss: 0.0017 - val_accuracy: 0.7984\n",
      "Epoch 373/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7855 - val_loss: 0.0017 - val_accuracy: 0.8003\n",
      "Epoch 374/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7876 - val_loss: 0.0017 - val_accuracy: 0.7953\n",
      "Epoch 375/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7814 - val_loss: 0.0017 - val_accuracy: 0.7976\n",
      "Epoch 376/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7839 - val_loss: 0.0017 - val_accuracy: 0.7982\n",
      "Epoch 377/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7852 - val_loss: 0.0017 - val_accuracy: 0.8050\n",
      "Epoch 378/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7882 - val_loss: 0.0017 - val_accuracy: 0.8010\n",
      "Epoch 379/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7850 - val_loss: 0.0017 - val_accuracy: 0.7999\n",
      "Epoch 380/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7893 - val_loss: 0.0017 - val_accuracy: 0.8017\n",
      "Epoch 381/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7865 - val_loss: 0.0017 - val_accuracy: 0.8023\n",
      "Epoch 382/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7921 - val_loss: 0.0017 - val_accuracy: 0.7965\n",
      "Epoch 383/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7862 - val_loss: 0.0017 - val_accuracy: 0.7991\n",
      "Epoch 384/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7864 - val_loss: 0.0017 - val_accuracy: 0.8014\n",
      "Epoch 385/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7872 - val_loss: 0.0017 - val_accuracy: 0.8051\n",
      "Epoch 386/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7918 - val_loss: 0.0017 - val_accuracy: 0.8010\n",
      "Epoch 387/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7868 - val_loss: 0.0017 - val_accuracy: 0.8009\n",
      "Epoch 388/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7888 - val_loss: 0.0017 - val_accuracy: 0.8004\n",
      "Epoch 389/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7868 - val_loss: 0.0017 - val_accuracy: 0.8078\n",
      "Epoch 390/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7902 - val_loss: 0.0016 - val_accuracy: 0.8002\n",
      "Epoch 391/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7901 - val_loss: 0.0016 - val_accuracy: 0.7983\n",
      "Epoch 392/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7899 - val_loss: 0.0016 - val_accuracy: 0.7973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7854 - val_loss: 0.0016 - val_accuracy: 0.8050\n",
      "Epoch 394/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7940 - val_loss: 0.0016 - val_accuracy: 0.8008\n",
      "Epoch 395/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7845 - val_loss: 0.0016 - val_accuracy: 0.8047\n",
      "Epoch 396/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7908 - val_loss: 0.0016 - val_accuracy: 0.8056\n",
      "Epoch 397/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7871 - val_loss: 0.0017 - val_accuracy: 0.8123\n",
      "Epoch 398/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7961 - val_loss: 0.0016 - val_accuracy: 0.8005\n",
      "Epoch 399/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7863 - val_loss: 0.0016 - val_accuracy: 0.8047\n",
      "Epoch 400/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7903 - val_loss: 0.0016 - val_accuracy: 0.8059\n",
      "Epoch 401/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7925 - val_loss: 0.0016 - val_accuracy: 0.8037\n",
      "Epoch 402/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7932 - val_loss: 0.0016 - val_accuracy: 0.8058\n",
      "Epoch 403/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7903 - val_loss: 0.0016 - val_accuracy: 0.8043\n",
      "Epoch 404/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7920 - val_loss: 0.0016 - val_accuracy: 0.8040\n",
      "Epoch 405/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7908 - val_loss: 0.0016 - val_accuracy: 0.8086\n",
      "Epoch 406/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7919 - val_loss: 0.0016 - val_accuracy: 0.8051\n",
      "Epoch 407/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7903 - val_loss: 0.0016 - val_accuracy: 0.8071\n",
      "Epoch 408/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7921 - val_loss: 0.0016 - val_accuracy: 0.8029\n",
      "Epoch 409/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7932 - val_loss: 0.0016 - val_accuracy: 0.8040\n",
      "Epoch 410/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7923 - val_loss: 0.0016 - val_accuracy: 0.8034\n",
      "Epoch 411/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7934 - val_loss: 0.0016 - val_accuracy: 0.8027\n",
      "Epoch 412/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7922 - val_loss: 0.0016 - val_accuracy: 0.8033\n",
      "Epoch 413/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7888 - val_loss: 0.0016 - val_accuracy: 0.8113\n",
      "Epoch 414/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7920 - val_loss: 0.0016 - val_accuracy: 0.8112\n",
      "Epoch 415/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7949 - val_loss: 0.0016 - val_accuracy: 0.8130\n",
      "Epoch 416/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7949 - val_loss: 0.0016 - val_accuracy: 0.8127\n",
      "Epoch 417/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7949 - val_loss: 0.0016 - val_accuracy: 0.8135\n",
      "Epoch 418/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7962 - val_loss: 0.0016 - val_accuracy: 0.8038\n",
      "Epoch 419/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7912 - val_loss: 0.0016 - val_accuracy: 0.8018\n",
      "Epoch 420/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7885 - val_loss: 0.0016 - val_accuracy: 0.8085\n",
      "Epoch 421/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7951 - val_loss: 0.0016 - val_accuracy: 0.8084\n",
      "Epoch 422/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7914 - val_loss: 0.0016 - val_accuracy: 0.8125\n",
      "Epoch 423/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7935 - val_loss: 0.0016 - val_accuracy: 0.8122\n",
      "Epoch 424/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7974 - val_loss: 0.0016 - val_accuracy: 0.8059\n",
      "Epoch 425/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7909 - val_loss: 0.0016 - val_accuracy: 0.8136\n",
      "Epoch 426/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.7949 - val_loss: 0.0016 - val_accuracy: 0.8119\n",
      "Epoch 427/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7928 - val_loss: 0.0016 - val_accuracy: 0.8117\n",
      "Epoch 428/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7953 - val_loss: 0.0016 - val_accuracy: 0.8103\n",
      "Epoch 429/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7980 - val_loss: 0.0016 - val_accuracy: 0.8102\n",
      "Epoch 430/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7927 - val_loss: 0.0016 - val_accuracy: 0.8148\n",
      "Epoch 431/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7985 - val_loss: 0.0016 - val_accuracy: 0.8132\n",
      "Epoch 432/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.7983 - val_loss: 0.0016 - val_accuracy: 0.8110\n",
      "Epoch 433/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7970 - val_loss: 0.0016 - val_accuracy: 0.8148\n",
      "Epoch 434/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7964 - val_loss: 0.0016 - val_accuracy: 0.8105\n",
      "Epoch 435/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7941 - val_loss: 0.0016 - val_accuracy: 0.8085\n",
      "Epoch 436/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7967 - val_loss: 0.0016 - val_accuracy: 0.8143\n",
      "Epoch 437/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.8017 - val_loss: 0.0016 - val_accuracy: 0.8112\n",
      "Epoch 438/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7940 - val_loss: 0.0016 - val_accuracy: 0.8069\n",
      "Epoch 439/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7928 - val_loss: 0.0016 - val_accuracy: 0.8187\n",
      "Epoch 440/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7999 - val_loss: 0.0016 - val_accuracy: 0.8120\n",
      "Epoch 441/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7959 - val_loss: 0.0016 - val_accuracy: 0.8104\n",
      "Epoch 442/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7952 - val_loss: 0.0016 - val_accuracy: 0.8103\n",
      "Epoch 443/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7931 - val_loss: 0.0016 - val_accuracy: 0.8120\n",
      "Epoch 444/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7991 - val_loss: 0.0016 - val_accuracy: 0.8136\n",
      "Epoch 445/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.7998 - val_loss: 0.0016 - val_accuracy: 0.8102\n",
      "Epoch 446/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.7991 - val_loss: 0.0016 - val_accuracy: 0.8120\n",
      "Epoch 447/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7954 - val_loss: 0.0016 - val_accuracy: 0.8192\n",
      "Epoch 448/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7983 - val_loss: 0.0016 - val_accuracy: 0.8175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7989 - val_loss: 0.0016 - val_accuracy: 0.8123\n",
      "Epoch 450/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.8012 - val_loss: 0.0016 - val_accuracy: 0.8131\n",
      "Epoch 451/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7961 - val_loss: 0.0016 - val_accuracy: 0.8200\n",
      "Epoch 452/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7966 - val_loss: 0.0016 - val_accuracy: 0.8189\n",
      "Epoch 453/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.8028 - val_loss: 0.0016 - val_accuracy: 0.8131\n",
      "Epoch 454/10000\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7995 - val_loss: 0.0016 - val_accuracy: 0.8121\n",
      "Epoch 455/10000\n",
      "230/233 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.7986"
     ]
    }
   ],
   "source": [
    "# Fit ML classifier\n",
    "EPOCHS = 10000\n",
    "batch_size = 512\n",
    "num_nodes = 64\n",
    "dropout = 0.1\n",
    "\n",
    "n_models = 10\n",
    "\n",
    "plot_name = 'all_train_feats_updated_full_list_no_phi_10_models'\n",
    "\n",
    "for i in range(n_models):\n",
    "    # Generate and fit model\n",
    "    classifier_4l_DF = Sequential()\n",
    "    classifier_4l_DF.add(Dense(num_nodes, input_dim=x_train.shape[1], activation='relu')) \n",
    "    classifier_4l_DF.add(Dropout(dropout))\n",
    "    classifier_4l_DF.add(Dense(num_nodes, activation='relu'))\n",
    "    classifier_4l_DF.add(Dropout(dropout))\n",
    "    classifier_4l_DF.add(Dense(num_nodes, activation='relu'))\n",
    "    classifier_4l_DF.add(Dropout(dropout))\n",
    "    classifier_4l_DF.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-5)\n",
    "    classifier_4l_DF.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    # Early stopping\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1000, restore_best_weights=True)\n",
    "\n",
    "    history = classifier_4l_DF.fit(x_train, y_train, epochs=EPOCHS, batch_size=batch_size,\n",
    "                                   validation_data=(x_test, y_test, w_test), sample_weight=w_train, \n",
    "                                   verbose=1, callbacks=[callback], shuffle=True)\n",
    "    \n",
    "    bg_test['NN_out_' + str(i)] = classifier_4l_DF.predict(bg_test[combined_train_feats], batch_size=10000)\n",
    "    sig_test['NN_out_' + str(i)] = classifier_4l_DF.predict(sig_test[combined_train_feats], batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_out_cols = ['NN_out_' + str(i) for i in range(n_models)]\n",
    "\n",
    "bg_test['NN_out_mean'] = np.mean(bg_test[nn_out_cols], axis=1)\n",
    "sig_test['NN_out_mean'] = np.mean(sig_test[nn_out_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, b, _ = plt.hist(bg_test.NN_out_mean, bins=20, alpha=0.7, weights=bg_test.wgt, label='Background')\n",
    "plt.hist(sig_test.NN_out_mean, bins=b, alpha=0.7, weights=sig_test.wgt, label='Signal')\n",
    "\n",
    "plt.ylabel('Events', fontsize=14)\n",
    "plt.xlabel('NN output', fontsize=14)\n",
    "plt.title('4$\\ell$-DF', loc='right', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.yscale('log')\n",
    "\n",
    "atlasify('Internal Simulation', outside=True)\n",
    "plt.minorticks_on()\n",
    "\n",
    "plt.savefig('plots/SR_4l_DF_optimization/' + plot_name + '_events.png')\n",
    "plt.savefig('plots/SR_4l_DF_optimization/' + plot_name + '_events.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sig_pts = 100\n",
    "\n",
    "nn_cuts = np.arange(0.0, 1.0, 1.0/n_sig_pts)\n",
    "significances = [float('nan')]*n_sig_pts\n",
    "\n",
    "max_sig_loc = 0\n",
    "max_sig = 0\n",
    "\n",
    "for i, nn_cut in enumerate(nn_cuts):\n",
    "    n_bg = sum(bg_test[bg_test.NN_out_mean > nn_cut].wgt)\n",
    "    n_sig = sum(sig_test[sig_test.NN_out_mean > nn_cut].wgt)\n",
    "    \n",
    "    try:\n",
    "        current_sig = region_sig(n_sig, n_bg)\n",
    "    except ZeroDivisionError:\n",
    "        current_sig = float('nan')\n",
    "    significances[i] = current_sig\n",
    "    \n",
    "    if current_sig > max_sig:\n",
    "        max_sig = current_sig\n",
    "        max_sig_loc = nn_cut\n",
    "        \n",
    "print('Max observed significance:', max_sig, 'sigma at cut of', max_sig_loc)\n",
    "print('Corresponds to', 2*max_sig, 'sigma with full dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nn_cuts, significances)\n",
    "\n",
    "plt.axhline(y=max_sig, color='black', ls='--')\n",
    "plt.axvline(x=max_sig_loc, color='black', ls='--')\n",
    "\n",
    "plt.ylabel('Significance', fontsize=14)\n",
    "plt.xlabel('NN cut', fontsize=14)\n",
    "plt.title('4$\\ell$-DF', loc='right', fontsize=14)\n",
    "\n",
    "plt.text(min(nn_cuts), min(significances), \n",
    "         'Max: %.2f $\\sigma$\\nCorresponds to %.2f $\\sigma$\\nLoc: %.2f'%(max_sig, 2*max_sig, max_sig_loc),\n",
    "         fontsize=14)\n",
    "\n",
    "atlasify('Internal Simulation', outside=True)\n",
    "\n",
    "plt.savefig('plots/SR_4l_DF_optimization/' + plot_name + '.png')\n",
    "plt.savefig('plots/SR_4l_DF_optimization/' + plot_name + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wvz_machine_learning",
   "language": "python",
   "name": "wvz_machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
